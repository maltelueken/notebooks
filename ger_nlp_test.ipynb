{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test German NLP Pipeline\n",
    "\n",
    "Test NLP pipeline for dependency parsing and semantic role labeling in German."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re\n",
    "import pandas as pd\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Stories From the Web\n",
    "\n",
    "Build web scraper for German stories about the pandemic. The stories are published on a webpage from the HSPV NRW (University of Applied Sciences for the police and public administration) and written by students as well as staff. For a general description, see: https://www.hspv.nrw.de/services/corona-krise/corona-geschichten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define URL and story page ids\n",
    "\n",
    "URL = \"https://www.hspv.nrw.de/nachrichten/artikel/corona-geschichten\"\n",
    "\n",
    "ID_STORIES = [\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\", \"13\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to retrieve text from webpages\n",
    "\n",
    "def get_text_from_web(url, ids):\n",
    "    docs = []\n",
    "\n",
    "    for id in ids:\n",
    "        new_page = urlopen(url + \"-\" + id).read()\n",
    "\n",
    "        new_soup = BeautifulSoup(new_page, 'html.parser')\n",
    "\n",
    "        for script in new_soup([\"script\", \"style\"]):\n",
    "            script.decompose()\n",
    "        \n",
    "        docs.append(list(new_soup.stripped_strings))\n",
    "    \n",
    "    return docs\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the relevant stories by removing text that is present in all documents (e.g., menu headers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract only text from stories\n",
    "\n",
    "def extract_story_text(docs):\n",
    "    new_docs = [[s for s in docs[0] if s not in docs[-1]]]\n",
    "\n",
    "    for doc in docs[1:]:\n",
    "        new_docs.append([s for s in doc if s not in docs[0]])\n",
    "    \n",
    "    return new_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = get_text_from_web(URL, ID_STORIES)\n",
    "\n",
    "short_docs = extract_story_text(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#WirmeisterndieKrise Der ganz normale Wahnsinn | HSPV NRW', 'Der ganz normale Wahnsinn', '05. Februar 2021', 'Ann-Katrin Vengels', 'Studienalltag in Zeiten von Corona', 'Ann-Katrin Vengels, Studentin der HSPV NRW am Studienort Mülheim an der Ruhr, berichtet aus ihrem Alltag zwischen Homeschooling, Kinderbetreuung und Online-Studium.', 'In den vergangenen Jahren habe ich die Frage nach meinem Befinden stets mit den Worten „Der normale Wahnsinn halt“\\xa0 beantwortet. Und ja, irgendwie ist der Wahnsinn tatsächlich normal geworden. Ich bin Mutter von zwei Kindern, meine Tochter ist 13 und mein Sohn sechs. Seit zehn Jahren bin ich verheiratet. 2019 habe ich mich dazu entschlossen, meinen Beruf aufzugeben und mich weiterzuentwickeln, weshalb ich mich für ein duales Bachelorstudium an der HSPV entschieden habe. Mittlerweile studiere ich im zweiten Studienjahr Polizeivollzugsdienst und bin Kommissaranwärterin.', 'Mein Ehemann (der inzwischen auch mein Kollege ist) und ich sind über die Jahre zu einem eingespielten Team geworden, das perfekt aufeinander eingestellt ist. Ein großer Pluspunkt, der definitiv eine wichtige Rolle bei meinem Berufswechsel gespielt hat. Als die Kinder schließlich groß genug waren und wir unser Haus gekauft hatten, sprach nichts mehr dagegen, sich beruflich neu zu orientieren – also wagte ich den Schritt. Der Studienplan war natürlich von Vorteil, denn der Verlauf der nächsten drei Jahre war absehbar und planbar. Mit der zugesicherten Unterstützung der Großeltern und der Familie konnte eigentlich nichts mehr schiefgehen.', 'Doch dann kamen die vorgezogenen Osterferien im vergangen Frühjahr. Die Einschulung im Sommer schien zu diesem Zeitpunkt noch gar nicht in Gefahr, denn alles wirkte irgendwie unwirklich und noch nicht besorgniserregend. Doch dann überschlugen sich die Ereignisse: Die Einschulung mit Abstand und Singverbot, der erste Corona-Fall in der Familie, der Vater, den man nicht auf der Intensivstation besuchen konnte, Geburtstage und Weihnachten im engsten Familienkreis – es kam mir vor wie ein Dauerlauf ohne wirkliches Ziel.']\n"
     ]
    }
   ],
   "source": [
    "print(short_docs[1][:9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependency Parsing and Named Entity Recognition\n",
    "\n",
    "Before running the pipeline, the pipeline must be installed, e.g., via:\n",
    "\n",
    "`python3 -m spacy download de_core_news_sm`\n",
    "\n",
    "For details on the pipeline, see: https://spacy.io/models/de.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load german nlp pipeline trained on news documents (sm = small size)\n",
    "\n",
    "nlp = spacy.load(\"de_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_stories(docs):\n",
    "    processed_docs = []\n",
    "    \n",
    "    for doc in docs:\n",
    "        processed_docs.append(nlp(\"\".join([s for s in short_docs[1]])))\n",
    "        \n",
    "    return processed_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs = analyse_stories(short_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From danlp_test notebook\n",
    "\n",
    "def print_results(doc):\n",
    "    analysis = []\n",
    "    for token in doc:\n",
    "        analysis.append({ \"text\": token.text, \"lemma\": token.lemma_, \"head\": token.head.i, \"dep\": token.dep_, \"pos\": token.pos_, \"ent\": token.ent_type_ })\n",
    "    return pd.DataFrame(analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>head</th>\n",
       "      <th>dep</th>\n",
       "      <th>pos</th>\n",
       "      <th>ent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>1</td>\n",
       "      <td>pnc</td>\n",
       "      <td>X</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WirmeisterndieKrise</td>\n",
       "      <td>WirmeisterndieKrise</td>\n",
       "      <td>1</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>X</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Der</td>\n",
       "      <td>der</td>\n",
       "      <td>5</td>\n",
       "      <td>nk</td>\n",
       "      <td>DET</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ganz</td>\n",
       "      <td>ganz</td>\n",
       "      <td>4</td>\n",
       "      <td>mo</td>\n",
       "      <td>ADV</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>normale</td>\n",
       "      <td>normale</td>\n",
       "      <td>5</td>\n",
       "      <td>nk</td>\n",
       "      <td>ADJ</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>694</td>\n",
       "      <td>punct</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>die</td>\n",
       "      <td>der</td>\n",
       "      <td>698</td>\n",
       "      <td>oa</td>\n",
       "      <td>PRON</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>wir</td>\n",
       "      <td>ich</td>\n",
       "      <td>698</td>\n",
       "      <td>sb</td>\n",
       "      <td>PRON</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>haben</td>\n",
       "      <td>haben</td>\n",
       "      <td>694</td>\n",
       "      <td>rc</td>\n",
       "      <td>VERB</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>683</td>\n",
       "      <td>punct</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    text                lemma  head    dep    pos  ent\n",
       "0                      #                    #     1    pnc      X     \n",
       "1    WirmeisterndieKrise  WirmeisterndieKrise     1   ROOT      X  ORG\n",
       "2                    Der                  der     5     nk    DET     \n",
       "3                   ganz                 ganz     4     mo    ADV     \n",
       "4                normale              normale     5     nk    ADJ     \n",
       "..                   ...                  ...   ...    ...    ...  ...\n",
       "695                    ,                    ,   694  punct  PUNCT     \n",
       "696                  die                  der   698     oa   PRON     \n",
       "697                  wir                  ich   698     sb   PRON     \n",
       "698                haben                haben   694     rc   VERB     \n",
       "699                    .                    .   683  punct  PUNCT     \n",
       "\n",
       "[700 rows x 6 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_analysis = print_results(processed_docs[0])\n",
    "print(nlp_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From danlp_test notebook\n",
    "\n",
    "def show_results(results_dict):\n",
    "    results_df = pd.DataFrame([{ \"key\": key, \"count\": results_dict[key], \"best value\": \"\"} \n",
    "                               for key in sorted(results_dict, key=lambda k: results_dict[k], reverse=True)])\n",
    "    best_keys = get_best_keys(results_df)\n",
    "    for i, row in results_df.iterrows():\n",
    "        if row[\"key\"] in best_keys:\n",
    "            results_df.at[i, \"best value\"] = \"yes\"\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From danlp_test notebook\n",
    "\n",
    "def get_best_keys(results_df):\n",
    "    best_count = -1\n",
    "    best_keys = []\n",
    "    for i, row in results_df.iterrows():\n",
    "        if row[\"count\"] > best_count:\n",
    "            best_count = row[\"count\"]\n",
    "            best_keys = [row[\"key\"]]\n",
    "        elif row[\"count\"] == best_count:\n",
    "            best_keys.append(row[\"key\"])\n",
    "    case_is_upper = []\n",
    "    for key in best_keys:\n",
    "        case_is_upper.append(re.search(r\"^[A-Z]\", key) != None)\n",
    "    if True in case_is_upper:\n",
    "        best_keys = [ best_keys[i] for i in range(0, len(best_keys)) if case_is_upper[i] ] \n",
    "    return best_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From danlp_test notebook\n",
    "\n",
    "def get_actors(nlp_table_df):\n",
    "    actors = {}\n",
    "    for i, row in nlp_table_df.iterrows():\n",
    "        if row[\"dep\"] == \"sb\":\n",
    "            actor = row[\"text\"]\n",
    "        else:\n",
    "            actor = \"\"\n",
    "        if actor != \"\":\n",
    "            if actor in actors:\n",
    "                actors[actor] += 1\n",
    "            else:\n",
    "                actors[actor] = 1\n",
    "    return actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From danlp_test notebook\n",
    "\n",
    "def get_locations(nlp_table_df):\n",
    "    locations = {}\n",
    "    for i, row in nlp_table_df.iterrows():\n",
    "        if row[\"ent\"] == \"LOC\":\n",
    "            location = row[\"text\"]\n",
    "        else:\n",
    "            location = \"\"\n",
    "        if location != \"\":\n",
    "            if location in locations:\n",
    "                locations[location] += 1\n",
    "            else:\n",
    "                locations[location] = 1\n",
    "    return locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From danlp_test notebook\n",
    "\n",
    "def get_actions(nlp_table_df):\n",
    "    actions = {}\n",
    "    for i, row in nlp_table_df.iterrows():\n",
    "        if row[\"pos\"] == \"VERB\" and re.search(\"[a-zA-Z]\", row[\"text\"]):\n",
    "            if row[\"text\"] in actions:\n",
    "                actions[row[\"text\"]] += 1\n",
    "            else:\n",
    "                actions[row[\"text\"]] = 1\n",
    "    return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>count</th>\n",
       "      <th>best value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ich</td>\n",
       "      <td>11</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wir</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>man</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>es</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wahnsinn</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>der</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Einschulung</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>können</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>VengelsStudienalltag</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ich</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    key  count best value\n",
       "0                   ich     11        yes\n",
       "1                   wir      5           \n",
       "2                   man      3           \n",
       "3                    es      3           \n",
       "4              Wahnsinn      2           \n",
       "5                   der      2           \n",
       "6           Einschulung      2           \n",
       "7                können      2           \n",
       "8  VengelsStudienalltag      1           \n",
       "9                   Ich      1           "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_results(get_actors(nlp_analysis)).loc[:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>count</th>\n",
       "      <th>best value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gebildet</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gibt</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>berichtet</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>beantwortet</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>verheiratet</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>entschlossen</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>aufzugeben</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>weiterzuentwickeln</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>entschieden</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>studiere</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  key  count best value\n",
       "0            gebildet      2        yes\n",
       "1                gibt      2        yes\n",
       "2           berichtet      1           \n",
       "3         beantwortet      1           \n",
       "4         verheiratet      1           \n",
       "5        entschlossen      1           \n",
       "6          aufzugeben      1           \n",
       "7  weiterzuentwickeln      1           \n",
       "8         entschieden      1           \n",
       "9            studiere      1           "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_results(get_actions(nlp_analysis)).loc[:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>count</th>\n",
       "      <th>best value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mülheim</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>an</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>der</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ruhr</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Studienplan</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lockdown</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lerngruppen</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sushi</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Kurs</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           key  count best value\n",
       "0      Mülheim      1        yes\n",
       "1           an      1           \n",
       "2          der      1           \n",
       "3         Ruhr      1        yes\n",
       "4  Studienplan      1        yes\n",
       "5     Lockdown      1        yes\n",
       "6  Lerngruppen      1        yes\n",
       "7        Sushi      1        yes\n",
       "8         Kurs      1        yes"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_results(get_locations(nlp_analysis)).loc[:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing\n",
    "1. Semantic role labeling\n",
    "2. Analysis of all stories\n",
    "3. Visualization"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ef1095abc5425b956665fdf6c5777e33a123796a065bd431132fec68f09fc7f0"
  },
  "kernelspec": {
   "display_name": "navigating-stories",
   "language": "python",
   "name": "navigating-stories"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
