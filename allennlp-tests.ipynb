{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "097cf9b2-c835-4d63-93e6-fb98636763f9",
   "metadata": {},
   "source": [
    "# AllenNLP tests\n",
    "\n",
    "Use AllenNLP's semantic role labeling in combination with manually written rules for extracting causal relations from political speeches. We found two limitations: only relations within a single sentence were found and complex relations involving understanding the sentence were hard to identify.\n",
    "\n",
    "Links:\n",
    "\n",
    "* software installation: https://github.com/allenai/allennlp (do not forget to install NLTK popular models)\n",
    "* software usage: https://demo.allennlp.org/semantic-role-labeling (tab: Model Usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4d59808-a18f-4dfe-970a-35ac0d46f573",
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.predictors.predictor import Predictor\n",
    "import allennlp_models.tagging\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "289eae14-db61-4df0-baec-41b07319a109",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erikt/anaconda3/envs/allennlp/lib/python3.7/site-packages/allennlp/tango/__init__.py:18: UserWarning: AllenNLP Tango is an experimental API and parts of it might change or disappear every time we release a new version.\n",
      "  \"AllenNLP Tango is an experimental API and parts of it might change or disappear \"\n",
      "2021-11-16 17:48:58,221 - INFO - allennlp.common.plugins - Plugin allennlp_models available\n",
      "2021-11-16 17:48:58,497 - INFO - cached_path - cache of https://storage.googleapis.com/allennlp-public-models/structured-prediction-srl-bert.2020.12.15.tar.gz is up-to-date\n",
      "2021-11-16 17:48:58,500 - INFO - allennlp.models.archival - loading archive file https://storage.googleapis.com/allennlp-public-models/structured-prediction-srl-bert.2020.12.15.tar.gz from cache at /home/erikt/.allennlp/cache/b5f1db011cc85691a5fa2bf29e055a712261a2e5d74a74edd7da2fffc98d4ab8.4c4ac7e06ec3d85631bd26b839f90b5a375d3ceeb43e3c74f1cf4758dcee2bb3\n",
      "2021-11-16 17:48:58,505 - INFO - allennlp.models.archival - extracting archive file /home/erikt/.allennlp/cache/b5f1db011cc85691a5fa2bf29e055a712261a2e5d74a74edd7da2fffc98d4ab8.4c4ac7e06ec3d85631bd26b839f90b5a375d3ceeb43e3c74f1cf4758dcee2bb3 to temp dir /tmp/tmpw1svv1bz\n",
      "2021-11-16 17:49:01,846 - INFO - allennlp.common.params - dataset_reader.type = srl\n",
      "2021-11-16 17:49:01,847 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
      "2021-11-16 17:49:01,847 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
      "2021-11-16 17:49:01,848 - INFO - allennlp.common.params - dataset_reader.manual_multiprocess_sharding = False\n",
      "2021-11-16 17:49:01,849 - INFO - allennlp.common.params - dataset_reader.token_indexers = None\n",
      "2021-11-16 17:49:01,850 - INFO - allennlp.common.params - dataset_reader.domain_identifier = None\n",
      "2021-11-16 17:49:01,851 - INFO - allennlp.common.params - dataset_reader.bert_model_name = bert-base-uncased\n",
      "2021-11-16 17:49:01,852 - INFO - allennlp.common.params - type = bert-base-uncased\n",
      "2021-11-16 17:49:15,314 - INFO - allennlp.common.params - dataset_reader.type = srl\n",
      "2021-11-16 17:49:15,315 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
      "2021-11-16 17:49:15,316 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
      "2021-11-16 17:49:15,317 - INFO - allennlp.common.params - dataset_reader.manual_multiprocess_sharding = False\n",
      "2021-11-16 17:49:15,320 - INFO - allennlp.common.params - dataset_reader.token_indexers = None\n",
      "2021-11-16 17:49:15,321 - INFO - allennlp.common.params - dataset_reader.domain_identifier = None\n",
      "2021-11-16 17:49:15,323 - INFO - allennlp.common.params - dataset_reader.bert_model_name = bert-base-uncased\n",
      "2021-11-16 17:49:15,324 - INFO - allennlp.common.params - type = bert-base-uncased\n",
      "2021-11-16 17:49:18,811 - INFO - allennlp.common.params - type = from_instances\n",
      "2021-11-16 17:49:18,812 - INFO - allennlp.data.vocabulary - Loading token dictionary from /tmp/tmpw1svv1bz/vocabulary.\n",
      "2021-11-16 17:49:18,815 - INFO - allennlp.common.params - model.type = srl_bert\n",
      "2021-11-16 17:49:18,815 - INFO - allennlp.common.params - model.regularizer = None\n",
      "2021-11-16 17:49:18,816 - INFO - allennlp.common.params - model.ddp_accelerator = None\n",
      "2021-11-16 17:49:18,817 - INFO - allennlp.common.params - model.bert_model = bert-base-uncased\n",
      "2021-11-16 17:49:18,820 - INFO - allennlp.common.params - type = bert-base-uncased\n",
      "2021-11-16 17:49:18,821 - INFO - allennlp.common.params - type = bert-base-uncased\n",
      "2021-11-16 17:49:18,822 - INFO - allennlp.common.params - model.embedding_dropout = 0.1\n",
      "2021-11-16 17:49:18,831 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7fc419f14d10>\n",
      "2021-11-16 17:49:18,833 - INFO - allennlp.common.params - model.label_smoothing = None\n",
      "2021-11-16 17:49:18,834 - INFO - allennlp.common.params - model.ignore_span_metric = False\n",
      "2021-11-16 17:49:18,834 - INFO - allennlp.common.params - model.srl_eval_path = /home/erikt/anaconda3/envs/allennlp/lib/python3.7/site-packages/allennlp_models/structured_prediction/tools/srl-eval.pl\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "2021-11-16 17:49:20,988 - INFO - allennlp.nn.initializers - Initializing parameters\n",
      "2021-11-16 17:49:20,990 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
      "2021-11-16 17:49:20,991 - INFO - allennlp.nn.initializers -    bert_model.embeddings.LayerNorm.bias\n",
      "2021-11-16 17:49:20,991 - INFO - allennlp.nn.initializers -    bert_model.embeddings.LayerNorm.weight\n",
      "2021-11-16 17:49:20,992 - INFO - allennlp.nn.initializers -    bert_model.embeddings.position_embeddings.weight\n",
      "2021-11-16 17:49:20,993 - INFO - allennlp.nn.initializers -    bert_model.embeddings.token_type_embeddings.weight\n",
      "2021-11-16 17:49:20,994 - INFO - allennlp.nn.initializers -    bert_model.embeddings.word_embeddings.weight\n",
      "2021-11-16 17:49:20,995 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "2021-11-16 17:49:20,995 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "2021-11-16 17:49:20,996 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.dense.bias\n",
      "2021-11-16 17:49:20,997 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.dense.weight\n",
      "2021-11-16 17:49:20,998 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.key.bias\n",
      "2021-11-16 17:49:21,004 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.key.weight\n",
      "2021-11-16 17:49:21,006 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.query.bias\n",
      "2021-11-16 17:49:21,008 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.query.weight\n",
      "2021-11-16 17:49:21,013 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.value.bias\n",
      "2021-11-16 17:49:21,014 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.value.weight\n",
      "2021-11-16 17:49:21,015 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.intermediate.dense.bias\n",
      "2021-11-16 17:49:21,016 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.intermediate.dense.weight\n",
      "2021-11-16 17:49:21,017 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.LayerNorm.bias\n",
      "2021-11-16 17:49:21,018 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.LayerNorm.weight\n",
      "2021-11-16 17:49:21,019 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.dense.bias\n",
      "2021-11-16 17:49:21,020 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.dense.weight\n",
      "2021-11-16 17:49:21,023 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "2021-11-16 17:49:21,025 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "2021-11-16 17:49:21,026 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.dense.bias\n",
      "2021-11-16 17:49:21,027 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.dense.weight\n",
      "2021-11-16 17:49:21,031 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.key.bias\n",
      "2021-11-16 17:49:21,032 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.key.weight\n",
      "2021-11-16 17:49:21,034 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.query.bias\n",
      "2021-11-16 17:49:21,035 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.query.weight\n",
      "2021-11-16 17:49:21,037 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.value.bias\n",
      "2021-11-16 17:49:21,039 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.value.weight\n",
      "2021-11-16 17:49:21,039 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.intermediate.dense.bias\n",
      "2021-11-16 17:49:21,042 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.intermediate.dense.weight\n",
      "2021-11-16 17:49:21,043 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.LayerNorm.bias\n",
      "2021-11-16 17:49:21,048 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.LayerNorm.weight\n",
      "2021-11-16 17:49:21,049 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.dense.bias\n",
      "2021-11-16 17:49:21,050 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.dense.weight\n",
      "2021-11-16 17:49:21,051 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "2021-11-16 17:49:21,052 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "2021-11-16 17:49:21,053 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.dense.bias\n",
      "2021-11-16 17:49:21,054 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.dense.weight\n",
      "2021-11-16 17:49:21,055 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.key.bias\n",
      "2021-11-16 17:49:21,056 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.key.weight\n",
      "2021-11-16 17:49:21,057 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.query.bias\n",
      "2021-11-16 17:49:21,058 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.query.weight\n",
      "2021-11-16 17:49:21,059 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.value.bias\n",
      "2021-11-16 17:49:21,060 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.value.weight\n",
      "2021-11-16 17:49:21,061 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.intermediate.dense.bias\n",
      "2021-11-16 17:49:21,063 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.intermediate.dense.weight\n",
      "2021-11-16 17:49:21,065 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.LayerNorm.bias\n",
      "2021-11-16 17:49:21,066 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.LayerNorm.weight\n",
      "2021-11-16 17:49:21,067 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.dense.bias\n",
      "2021-11-16 17:49:21,067 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.dense.weight\n",
      "2021-11-16 17:49:21,068 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "2021-11-16 17:49:21,069 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "2021-11-16 17:49:21,070 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.dense.bias\n",
      "2021-11-16 17:49:21,071 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.dense.weight\n",
      "2021-11-16 17:49:21,072 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.key.bias\n",
      "2021-11-16 17:49:21,073 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.key.weight\n",
      "2021-11-16 17:49:21,074 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.query.bias\n",
      "2021-11-16 17:49:21,075 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.query.weight\n",
      "2021-11-16 17:49:21,076 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.value.bias\n",
      "2021-11-16 17:49:21,077 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.value.weight\n",
      "2021-11-16 17:49:21,079 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.intermediate.dense.bias\n",
      "2021-11-16 17:49:21,080 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.intermediate.dense.weight\n",
      "2021-11-16 17:49:21,081 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.LayerNorm.bias\n",
      "2021-11-16 17:49:21,082 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.LayerNorm.weight\n",
      "2021-11-16 17:49:21,084 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.dense.bias\n",
      "2021-11-16 17:49:21,085 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.dense.weight\n",
      "2021-11-16 17:49:21,086 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "2021-11-16 17:49:21,087 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "2021-11-16 17:49:21,088 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.dense.bias\n",
      "2021-11-16 17:49:21,089 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.dense.weight\n",
      "2021-11-16 17:49:21,090 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.key.bias\n",
      "2021-11-16 17:49:21,092 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.key.weight\n",
      "2021-11-16 17:49:21,093 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.query.bias\n",
      "2021-11-16 17:49:21,094 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.query.weight\n",
      "2021-11-16 17:49:21,095 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.value.bias\n",
      "2021-11-16 17:49:21,097 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.value.weight\n",
      "2021-11-16 17:49:21,098 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.intermediate.dense.bias\n",
      "2021-11-16 17:49:21,100 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.intermediate.dense.weight\n",
      "2021-11-16 17:49:21,103 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.LayerNorm.bias\n",
      "2021-11-16 17:49:21,104 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.LayerNorm.weight\n",
      "2021-11-16 17:49:21,105 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.dense.bias\n",
      "2021-11-16 17:49:21,106 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.dense.weight\n",
      "2021-11-16 17:49:21,108 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "2021-11-16 17:49:21,109 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "2021-11-16 17:49:21,111 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.dense.bias\n",
      "2021-11-16 17:49:21,112 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.dense.weight\n",
      "2021-11-16 17:49:21,113 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.key.bias\n",
      "2021-11-16 17:49:21,115 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.key.weight\n",
      "2021-11-16 17:49:21,116 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.query.bias\n",
      "2021-11-16 17:49:21,117 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.query.weight\n",
      "2021-11-16 17:49:21,118 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.value.bias\n",
      "2021-11-16 17:49:21,120 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.value.weight\n",
      "2021-11-16 17:49:21,121 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.intermediate.dense.bias\n",
      "2021-11-16 17:49:21,121 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.intermediate.dense.weight\n",
      "2021-11-16 17:49:21,122 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.LayerNorm.bias\n",
      "2021-11-16 17:49:21,123 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.LayerNorm.weight\n",
      "2021-11-16 17:49:21,124 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.dense.bias\n",
      "2021-11-16 17:49:21,125 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.dense.weight\n",
      "2021-11-16 17:49:21,126 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "2021-11-16 17:49:21,127 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "2021-11-16 17:49:21,128 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.dense.bias\n",
      "2021-11-16 17:49:21,130 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.dense.weight\n",
      "2021-11-16 17:49:21,133 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.key.bias\n",
      "2021-11-16 17:49:21,134 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.key.weight\n",
      "2021-11-16 17:49:21,135 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.query.bias\n",
      "2021-11-16 17:49:21,136 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.query.weight\n",
      "2021-11-16 17:49:21,137 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.value.bias\n",
      "2021-11-16 17:49:21,138 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.value.weight\n",
      "2021-11-16 17:49:21,139 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.intermediate.dense.bias\n",
      "2021-11-16 17:49:21,140 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.intermediate.dense.weight\n",
      "2021-11-16 17:49:21,141 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.LayerNorm.bias\n",
      "2021-11-16 17:49:21,143 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.LayerNorm.weight\n",
      "2021-11-16 17:49:21,145 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.dense.bias\n",
      "2021-11-16 17:49:21,146 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.dense.weight\n",
      "2021-11-16 17:49:21,148 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "2021-11-16 17:49:21,149 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "2021-11-16 17:49:21,150 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.dense.bias\n",
      "2021-11-16 17:49:21,151 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.dense.weight\n",
      "2021-11-16 17:49:21,152 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.key.bias\n",
      "2021-11-16 17:49:21,153 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.key.weight\n",
      "2021-11-16 17:49:21,155 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.query.bias\n",
      "2021-11-16 17:49:21,156 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.query.weight\n",
      "2021-11-16 17:49:21,157 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.value.bias\n",
      "2021-11-16 17:49:21,158 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.value.weight\n",
      "2021-11-16 17:49:21,159 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.intermediate.dense.bias\n",
      "2021-11-16 17:49:21,161 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.intermediate.dense.weight\n",
      "2021-11-16 17:49:21,162 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.LayerNorm.bias\n",
      "2021-11-16 17:49:21,164 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.LayerNorm.weight\n",
      "2021-11-16 17:49:21,166 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.dense.bias\n",
      "2021-11-16 17:49:21,167 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.dense.weight\n",
      "2021-11-16 17:49:21,168 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "2021-11-16 17:49:21,169 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "2021-11-16 17:49:21,170 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.dense.bias\n",
      "2021-11-16 17:49:21,171 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.dense.weight\n",
      "2021-11-16 17:49:21,173 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.key.bias\n",
      "2021-11-16 17:49:21,174 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.key.weight\n",
      "2021-11-16 17:49:21,176 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.query.bias\n",
      "2021-11-16 17:49:21,177 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.query.weight\n",
      "2021-11-16 17:49:21,178 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.value.bias\n",
      "2021-11-16 17:49:21,179 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.value.weight\n",
      "2021-11-16 17:49:21,181 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.intermediate.dense.bias\n",
      "2021-11-16 17:49:21,184 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.intermediate.dense.weight\n",
      "2021-11-16 17:49:21,186 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.LayerNorm.bias\n",
      "2021-11-16 17:49:21,187 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.LayerNorm.weight\n",
      "2021-11-16 17:49:21,188 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.dense.bias\n",
      "2021-11-16 17:49:21,190 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.dense.weight\n",
      "2021-11-16 17:49:21,192 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "2021-11-16 17:49:21,193 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "2021-11-16 17:49:21,194 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.dense.bias\n",
      "2021-11-16 17:49:21,196 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.dense.weight\n",
      "2021-11-16 17:49:21,198 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.key.bias\n",
      "2021-11-16 17:49:21,199 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.key.weight\n",
      "2021-11-16 17:49:21,200 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.query.bias\n",
      "2021-11-16 17:49:21,201 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.query.weight\n",
      "2021-11-16 17:49:21,202 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.value.bias\n",
      "2021-11-16 17:49:21,203 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.value.weight\n",
      "2021-11-16 17:49:21,204 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.intermediate.dense.bias\n",
      "2021-11-16 17:49:21,205 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.intermediate.dense.weight\n",
      "2021-11-16 17:49:21,206 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.LayerNorm.bias\n",
      "2021-11-16 17:49:21,207 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.LayerNorm.weight\n",
      "2021-11-16 17:49:21,208 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.dense.bias\n",
      "2021-11-16 17:49:21,210 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.dense.weight\n",
      "2021-11-16 17:49:21,211 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "2021-11-16 17:49:21,212 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "2021-11-16 17:49:21,213 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.dense.bias\n",
      "2021-11-16 17:49:21,214 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.dense.weight\n",
      "2021-11-16 17:49:21,217 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.key.bias\n",
      "2021-11-16 17:49:21,218 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.key.weight\n",
      "2021-11-16 17:49:21,219 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.query.bias\n",
      "2021-11-16 17:49:21,220 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.query.weight\n",
      "2021-11-16 17:49:21,221 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.value.bias\n",
      "2021-11-16 17:49:21,222 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.value.weight\n",
      "2021-11-16 17:49:21,223 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.intermediate.dense.bias\n",
      "2021-11-16 17:49:21,225 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.intermediate.dense.weight\n",
      "2021-11-16 17:49:21,227 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.LayerNorm.bias\n",
      "2021-11-16 17:49:21,229 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.LayerNorm.weight\n",
      "2021-11-16 17:49:21,231 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.dense.bias\n",
      "2021-11-16 17:49:21,234 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.dense.weight\n",
      "2021-11-16 17:49:21,235 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "2021-11-16 17:49:21,236 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "2021-11-16 17:49:21,237 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.dense.bias\n",
      "2021-11-16 17:49:21,238 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.dense.weight\n",
      "2021-11-16 17:49:21,239 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.key.bias\n",
      "2021-11-16 17:49:21,240 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.key.weight\n",
      "2021-11-16 17:49:21,241 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.query.bias\n",
      "2021-11-16 17:49:21,242 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.query.weight\n",
      "2021-11-16 17:49:21,243 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.value.bias\n",
      "2021-11-16 17:49:21,245 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.value.weight\n",
      "2021-11-16 17:49:21,246 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.intermediate.dense.bias\n",
      "2021-11-16 17:49:21,247 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.intermediate.dense.weight\n",
      "2021-11-16 17:49:21,248 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.LayerNorm.bias\n",
      "2021-11-16 17:49:21,250 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.LayerNorm.weight\n",
      "2021-11-16 17:49:21,252 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.dense.bias\n",
      "2021-11-16 17:49:21,253 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.dense.weight\n",
      "2021-11-16 17:49:21,254 - INFO - allennlp.nn.initializers -    bert_model.pooler.dense.bias\n",
      "2021-11-16 17:49:21,255 - INFO - allennlp.nn.initializers -    bert_model.pooler.dense.weight\n",
      "2021-11-16 17:49:21,256 - INFO - allennlp.nn.initializers -    tag_projection_layer.bias\n",
      "2021-11-16 17:49:21,257 - INFO - allennlp.nn.initializers -    tag_projection_layer.weight\n",
      "2021-11-16 17:49:21,738 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /tmp/tmpw1svv1bz\n"
     ]
    }
   ],
   "source": [
    "srl_predictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/structured-prediction-srl-bert.2020.12.15.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "022436b0-d987-4c02-9ec8-6c8b47489dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLOR_CONCEPT_1 = 1\n",
    "COLOR_CONCEPT_2 = 4\n",
    "COLOR_CONTENT_RELATION_EXPLANATION = 0\n",
    "NO_COLOR = -1\n",
    "RELATION_VERBS = [ \"allowed\", \"avoid\", \"contribute\", \"eliminated\", \"entailed\", \"eroded\", \"failed\", \"weakened\", ]\n",
    "\n",
    "\n",
    "def strip_tag(token):\n",
    "    if len(token) > 1:\n",
    "        if re.search(\"^\\[\", token):\n",
    "            token = re.sub(\"^\\[\", \"\", token)\n",
    "            token = re.sub(\":$\", \"\", token)\n",
    "        token = re.sub(\"\\]$\", \"\", token)\n",
    "    return token\n",
    "\n",
    "\n",
    "def print_with_color(string, color_code):\n",
    "    print(f\"\\x1b[1;3{color_code};47m{string} \\x1b[m\", end=\"\")\n",
    "    \n",
    "    \n",
    "def print_argm_prp(tokens, arguments, i):\n",
    "    if i in arguments[\"ARGM-PRP\"]:\n",
    "        color_code = COLOR_CONCEPT_2\n",
    "    elif \"V\" in arguments and i in arguments[\"V\"]:\n",
    "        color_code = COLOR_CONCEPT_1\n",
    "    elif \"ARG0\" in arguments and i in arguments[\"ARG0\"]:\n",
    "        color_code = COLOR_CONCEPT_1\n",
    "    elif \"ARG1\" in arguments and i in arguments[\"ARG1\"]:\n",
    "        color_code = COLOR_CONCEPT_1\n",
    "    elif \"ARG2\" in arguments and i in arguments[\"ARG2\"]:\n",
    "        color_code = COLOR_CONCEPT_1\n",
    "    else:\n",
    "        color_code = NO_COLOR\n",
    "    if color_code >= 0:\n",
    "        print_with_color(tokens[i], color_code)\n",
    "    else:\n",
    "        print(f\"{tokens[i]} \", end=\"\")\n",
    "        \n",
    "\n",
    "def print_v(tokens, arguments, i):\n",
    "    if \"V\" in arguments and i in arguments[\"V\"]:\n",
    "        color_code = COLOR_CONTENT_RELATION_EXPLANATION\n",
    "    elif \"ARG0\" in arguments and i in arguments[\"ARG0\"]:\n",
    "        color_code = COLOR_CONCEPT_1\n",
    "    elif \"ARG1\" in arguments and i in arguments[\"ARG1\"]:\n",
    "        color_code = COLOR_CONCEPT_2\n",
    "    elif \"ARG2\" in arguments and i in arguments[\"ARG2\"]:\n",
    "        color_code = COLOR_CONCEPT_2\n",
    "    else:\n",
    "        color_code = NO_COLOR\n",
    "    if color_code >= 0:\n",
    "        print_with_color(tokens[i], color_code)\n",
    "    else:\n",
    "        print(f\"{tokens[i]} \", end=\"\")\n",
    "\n",
    "        \n",
    "def pretty_print(analyzed_sentence):\n",
    "    arguments = {}\n",
    "    tokens = analyzed_sentence.split()\n",
    "    current_argument = \"\"\n",
    "    for i in range(0, len(tokens)):\n",
    "        if re.search(\"^\\[\", tokens[i]):\n",
    "            current_argument = strip_tag(tokens[i])\n",
    "        if current_argument != \"\":\n",
    "            if current_argument in arguments:\n",
    "                arguments[current_argument].append(i)\n",
    "            else:\n",
    "                arguments[current_argument] = [i]\n",
    "        if re.search(\"\\]$\", tokens[i]):\n",
    "            current_argument = \"\"\n",
    "    for i in range(0, len(tokens)):\n",
    "        if \"ARGM-PRP\" in arguments:\n",
    "            print_argm_prp(tokens, arguments, i)\n",
    "        elif \"V\" in arguments and strip_tag(tokens[arguments[\"V\"][-1]]) in RELATION_VERBS:\n",
    "            print_v(tokens, arguments, i)\n",
    "        else:\n",
    "            print(f\"{tokens[i]} \", end=\"\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3057805e-406f-48e5-82f2-b57713e6c38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(sentence):\n",
    "    analysis = srl_predictor.predict(sentence=sentence)\n",
    "    for verb_data in analysis['verbs']:\n",
    "        pretty_print(verb_data['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1011a94-4b99-445b-a402-8d8da2b2c102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ARG0: You] , [ARGM-LOC: in Greece] , [ARGM-MNR: with our support] , [V: need] [ARG1: to rebuild your country , your structures , your administration , your economy to increase the competitiveness of Greece] . \n",
      "\u001b[1;31;47m[ARG0: \u001b[m\u001b[1;31;47mYou] \u001b[m, in Greece , with our support , need to \u001b[1;31;47m[V: \u001b[m\u001b[1;31;47mrebuild] \u001b[m\u001b[1;31;47m[ARG1: \u001b[m\u001b[1;31;47myour \u001b[m\u001b[1;31;47mcountry \u001b[m\u001b[1;31;47m, \u001b[m\u001b[1;31;47myour \u001b[m\u001b[1;31;47mstructures \u001b[m\u001b[1;31;47m, \u001b[m\u001b[1;31;47myour \u001b[m\u001b[1;31;47madministration \u001b[m\u001b[1;31;47m, \u001b[m\u001b[1;31;47myour \u001b[m\u001b[1;31;47meconomy] \u001b[m\u001b[1;34;47m[ARGM-PRP: \u001b[m\u001b[1;34;47mto \u001b[m\u001b[1;34;47mincrease \u001b[m\u001b[1;34;47mthe \u001b[m\u001b[1;34;47mcompetitiveness \u001b[m\u001b[1;34;47mof \u001b[m\u001b[1;34;47mGreece] \u001b[m. \n",
      "You , in Greece , with our support , need to rebuild your country , your structures , your administration , your economy to [V: increase] [ARG1: the competitiveness of Greece] . \n"
     ]
    }
   ],
   "source": [
    "analyze(\"You, in Greece, with our support, need to rebuild your country, your structures, your administration, your economy to increase the competitiveness of Greece.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ed79018-85a0-45fb-9d5c-2f1947602cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ARGM-DIS: And] [ARG1: the best hope of a return to growth and job creation] [V: is] [ARG2: inside the euro area] . \n"
     ]
    }
   ],
   "source": [
    "analyze(\"And the best hope of a return to growth and job creation is inside the euro area.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da62399a-2a30-4bfd-a4eb-ce2215579c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To [V: conclude] , let me say a few words on the euro area more generally . \n",
      "\u001b[1;34;47m[ARGM-PRP: \u001b[m\u001b[1;34;47mTo \u001b[m\u001b[1;34;47mconclude] \u001b[m, \u001b[1;31;47m[V: \u001b[m\u001b[1;31;47mlet] \u001b[m\u001b[1;31;47m[ARG1: \u001b[m\u001b[1;31;47mme \u001b[m\u001b[1;31;47msay \u001b[m\u001b[1;31;47ma \u001b[m\u001b[1;31;47mfew \u001b[m\u001b[1;31;47mwords \u001b[m\u001b[1;31;47mon \u001b[m\u001b[1;31;47mthe \u001b[m\u001b[1;31;47meuro \u001b[m\u001b[1;31;47marea \u001b[m\u001b[1;31;47mmore \u001b[m\u001b[1;31;47mgenerally] \u001b[m. \n",
      "To conclude , let [ARG0: me] [V: say] [ARG1: a few words] [ARGM-LOC: on the euro area] [ARGM-ADV: more generally] . \n"
     ]
    }
   ],
   "source": [
    "analyze(\"To conclude, let me say a few words on the euro area more generally.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d41d16d-acbf-4da7-9afe-0992057f9fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We [V: have] taken important , fundamental decisions over the last couple of months to safeguard the stability of the euro area , and indeed we are now in the phase of implementation . \n",
      "\u001b[1;31;47m[ARG0: \u001b[m\u001b[1;31;47mWe] \u001b[mhave \u001b[1;31;47m[V: \u001b[m\u001b[1;31;47mtaken] \u001b[m\u001b[1;31;47m[ARG1: \u001b[m\u001b[1;31;47mimportant \u001b[m\u001b[1;31;47m, \u001b[m\u001b[1;31;47mfundamental \u001b[m\u001b[1;31;47mdecisions] \u001b[m[ARGM-TMP: over the last couple of months] \u001b[1;34;47m[ARGM-PRP: \u001b[m\u001b[1;34;47mto \u001b[m\u001b[1;34;47msafeguard \u001b[m\u001b[1;34;47mthe \u001b[m\u001b[1;34;47mstability \u001b[m\u001b[1;34;47mof \u001b[m\u001b[1;34;47mthe \u001b[m\u001b[1;34;47meuro \u001b[m\u001b[1;34;47marea] \u001b[m, and indeed we are now in the phase of implementation . \n",
      "[ARG0: We] have taken important , fundamental decisions over the last couple of months to [V: safeguard] [ARG1: the stability of the euro area] , and indeed we are now in the phase of implementation . \n",
      "We have taken important , fundamental decisions over the last couple of months to safeguard the stability of the euro area , and [ARGM-ADV: indeed] [ARG1: we] [V: are] [ARGM-TMP: now] [ARG2: in the phase of implementation] . \n"
     ]
    }
   ],
   "source": [
    "analyze(\"We have taken important, fundamental decisions over the last couple of months to safeguard the stability of the euro area, and indeed we are now in the phase of implementation. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cc28fe0-2fd8-40f0-bb47-e66a0dbc7822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A number of governments [V: have] embarked on a path of reform and fiscal consolidation that was unthinkable only very recently , and they have taken important decisions and I encourage them to keep this determination . \n",
      "[ARG0: A number of governments] have [V: embarked] [ARG1: on a path of reform and fiscal consolidation that was unthinkable only very recently] , and they have taken important decisions and I encourage them to keep this determination . \n",
      "A number of governments have embarked on [ARG1: a path of reform and fiscal consolidation] [R-ARG1: that] [V: was] [ARG2: unthinkable] [ARGM-TMP: only very recently] , and they have taken important decisions and I encourage them to keep this determination . \n",
      "A number of governments have embarked on a path of reform and fiscal consolidation that was unthinkable only very recently , and they [V: have] taken important decisions and I encourage them to keep this determination . \n",
      "A number of governments have embarked on a path of reform and fiscal consolidation that was unthinkable only very recently , and [ARG0: they] have [V: taken] [ARG1: important decisions] and I encourage them to keep this determination . \n",
      "A number of governments have embarked on a path of reform and fiscal consolidation that was unthinkable only very recently , and they have taken important decisions and [ARG0: I] [V: encourage] [ARG1: them] [ARG2: to keep this determination] . \n",
      "A number of governments have embarked on a path of reform and fiscal consolidation that was unthinkable only very recently , and they have taken important decisions and I encourage [ARG0: them] to [V: keep] [ARG1: this determination] . \n"
     ]
    }
   ],
   "source": [
    "analyze(\"\"\"A number of governments have embarked on a path of reform and fiscal consolidation that was unthinkable only very recently, \n",
    "        and they have taken important decisions and I encourage them to keep this determination.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3608204a-2217-4403-896d-10b5b02f0f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These reforms [V: are] now being implemented and this effort must continue with credibility , with consistency , with coherence over time . \n",
      "These reforms are now [V: being] implemented and this effort must continue with credibility , with consistency , with coherence over time . \n",
      "[ARG1: These reforms] are [ARGM-TMP: now] being [V: implemented] and this effort must continue with credibility , with consistency , with coherence over time . \n",
      "These reforms are now being implemented and this effort [V: must] continue with credibility , with consistency , with coherence over time . \n",
      "These reforms are now being implemented and [ARG1: this effort] [ARGM-MOD: must] [V: continue] [ARGM-MNR: with credibility , with consistency , with coherence over time] . \n"
     ]
    }
   ],
   "source": [
    "analyze(\"These reforms are now being implemented and this effort must continue with credibility, with consistency, with coherence over time. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21df66a7-1c41-43a5-a953-c40ac915e150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As [ARG0: we] [V: said] there will not be magic solutions . \n",
      "As we said there [V: will] not be magic solutions . \n",
      "[ARGM-ADV: As we said] there [ARGM-MOD: will] [ARGM-NEG: not] [V: be] [ARG1: magic solutions] . \n"
     ]
    }
   ],
   "source": [
    "analyze(\"As we said there will not be magic solutions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0e08438-0804-4afb-a771-5f848fd6278e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ARG0: We] [V: need] [ARG1: sustained efforts and determination] . \n"
     ]
    }
   ],
   "source": [
    "analyze(\"We need sustained efforts and determination.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89cd2b3d-b1ad-4a4a-b690-6d86877ef10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At the same time , the [V: existing] [ARG1: financial backstops] are being used as necessary . \n",
      "At the same time , the existing financial backstops [V: are] being used as necessary . \n",
      "At the same time , the existing financial backstops are [V: being] used as necessary . \n",
      "[ARGM-TMP: At the same time] , [ARG1: the existing financial backstops] are being [V: used] [ARGM-MNR: as necessary] . \n"
     ]
    }
   ],
   "source": [
    "analyze(\"At the same time, the existing financial backstops are being used as necessary.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9bbefe2-4e57-495d-886c-d76f4b240d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most recently , the financial assistance to the recapitalisation of Spanish banks [V: has] been agreed and is ready for implementation . \n",
      "Most recently , the financial assistance to the recapitalisation of Spanish banks has [V: been] agreed and is ready for implementation . \n",
      "[ARGM-TMP: Most recently] , [ARG1: the financial assistance to the recapitalisation of Spanish banks] has been [V: agreed] and is ready for implementation . \n",
      "[ARGM-TMP: Most recently] , [ARG1: the financial assistance to the recapitalisation of Spanish banks] has been agreed and [V: is] [ARG2: ready for implementation] . \n"
     ]
    }
   ],
   "source": [
    "analyze(\"Most recently, the financial assistance to the recapitalisation of Spanish banks has been agreed and is ready for implementation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "985bbeaa-a66b-4ee9-8bef-a512bca9cbb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V: Giving] [ARG2: to the ECB] [ARG1: the ultimate responsibility for supervision of banks in the euro area] will decisively contribute to increase confidence between the banks and in this way increase the financial stability in the euro area . \n",
      "Giving to the ECB the ultimate responsibility for supervision of banks in the euro area [V: will] decisively contribute to increase confidence between the banks and in this way increase the financial stability in the euro area . \n",
      "[ARGM-PRD: Giving to the ECB the ultimate responsibility for supervision of banks in the euro area] [ARGM-MOD: will] [ARGM-MNR: decisively] \u001b[1;30;47m[V: \u001b[m\u001b[1;30;47mcontribute] \u001b[m\u001b[1;34;47m[ARG2: \u001b[m\u001b[1;34;47mto \u001b[m\u001b[1;34;47mincrease \u001b[m\u001b[1;34;47mconfidence \u001b[m\u001b[1;34;47mbetween \u001b[m\u001b[1;34;47mthe \u001b[m\u001b[1;34;47mbanks \u001b[m\u001b[1;34;47mand \u001b[m\u001b[1;34;47min \u001b[m\u001b[1;34;47mthis \u001b[m\u001b[1;34;47mway \u001b[m\u001b[1;34;47mincrease \u001b[m\u001b[1;34;47mthe \u001b[m\u001b[1;34;47mfinancial \u001b[m\u001b[1;34;47mstability \u001b[m\u001b[1;34;47min \u001b[m\u001b[1;34;47mthe \u001b[m\u001b[1;34;47meuro \u001b[m\u001b[1;34;47marea] \u001b[m. \n",
      "Giving to the ECB the ultimate responsibility for supervision of banks in the euro area will decisively contribute to [V: increase] [ARG1: confidence between the banks] and in this way increase the financial stability in the euro area . \n",
      "Giving to the ECB the ultimate responsibility for supervision of banks in the euro area will decisively contribute to increase confidence between the banks and [ARGM-MNR: in this way] [V: increase] [ARG1: the financial stability in the euro area] . \n"
     ]
    }
   ],
   "source": [
    "analyze(\"\"\"Giving to the ECB the ultimate responsibility for supervision of banks in the euro area will decisively contribute to increase confidence between the banks \n",
    "           and in this way increase the financial stability in the euro area.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e74993ff-629f-4444-a3e9-95d936869c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ARGM-DIS: Second] , [ARG1: Germany] [V: is] [ARG2: acutely aware of the need to tackle the root causes and not just the symptoms of the crisis] . \n",
      "Second , Germany is acutely aware of the need to [V: tackle] [ARG1: the root causes and not just the symptoms of the crisis] . \n"
     ]
    }
   ],
   "source": [
    "analyze(\"Second, Germany is acutely aware of the need to tackle the root causes and not just the symptoms of the crisis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ae9f741-68e7-4ae0-b1de-5ecb8723f609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ARG1: This] [V: is] [ARG2: why it is pressing strongly for institutional reforms of the EMU framework plus structural reforms and budgetary discipline in the member states] . \n",
      "This is why it [V: is] pressing strongly for institutional reforms of the EMU framework plus structural reforms and budgetary discipline in the member states . \n",
      "This is [ARGM-CAU: why] [ARG0: it] is [V: pressing] [ARGM-MNR: strongly] [ARG2: for institutional reforms of the EMU framework plus structural reforms and budgetary discipline in the member states] . \n"
     ]
    }
   ],
   "source": [
    "analyze(\"This is why it is pressing strongly for institutional reforms of the EMU framework plus structural reforms and budgetary discipline in the member states.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2040f38a-a5a9-4985-bec9-5407b44785a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;47m[ARG0: \u001b[m\u001b[1;31;47mThe \u001b[m\u001b[1;31;47mintroduction \u001b[m\u001b[1;31;47mof \u001b[m\u001b[1;31;47mthe \u001b[m\u001b[1;31;47meuro] \u001b[m\u001b[1;30;47m[V: \u001b[m\u001b[1;30;47meliminated] \u001b[m\u001b[1;34;47m[ARG1: \u001b[m\u001b[1;34;47mexchange \u001b[m\u001b[1;34;47mrate \u001b[m\u001b[1;34;47mrisks] \u001b[m. \n"
     ]
    }
   ],
   "source": [
    "analyze(\"The introduction of the euro eliminated exchange rate risks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12883bd7-edda-4218-9303-1765e061dc10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ARG1: Another implication of the euro area 's single monetary policy] [V: is] [ARG2: that the key interest rates are set for the currency bloc as a whole] . \n",
      "Another implication of the euro area 's single monetary policy is that the key interest rates [V: are] set for the currency bloc as a whole . \n",
      "Another implication of the euro area 's single monetary policy is that [ARG1: the key interest rates] are [V: set] [ARGM-ADV: for the currency bloc as a whole] . \n"
     ]
    }
   ],
   "source": [
    "analyze(\"Another implication of the euro area's single monetary policy is that the key interest rates are set for the currency bloc as a whole.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f0a3592-99cf-48eb-acdd-9cfd79fff765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ARG1: One risk] [V: is] [ARG2: the temptation for governments to overborrow because the economic costs of excessive public debt , for example higher interest rates , can be more easily shifted to other member states] . \n",
      "One risk is the temptation for governments to overborrow because the economic costs of excessive public debt , for example higher interest rates , [V: can] be more easily shifted to other member states . \n",
      "One risk is the temptation for governments to overborrow because the economic costs of excessive public debt , for example higher interest rates , can [V: be] more easily shifted to other member states . \n",
      "One risk is the temptation for governments to overborrow because [ARG1: the economic costs of excessive public debt , for example higher interest rates] , [ARGM-MOD: can] be [ARGM-MNR: more easily] [V: shifted] [ARG2: to other member states] . \n"
     ]
    }
   ],
   "source": [
    "analyze(\"\"\"One risk is the temptation for governments to overborrow because the economic costs of excessive public debt, \n",
    "           for example higher interest rates, can be more easily shifted to other member states.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d9960a6-24ea-4ee9-b260-6112c96cd9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ARG0: Even Germany] [V: ran] up [ARG1: excessive deficits] [ARGM-TMP: for a few years] and , even worse , championed a reform of the SGP which ultimately further weakened the application of the fiscal rules . \n",
      "[ARG0: Even Germany] ran up excessive deficits for a few years and , [ARGM-ADV: even worse] , [V: championed] [ARG1: a reform of the SGP which ultimately further weakened the application of the fiscal rules] . \n",
      "Even Germany ran up excessive deficits for a few years and , even worse , championed \u001b[1;31;47m[ARG0: \u001b[m\u001b[1;31;47ma \u001b[m\u001b[1;31;47mreform \u001b[m\u001b[1;31;47mof \u001b[m\u001b[1;31;47mthe \u001b[m\u001b[1;31;47mSGP] \u001b[m[R-ARG0: which] [ARGM-TMP: ultimately] \u001b[1;34;47m[ARG2: \u001b[m\u001b[1;34;47mfurther] \u001b[m\u001b[1;30;47m[V: \u001b[m\u001b[1;30;47mweakened] \u001b[m\u001b[1;34;47m[ARG1: \u001b[m\u001b[1;34;47mthe \u001b[m\u001b[1;34;47mapplication \u001b[m\u001b[1;34;47mof \u001b[m\u001b[1;34;47mthe \u001b[m\u001b[1;34;47mfiscal \u001b[m\u001b[1;34;47mrules] \u001b[m. \n"
     ]
    }
   ],
   "source": [
    "analyze(\"Even Germany ran up excessive deficits for a few years and, even worse, championed a reform of the SGP which ultimately further weakened the application of the fiscal rules.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1d20c14-9a56-4456-8abb-6dd8debb1b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ARGM-DIS: However] , \u001b[1;34;47m[ARG1: \u001b[m\u001b[1;34;47mthe \u001b[m\u001b[1;34;47mEMU \u001b[m\u001b[1;34;47mframework] \u001b[mnot only \u001b[1;30;47m[V: \u001b[m\u001b[1;30;47mfailed] \u001b[m\u001b[1;34;47m[ARG2: \u001b[m\u001b[1;34;47mto \u001b[m\u001b[1;34;47mavoid \u001b[m\u001b[1;34;47mexcessive \u001b[m\u001b[1;34;47mdeficits] \u001b[m, it was also unable to prevent the build - up of macroeconomic imbalances within the euro area . \n",
      "However , \u001b[1;31;47m[ARG0: \u001b[m\u001b[1;31;47mthe \u001b[m\u001b[1;31;47mEMU \u001b[m\u001b[1;31;47mframework] \u001b[mnot only failed to \u001b[1;30;47m[V: \u001b[m\u001b[1;30;47mavoid] \u001b[m\u001b[1;34;47m[ARG1: \u001b[m\u001b[1;34;47mexcessive \u001b[m\u001b[1;34;47mdeficits] \u001b[m, it was also unable to prevent the build - up of macroeconomic imbalances within the euro area . \n",
      "However , the EMU framework not only failed to avoid excessive deficits , [ARG1: it] [V: was] [ARGM-ADV: also] [ARG2: unable to prevent the build - up of macroeconomic imbalances within the euro area] . \n",
      "However , the EMU framework not only failed to avoid excessive deficits , [ARG0: it] was also unable to [V: prevent] [ARG1: the build - up of macroeconomic imbalances within the euro area] . \n"
     ]
    }
   ],
   "source": [
    "analyze(\"However, the EMU framework not only failed to avoid excessive deficits, it was also unable to prevent the build-up of macroeconomic imbalances within the euro area.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "931baf3e-958f-4ad6-a998-a4f8ea2cfcec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The [V: resulting] [ARG2: increase] in domestic inflation and wages eroded the competitiveness of the countries concerned and increased their dependence on capital imports . \n",
      "\u001b[1;31;47m[ARG0: \u001b[m\u001b[1;31;47mThe \u001b[m\u001b[1;31;47mresulting \u001b[m\u001b[1;31;47mincrease \u001b[m\u001b[1;31;47min \u001b[m\u001b[1;31;47mdomestic \u001b[m\u001b[1;31;47minflation \u001b[m\u001b[1;31;47mand \u001b[m\u001b[1;31;47mwages] \u001b[m\u001b[1;30;47m[V: \u001b[m\u001b[1;30;47meroded] \u001b[m\u001b[1;34;47m[ARG1: \u001b[m\u001b[1;34;47mthe \u001b[m\u001b[1;34;47mcompetitiveness \u001b[m\u001b[1;34;47mof \u001b[m\u001b[1;34;47mthe \u001b[m\u001b[1;34;47mcountries \u001b[m\u001b[1;34;47mconcerned] \u001b[mand increased their dependence on capital imports . \n",
      "The resulting increase in domestic inflation and wages eroded the competitiveness of [ARG1: the countries] [V: concerned] and increased their dependence on capital imports . \n",
      "[ARG0: The resulting increase in domestic inflation and wages] eroded the competitiveness of the countries concerned and [V: increased] [ARG1: their dependence on capital imports] . \n"
     ]
    }
   ],
   "source": [
    "analyze(\"The resulting increase in domestic inflation and wages eroded the competitiveness of the countries concerned and increased their dependence on capital imports.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87956f23-b8ce-48ff-8ddf-2d6ce8b5e0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The task of [V: implementing] [ARG1: the reforms] and regaining competitiveness entailed significant political and social costs . \n",
      "The task of implementing the reforms and [V: regaining] [ARG1: competitiveness] entailed significant political and social costs . \n",
      "\u001b[1;31;47m[ARG0: \u001b[m\u001b[1;31;47mThe \u001b[m\u001b[1;31;47mtask \u001b[m\u001b[1;31;47mof \u001b[m\u001b[1;31;47mimplementing \u001b[m\u001b[1;31;47mthe \u001b[m\u001b[1;31;47mreforms \u001b[m\u001b[1;31;47mand \u001b[m\u001b[1;31;47mregaining \u001b[m\u001b[1;31;47mcompetitiveness] \u001b[m\u001b[1;30;47m[V: \u001b[m\u001b[1;30;47mentailed] \u001b[m\u001b[1;34;47m[ARG1: \u001b[m\u001b[1;34;47msignificant \u001b[m\u001b[1;34;47mpolitical \u001b[m\u001b[1;34;47mand \u001b[m\u001b[1;34;47msocial \u001b[m\u001b[1;34;47mcosts] \u001b[m. \n"
     ]
    }
   ],
   "source": [
    "analyze(\"The task of implementing the reforms and regaining competitiveness entailed significant political and social costs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "92f2d27b-0dc7-48cd-9cdd-4b99aa507cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "However , [ARG1: these efforts] , [V: supported] [ARG0: by a strong expansion in the global economy] , allowed German growth to rebound after 2005 . \n",
      "[ARGM-DIS: However] , \u001b[1;31;47m[ARG0: \u001b[m\u001b[1;31;47mthese \u001b[m\u001b[1;31;47mefforts \u001b[m\u001b[1;31;47m, \u001b[m\u001b[1;31;47msupported \u001b[m\u001b[1;31;47mby \u001b[m\u001b[1;31;47ma \u001b[m\u001b[1;31;47mstrong \u001b[m\u001b[1;31;47mexpansion \u001b[m\u001b[1;31;47min \u001b[m\u001b[1;31;47mthe \u001b[m\u001b[1;31;47mglobal \u001b[m\u001b[1;31;47meconomy] \u001b[m, \u001b[1;30;47m[V: \u001b[m\u001b[1;30;47mallowed] \u001b[m\u001b[1;34;47m[ARG1: \u001b[m\u001b[1;34;47mGerman \u001b[m\u001b[1;34;47mgrowth \u001b[m\u001b[1;34;47mto \u001b[m\u001b[1;34;47mrebound \u001b[m\u001b[1;34;47mafter \u001b[m\u001b[1;34;47m2005] \u001b[m. \n",
      "However , these efforts , supported by a strong expansion in the global economy , allowed [ARG1: German growth] to [V: rebound] [ARGM-TMP: after 2005] . \n"
     ]
    }
   ],
   "source": [
    "analyze(\"However, these efforts, supported by a strong expansion in the global economy, allowed German growth to rebound after 2005.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c6d13dc9-f815-4348-9384-b9a18d20e660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In order to [V: achieve] [ARG1: a turnaround] and allow further assistance , it is now essential for Greece to deliver on the promises that have been made . \n",
      "In order to achieve a turnaround and [V: allow] [ARG1: further assistance] , it is now essential for Greece to deliver on the promises that have been made . \n",
      "\u001b[1;34;47m[ARGM-PRP: \u001b[m\u001b[1;34;47mIn \u001b[m\u001b[1;34;47morder \u001b[m\u001b[1;34;47mto \u001b[m\u001b[1;34;47machieve \u001b[m\u001b[1;34;47ma \u001b[m\u001b[1;34;47mturnaround \u001b[m\u001b[1;34;47mand \u001b[m\u001b[1;34;47mallow \u001b[m\u001b[1;34;47mfurther \u001b[m\u001b[1;34;47massistance] \u001b[m, it \u001b[1;31;47m[V: \u001b[m\u001b[1;31;47mis] \u001b[m[ARGM-TMP: now] \u001b[1;31;47m[ARG2: \u001b[m\u001b[1;31;47messential] \u001b[m\u001b[1;31;47m[ARG1: \u001b[m\u001b[1;31;47mfor \u001b[m\u001b[1;31;47mGreece \u001b[m\u001b[1;31;47mto \u001b[m\u001b[1;31;47mdeliver \u001b[m\u001b[1;31;47mon \u001b[m\u001b[1;31;47mthe \u001b[m\u001b[1;31;47mpromises \u001b[m\u001b[1;31;47mthat \u001b[m\u001b[1;31;47mhave \u001b[m\u001b[1;31;47mbeen \u001b[m\u001b[1;31;47mmade] \u001b[m. \n",
      "In order to achieve a turnaround and allow further assistance , it is now essential for [ARG0: Greece] to [V: deliver] [ARG1: on the promises that have been made] . \n",
      "In order to achieve a turnaround and allow further assistance , it is now essential for Greece to deliver on the promises that [V: have] been made . \n",
      "In order to achieve a turnaround and allow further assistance , it is now essential for Greece to deliver on the promises that have [V: been] made . \n",
      "In order to achieve a turnaround and allow further assistance , it is now essential for Greece to deliver on [ARG1: the promises] [R-ARG1: that] have been [V: made] . \n"
     ]
    }
   ],
   "source": [
    "analyze(\"In order to achieve a turnaround and allow further assistance, it is now essential for Greece to deliver on the promises that have been made.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588908d7-0689-4902-b868-95fe6b5747ef",
   "metadata": {},
   "source": [
    "Modifiers in Propbank (source: http://clear.colorado.edu/compsem/documents/propbank_guidelines.pdf )\n",
    "* ADJ: Adjectival\n",
    "* ADV: Adverbials\n",
    "* CAU: Cause\n",
    "* COM: Comitative\n",
    "* DIR: Directional\n",
    "* DIS: Discourse\n",
    "* DSP: Direct Speech\n",
    "* EXT: Extent\n",
    "* GOL: Goal\n",
    "* LOC: Locative\n",
    "* LVB: Light Verb\n",
    "* MNR: Manner\n",
    "* MOD: Modal\n",
    "* NEG: Negation\n",
    "* PRD: Secondary Predication\n",
    "* PRP: Purpose\n",
    "* REC: Reciprocals\n",
    "* SLC: Relative Clause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1b7da2-a7d6-4031-8881-6ca37bd6ddaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "allennlp",
   "language": "python",
   "name": "allennlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
