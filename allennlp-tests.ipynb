{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "097cf9b2-c835-4d63-93e6-fb98636763f9",
   "metadata": {},
   "source": [
    "# AllenNLP tests\n",
    "\n",
    "Use AllenNLP's semantic role labeling in combination with manually written rules for extracting causal relations from political speeches. We found two limitations: only relations within a single sentence were found and complex relations involving understanding the sentence were hard to identify.\n",
    "\n",
    "Links:\n",
    "\n",
    "* software installation: https://github.com/allenai/allennlp (do not forget to install NLTK popular models)\n",
    "* software usage: https://demo.allennlp.org/semantic-role-labeling (tab: Model Usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4d59808-a18f-4dfe-970a-35ac0d46f573",
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.predictors.predictor import Predictor\n",
    "import allennlp_models.tagging\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "289eae14-db61-4df0-baec-41b07319a109",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erikt/anaconda3/envs/allennlp/lib/python3.7/site-packages/allennlp/tango/__init__.py:18: UserWarning: AllenNLP Tango is an experimental API and parts of it might change or disappear every time we release a new version.\n",
      "  \"AllenNLP Tango is an experimental API and parts of it might change or disappear \"\n",
      "2021-11-23 17:38:49,135 - INFO - allennlp.common.plugins - Plugin allennlp_models available\n",
      "2021-11-23 17:38:49,395 - INFO - cached_path - cache of https://storage.googleapis.com/allennlp-public-models/structured-prediction-srl-bert.2020.12.15.tar.gz is up-to-date\n",
      "2021-11-23 17:38:49,398 - INFO - allennlp.models.archival - loading archive file https://storage.googleapis.com/allennlp-public-models/structured-prediction-srl-bert.2020.12.15.tar.gz from cache at /home/erikt/.allennlp/cache/b5f1db011cc85691a5fa2bf29e055a712261a2e5d74a74edd7da2fffc98d4ab8.4c4ac7e06ec3d85631bd26b839f90b5a375d3ceeb43e3c74f1cf4758dcee2bb3\n",
      "2021-11-23 17:38:49,405 - INFO - allennlp.models.archival - extracting archive file /home/erikt/.allennlp/cache/b5f1db011cc85691a5fa2bf29e055a712261a2e5d74a74edd7da2fffc98d4ab8.4c4ac7e06ec3d85631bd26b839f90b5a375d3ceeb43e3c74f1cf4758dcee2bb3 to temp dir /tmp/tmplyfcs5a7\n",
      "2021-11-23 17:38:52,703 - INFO - allennlp.common.params - dataset_reader.type = srl\n",
      "2021-11-23 17:38:52,704 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
      "2021-11-23 17:38:52,704 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
      "2021-11-23 17:38:52,705 - INFO - allennlp.common.params - dataset_reader.manual_multiprocess_sharding = False\n",
      "2021-11-23 17:38:52,706 - INFO - allennlp.common.params - dataset_reader.token_indexers = None\n",
      "2021-11-23 17:38:52,706 - INFO - allennlp.common.params - dataset_reader.domain_identifier = None\n",
      "2021-11-23 17:38:52,707 - INFO - allennlp.common.params - dataset_reader.bert_model_name = bert-base-uncased\n",
      "2021-11-23 17:38:52,708 - INFO - allennlp.common.params - type = bert-base-uncased\n",
      "2021-11-23 17:39:05,527 - INFO - allennlp.common.params - dataset_reader.type = srl\n",
      "2021-11-23 17:39:05,527 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
      "2021-11-23 17:39:05,528 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
      "2021-11-23 17:39:05,528 - INFO - allennlp.common.params - dataset_reader.manual_multiprocess_sharding = False\n",
      "2021-11-23 17:39:05,529 - INFO - allennlp.common.params - dataset_reader.token_indexers = None\n",
      "2021-11-23 17:39:05,530 - INFO - allennlp.common.params - dataset_reader.domain_identifier = None\n",
      "2021-11-23 17:39:05,531 - INFO - allennlp.common.params - dataset_reader.bert_model_name = bert-base-uncased\n",
      "2021-11-23 17:39:05,531 - INFO - allennlp.common.params - type = bert-base-uncased\n",
      "2021-11-23 17:39:09,228 - INFO - allennlp.common.params - type = from_instances\n",
      "2021-11-23 17:39:09,229 - INFO - allennlp.data.vocabulary - Loading token dictionary from /tmp/tmplyfcs5a7/vocabulary.\n",
      "2021-11-23 17:39:09,230 - INFO - allennlp.common.params - model.type = srl_bert\n",
      "2021-11-23 17:39:09,231 - INFO - allennlp.common.params - model.regularizer = None\n",
      "2021-11-23 17:39:09,232 - INFO - allennlp.common.params - model.ddp_accelerator = None\n",
      "2021-11-23 17:39:09,232 - INFO - allennlp.common.params - model.bert_model = bert-base-uncased\n",
      "2021-11-23 17:39:09,238 - INFO - allennlp.common.params - type = bert-base-uncased\n",
      "2021-11-23 17:39:09,239 - INFO - allennlp.common.params - type = bert-base-uncased\n",
      "2021-11-23 17:39:09,240 - INFO - allennlp.common.params - model.embedding_dropout = 0.1\n",
      "2021-11-23 17:39:09,241 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7f7079d080d0>\n",
      "2021-11-23 17:39:09,242 - INFO - allennlp.common.params - model.label_smoothing = None\n",
      "2021-11-23 17:39:09,243 - INFO - allennlp.common.params - model.ignore_span_metric = False\n",
      "2021-11-23 17:39:09,244 - INFO - allennlp.common.params - model.srl_eval_path = /home/erikt/anaconda3/envs/allennlp/lib/python3.7/site-packages/allennlp_models/structured_prediction/tools/srl-eval.pl\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "2021-11-23 17:39:11,486 - INFO - allennlp.nn.initializers - Initializing parameters\n",
      "2021-11-23 17:39:11,487 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
      "2021-11-23 17:39:11,488 - INFO - allennlp.nn.initializers -    bert_model.embeddings.LayerNorm.bias\n",
      "2021-11-23 17:39:11,489 - INFO - allennlp.nn.initializers -    bert_model.embeddings.LayerNorm.weight\n",
      "2021-11-23 17:39:11,490 - INFO - allennlp.nn.initializers -    bert_model.embeddings.position_embeddings.weight\n",
      "2021-11-23 17:39:11,491 - INFO - allennlp.nn.initializers -    bert_model.embeddings.token_type_embeddings.weight\n",
      "2021-11-23 17:39:11,502 - INFO - allennlp.nn.initializers -    bert_model.embeddings.word_embeddings.weight\n",
      "2021-11-23 17:39:11,503 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "2021-11-23 17:39:11,503 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "2021-11-23 17:39:11,504 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.dense.bias\n",
      "2021-11-23 17:39:11,505 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.dense.weight\n",
      "2021-11-23 17:39:11,505 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.key.bias\n",
      "2021-11-23 17:39:11,506 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.key.weight\n",
      "2021-11-23 17:39:11,506 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.query.bias\n",
      "2021-11-23 17:39:11,507 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.query.weight\n",
      "2021-11-23 17:39:11,507 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.value.bias\n",
      "2021-11-23 17:39:11,508 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.value.weight\n",
      "2021-11-23 17:39:11,510 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.intermediate.dense.bias\n",
      "2021-11-23 17:39:11,511 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.intermediate.dense.weight\n",
      "2021-11-23 17:39:11,518 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.LayerNorm.bias\n",
      "2021-11-23 17:39:11,521 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.LayerNorm.weight\n",
      "2021-11-23 17:39:11,531 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.dense.bias\n",
      "2021-11-23 17:39:11,534 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.dense.weight\n",
      "2021-11-23 17:39:11,536 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "2021-11-23 17:39:11,538 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "2021-11-23 17:39:11,540 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.dense.bias\n",
      "2021-11-23 17:39:11,541 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.dense.weight\n",
      "2021-11-23 17:39:11,542 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.key.bias\n",
      "2021-11-23 17:39:11,543 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.key.weight\n",
      "2021-11-23 17:39:11,544 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.query.bias\n",
      "2021-11-23 17:39:11,544 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.query.weight\n",
      "2021-11-23 17:39:11,547 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.value.bias\n",
      "2021-11-23 17:39:11,550 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.value.weight\n",
      "2021-11-23 17:39:11,551 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.intermediate.dense.bias\n",
      "2021-11-23 17:39:11,553 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.intermediate.dense.weight\n",
      "2021-11-23 17:39:11,555 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.LayerNorm.bias\n",
      "2021-11-23 17:39:11,556 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.LayerNorm.weight\n",
      "2021-11-23 17:39:11,557 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.dense.bias\n",
      "2021-11-23 17:39:11,558 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.dense.weight\n",
      "2021-11-23 17:39:11,559 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "2021-11-23 17:39:11,564 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "2021-11-23 17:39:11,567 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.dense.bias\n",
      "2021-11-23 17:39:11,569 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.dense.weight\n",
      "2021-11-23 17:39:11,571 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.key.bias\n",
      "2021-11-23 17:39:11,572 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.key.weight\n",
      "2021-11-23 17:39:11,573 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.query.bias\n",
      "2021-11-23 17:39:11,574 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.query.weight\n",
      "2021-11-23 17:39:11,575 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.value.bias\n",
      "2021-11-23 17:39:11,576 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.value.weight\n",
      "2021-11-23 17:39:11,577 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.intermediate.dense.bias\n",
      "2021-11-23 17:39:11,578 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.intermediate.dense.weight\n",
      "2021-11-23 17:39:11,579 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.LayerNorm.bias\n",
      "2021-11-23 17:39:11,580 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.LayerNorm.weight\n",
      "2021-11-23 17:39:11,581 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.dense.bias\n",
      "2021-11-23 17:39:11,582 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.dense.weight\n",
      "2021-11-23 17:39:11,584 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "2021-11-23 17:39:11,586 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "2021-11-23 17:39:11,588 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.dense.bias\n",
      "2021-11-23 17:39:11,590 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.dense.weight\n",
      "2021-11-23 17:39:11,591 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.key.bias\n",
      "2021-11-23 17:39:11,592 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.key.weight\n",
      "2021-11-23 17:39:11,592 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.query.bias\n",
      "2021-11-23 17:39:11,593 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.query.weight\n",
      "2021-11-23 17:39:11,594 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.value.bias\n",
      "2021-11-23 17:39:11,595 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.value.weight\n",
      "2021-11-23 17:39:11,596 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.intermediate.dense.bias\n",
      "2021-11-23 17:39:11,597 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.intermediate.dense.weight\n",
      "2021-11-23 17:39:11,599 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.LayerNorm.bias\n",
      "2021-11-23 17:39:11,601 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.LayerNorm.weight\n",
      "2021-11-23 17:39:11,602 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.dense.bias\n",
      "2021-11-23 17:39:11,603 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.dense.weight\n",
      "2021-11-23 17:39:11,604 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "2021-11-23 17:39:11,605 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "2021-11-23 17:39:11,605 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.dense.bias\n",
      "2021-11-23 17:39:11,606 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.dense.weight\n",
      "2021-11-23 17:39:11,607 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.key.bias\n",
      "2021-11-23 17:39:11,608 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.key.weight\n",
      "2021-11-23 17:39:11,609 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.query.bias\n",
      "2021-11-23 17:39:11,610 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.query.weight\n",
      "2021-11-23 17:39:11,610 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.value.bias\n",
      "2021-11-23 17:39:11,611 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.value.weight\n",
      "2021-11-23 17:39:11,612 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.intermediate.dense.bias\n",
      "2021-11-23 17:39:11,613 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.intermediate.dense.weight\n",
      "2021-11-23 17:39:11,615 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.LayerNorm.bias\n",
      "2021-11-23 17:39:11,616 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.LayerNorm.weight\n",
      "2021-11-23 17:39:11,618 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.dense.bias\n",
      "2021-11-23 17:39:11,625 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.dense.weight\n",
      "2021-11-23 17:39:11,626 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "2021-11-23 17:39:11,627 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "2021-11-23 17:39:11,628 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.dense.bias\n",
      "2021-11-23 17:39:11,629 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.dense.weight\n",
      "2021-11-23 17:39:11,631 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.key.bias\n",
      "2021-11-23 17:39:11,633 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.key.weight\n",
      "2021-11-23 17:39:11,634 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.query.bias\n",
      "2021-11-23 17:39:11,635 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.query.weight\n",
      "2021-11-23 17:39:11,636 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.value.bias\n",
      "2021-11-23 17:39:11,636 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.value.weight\n",
      "2021-11-23 17:39:11,637 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.intermediate.dense.bias\n",
      "2021-11-23 17:39:11,638 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.intermediate.dense.weight\n",
      "2021-11-23 17:39:11,639 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.LayerNorm.bias\n",
      "2021-11-23 17:39:11,639 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.LayerNorm.weight\n",
      "2021-11-23 17:39:11,642 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.dense.bias\n",
      "2021-11-23 17:39:11,645 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.dense.weight\n",
      "2021-11-23 17:39:11,646 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "2021-11-23 17:39:11,648 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "2021-11-23 17:39:11,649 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.dense.bias\n",
      "2021-11-23 17:39:11,652 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.dense.weight\n",
      "2021-11-23 17:39:11,653 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.key.bias\n",
      "2021-11-23 17:39:11,654 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.key.weight\n",
      "2021-11-23 17:39:11,655 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.query.bias\n",
      "2021-11-23 17:39:11,655 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.query.weight\n",
      "2021-11-23 17:39:11,656 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.value.bias\n",
      "2021-11-23 17:39:11,657 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.value.weight\n",
      "2021-11-23 17:39:11,657 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.intermediate.dense.bias\n",
      "2021-11-23 17:39:11,658 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.intermediate.dense.weight\n",
      "2021-11-23 17:39:11,659 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.LayerNorm.bias\n",
      "2021-11-23 17:39:11,660 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.LayerNorm.weight\n",
      "2021-11-23 17:39:11,660 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.dense.bias\n",
      "2021-11-23 17:39:11,661 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.dense.weight\n",
      "2021-11-23 17:39:11,662 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "2021-11-23 17:39:11,665 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "2021-11-23 17:39:11,667 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.dense.bias\n",
      "2021-11-23 17:39:11,668 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.dense.weight\n",
      "2021-11-23 17:39:11,668 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.key.bias\n",
      "2021-11-23 17:39:11,669 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.key.weight\n",
      "2021-11-23 17:39:11,670 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.query.bias\n",
      "2021-11-23 17:39:11,671 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.query.weight\n",
      "2021-11-23 17:39:11,672 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.value.bias\n",
      "2021-11-23 17:39:11,672 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.value.weight\n",
      "2021-11-23 17:39:11,673 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.intermediate.dense.bias\n",
      "2021-11-23 17:39:11,674 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.intermediate.dense.weight\n",
      "2021-11-23 17:39:11,675 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.LayerNorm.bias\n",
      "2021-11-23 17:39:11,675 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.LayerNorm.weight\n",
      "2021-11-23 17:39:11,676 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.dense.bias\n",
      "2021-11-23 17:39:11,677 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.dense.weight\n",
      "2021-11-23 17:39:11,678 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "2021-11-23 17:39:11,679 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "2021-11-23 17:39:11,679 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.dense.bias\n",
      "2021-11-23 17:39:11,681 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.dense.weight\n",
      "2021-11-23 17:39:11,683 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.key.bias\n",
      "2021-11-23 17:39:11,686 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.key.weight\n",
      "2021-11-23 17:39:11,687 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.query.bias\n",
      "2021-11-23 17:39:11,688 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.query.weight\n",
      "2021-11-23 17:39:11,689 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.value.bias\n",
      "2021-11-23 17:39:11,690 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.value.weight\n",
      "2021-11-23 17:39:11,690 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.intermediate.dense.bias\n",
      "2021-11-23 17:39:11,691 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.intermediate.dense.weight\n",
      "2021-11-23 17:39:11,692 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.LayerNorm.bias\n",
      "2021-11-23 17:39:11,693 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.LayerNorm.weight\n",
      "2021-11-23 17:39:11,694 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.dense.bias\n",
      "2021-11-23 17:39:11,695 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.dense.weight\n",
      "2021-11-23 17:39:11,695 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "2021-11-23 17:39:11,696 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "2021-11-23 17:39:11,697 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.dense.bias\n",
      "2021-11-23 17:39:11,698 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.dense.weight\n",
      "2021-11-23 17:39:11,700 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.key.bias\n",
      "2021-11-23 17:39:11,701 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.key.weight\n",
      "2021-11-23 17:39:11,702 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.query.bias\n",
      "2021-11-23 17:39:11,703 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.query.weight\n",
      "2021-11-23 17:39:11,703 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.value.bias\n",
      "2021-11-23 17:39:11,704 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.value.weight\n",
      "2021-11-23 17:39:11,705 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.intermediate.dense.bias\n",
      "2021-11-23 17:39:11,706 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.intermediate.dense.weight\n",
      "2021-11-23 17:39:11,706 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.LayerNorm.bias\n",
      "2021-11-23 17:39:11,707 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.LayerNorm.weight\n",
      "2021-11-23 17:39:11,708 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.dense.bias\n",
      "2021-11-23 17:39:11,709 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.dense.weight\n",
      "2021-11-23 17:39:11,710 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "2021-11-23 17:39:11,710 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "2021-11-23 17:39:11,711 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.dense.bias\n",
      "2021-11-23 17:39:11,712 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.dense.weight\n",
      "2021-11-23 17:39:11,713 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.key.bias\n",
      "2021-11-23 17:39:11,715 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.key.weight\n",
      "2021-11-23 17:39:11,716 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.query.bias\n",
      "2021-11-23 17:39:11,716 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.query.weight\n",
      "2021-11-23 17:39:11,717 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.value.bias\n",
      "2021-11-23 17:39:11,720 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.value.weight\n",
      "2021-11-23 17:39:11,721 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.intermediate.dense.bias\n",
      "2021-11-23 17:39:11,722 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.intermediate.dense.weight\n",
      "2021-11-23 17:39:11,723 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.LayerNorm.bias\n",
      "2021-11-23 17:39:11,724 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.LayerNorm.weight\n",
      "2021-11-23 17:39:11,724 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.dense.bias\n",
      "2021-11-23 17:39:11,725 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.dense.weight\n",
      "2021-11-23 17:39:11,726 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "2021-11-23 17:39:11,727 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "2021-11-23 17:39:11,728 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.dense.bias\n",
      "2021-11-23 17:39:11,728 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.dense.weight\n",
      "2021-11-23 17:39:11,730 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.key.bias\n",
      "2021-11-23 17:39:11,731 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.key.weight\n",
      "2021-11-23 17:39:11,731 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.query.bias\n",
      "2021-11-23 17:39:11,734 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.query.weight\n",
      "2021-11-23 17:39:11,734 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.value.bias\n",
      "2021-11-23 17:39:11,735 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.value.weight\n",
      "2021-11-23 17:39:11,736 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.intermediate.dense.bias\n",
      "2021-11-23 17:39:11,737 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.intermediate.dense.weight\n",
      "2021-11-23 17:39:11,738 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.LayerNorm.bias\n",
      "2021-11-23 17:39:11,738 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.LayerNorm.weight\n",
      "2021-11-23 17:39:11,739 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.dense.bias\n",
      "2021-11-23 17:39:11,740 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.dense.weight\n",
      "2021-11-23 17:39:11,740 - INFO - allennlp.nn.initializers -    bert_model.pooler.dense.bias\n",
      "2021-11-23 17:39:11,741 - INFO - allennlp.nn.initializers -    bert_model.pooler.dense.weight\n",
      "2021-11-23 17:39:11,743 - INFO - allennlp.nn.initializers -    tag_projection_layer.bias\n",
      "2021-11-23 17:39:11,744 - INFO - allennlp.nn.initializers -    tag_projection_layer.weight\n",
      "2021-11-23 17:39:12,671 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /tmp/tmplyfcs5a7\n"
     ]
    }
   ],
   "source": [
    "srl_predictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/structured-prediction-srl-bert.2020.12.15.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "022436b0-d987-4c02-9ec8-6c8b47489dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLOR_CONCEPT_1 = 1\n",
    "COLOR_CONCEPT_2 = 4\n",
    "COLOR_CONTENT_RELATION_EXPLANATION = 0\n",
    "NO_COLOR = -1\n",
    "RELATION_VERBS = [ \"achieve\", \"allow\", \"avoid\", \"balance\", \"boost\", \"bring\", \"brought\", \"consolidate\", \"compromise\",  \"contain\", \"contribute\", \n",
    "                   \"eliminate\", \"endanger\", \"entail\", \"ensure\", \"erode\", \"fail\", \"flow\", \"gave\", \"give\", \"given\", \"increase\", \"open\", \"preserve\", \"protect\", \n",
    "                   \"reduce\", \"reinforce\", \"restore\", \"result\", \"safeguard\", \"secure\", \"strenghten\", \"support\", \"tackle\", \"trigger\", \"undermine\", \"weaken\", ]\n",
    "REVERSE_VERBS = [ \"arise\", \"need\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfb6f8c8-dcc8-4c89-93b4-78d1afab73df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_tag(token):\n",
    "    if len(token) > 1:\n",
    "        if re.search(\"^\\[\", token):\n",
    "            token = re.sub(\"^\\[\", \"\", token)\n",
    "            token = re.sub(\":$\", \"\", token)\n",
    "        token = re.sub(\"\\]$\", \"\", token)\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f33cca46-632f-4cfc-8f50-aae6f0e8fbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_with_color(string, color_code):\n",
    "    print(f\"\\x1b[1;3{color_code};47m{string} \\x1b[m\", end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac4738ff-d132-47ea-89c9-3bc4dec25543",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_argm_prp(tokens, arguments, i):\n",
    "    if i in arguments[\"ARGM-PRP\"]:\n",
    "        color_code = COLOR_CONCEPT_2\n",
    "    elif \"V\" in arguments and i in arguments[\"V\"]:\n",
    "        color_code = COLOR_CONCEPT_1\n",
    "    elif \"ARG0\" in arguments and i in arguments[\"ARG0\"]:\n",
    "        color_code = COLOR_CONCEPT_1\n",
    "    elif \"ARG1\" in arguments and i in arguments[\"ARG1\"]:\n",
    "        color_code = COLOR_CONCEPT_1\n",
    "    elif \"ARG2\" in arguments and i in arguments[\"ARG2\"]:\n",
    "        color_code = COLOR_CONCEPT_1\n",
    "    else:\n",
    "        color_code = NO_COLOR\n",
    "    if color_code >= 0:\n",
    "        print_with_color(tokens[i], color_code)\n",
    "    else:\n",
    "        print(f\"{tokens[i]} \", end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75f9d05f-0b73-48ce-9604-ba7283d051c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_argm_dis(tokens, arguments, i):\n",
    "    color_code = NO_COLOR\n",
    "    if i in arguments[\"ARGM-DIS\"]:\n",
    "        color_code = COLOR_CONTENT_RELATION_EXPLANATION\n",
    "    else:\n",
    "        for key in arguments:\n",
    "            if key != \"ARGM-DIS\" and i in arguments[key]:\n",
    "                color_code = COLOR_CONCEPT_2\n",
    "    if color_code >= 0:\n",
    "        print_with_color(tokens[i], color_code)\n",
    "    else:\n",
    "        print(f\"{tokens[i]} \", end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe60a35d-1501-44d9-9aab-0bb7b150bcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_v(tokens, arguments, i):\n",
    "    if \"V\" in arguments and i in arguments[\"V\"]:\n",
    "        color_code = COLOR_CONTENT_RELATION_EXPLANATION\n",
    "    elif \"ARG0\" in arguments and i in arguments[\"ARG0\"]:\n",
    "        color_code = COLOR_CONCEPT_1\n",
    "    elif \"ARG1\" in arguments and i in arguments[\"ARG1\"]:\n",
    "        color_code = COLOR_CONCEPT_2\n",
    "    elif \"ARG2\" in arguments and i in arguments[\"ARG2\"]:\n",
    "        color_code = COLOR_CONCEPT_2\n",
    "    else:\n",
    "        color_code = NO_COLOR\n",
    "    if color_code >= 0:\n",
    "        print_with_color(tokens[i], color_code)\n",
    "    else:\n",
    "        print(f\"{tokens[i]} \", end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05549e58-5850-4ec6-a685-8470df89da05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_reverse_v(tokens, arguments, i):\n",
    "    if \"V\" in arguments and i in arguments[\"V\"]:\n",
    "        color_code = COLOR_CONTENT_RELATION_EXPLANATION\n",
    "    elif \"ARG0\" in arguments and i in arguments[\"ARG0\"]:\n",
    "        color_code = COLOR_CONCEPT_2\n",
    "    elif \"ARG1\" in arguments and i in arguments[\"ARG1\"]:\n",
    "        color_code = COLOR_CONCEPT_1\n",
    "    elif \"ARG2\" in arguments and i in arguments[\"ARG2\"]:\n",
    "        color_code = COLOR_CONCEPT_1\n",
    "    else:\n",
    "        color_code = NO_COLOR\n",
    "    if color_code >= 0:\n",
    "        print_with_color(tokens[i], color_code)\n",
    "    else:\n",
    "        print(f\"{tokens[i]} \", end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94001968-cb87-49f3-98bb-3ecc19973f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_verb(verb, RELATION_VERBS):\n",
    "    if verb in RELATION_VERBS:\n",
    "        return True\n",
    "    if re.sub(\"[ds]$\", \"\", verb) in RELATION_VERBS:\n",
    "        return True\n",
    "    if re.sub(\"ed$\", \"\", verb) in RELATION_VERBS:\n",
    "        return True\n",
    "    if re.sub(\"ing$\", \"\", verb) in RELATION_VERBS:\n",
    "        return True\n",
    "    if re.sub(\"ing$\", \"e\", verb) in RELATION_VERBS:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31a63481-9434-43ff-9146-6a5fb0b39520",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print(analyzed_sentence):\n",
    "    arguments = {}\n",
    "    tokens = analyzed_sentence.split()\n",
    "    current_argument = \"\"\n",
    "    for i in range(0, len(tokens)):\n",
    "        if re.search(\"^\\[\", tokens[i]):\n",
    "            current_argument = strip_tag(tokens[i])\n",
    "        if current_argument != \"\":\n",
    "            if current_argument in arguments:\n",
    "                arguments[current_argument].append(i)\n",
    "            else:\n",
    "                arguments[current_argument] = [i]\n",
    "        if re.search(\"\\]$\", tokens[i]):\n",
    "            current_argument = \"\"\n",
    "    for i in range(0, len(tokens)):\n",
    "        if \"ARGM-PRP\" in arguments:\n",
    "            print_argm_prp(tokens, arguments, i)\n",
    "        elif \"ARGM-DIS\" in arguments:\n",
    "            print_argm_dis(tokens, arguments, i)\n",
    "        elif \"V\" in arguments and check_verb(strip_tag(tokens[arguments[\"V\"][-1]]), RELATION_VERBS):\n",
    "            print_v(tokens, arguments, i)\n",
    "        elif \"V\" in arguments and check_verb(strip_tag(tokens[arguments[\"V\"][-1]]), REVERSE_VERBS):\n",
    "            print_reverse_v(tokens, arguments, i)\n",
    "        else:\n",
    "            print(f\"{tokens[i]} \", end=\"\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3057805e-406f-48e5-82f2-b57713e6c38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(sentence):\n",
    "    analysis = srl_predictor.predict(sentence=sentence)\n",
    "    for verb_data in analysis['verbs']:\n",
    "        pretty_print(verb_data['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a15844e-570e-4d1f-be62-b2f953dedbc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ARG0: John] [V: sees] [ARG1: the mountain with the snow] \n"
     ]
    }
   ],
   "source": [
    "analyze(\"John sees the mountain with the snow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1011a94-4b99-445b-a402-8d8da2b2c102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34;47m[ARG0: \u001b[m\u001b[1;34;47mYou] \u001b[m, [ARGM-LOC: in Greece] , [ARGM-MNR: with our support] , \u001b[1;30;47m[V: \u001b[m\u001b[1;30;47mneed] \u001b[m\u001b[1;31;47m[ARG1: \u001b[m\u001b[1;31;47mto \u001b[m\u001b[1;31;47mrebuild \u001b[m\u001b[1;31;47myour \u001b[m\u001b[1;31;47mcountry \u001b[m\u001b[1;31;47m, \u001b[m\u001b[1;31;47myour \u001b[m\u001b[1;31;47mstructures \u001b[m\u001b[1;31;47m, \u001b[m\u001b[1;31;47myour \u001b[m\u001b[1;31;47madministration \u001b[m\u001b[1;31;47m, \u001b[m\u001b[1;31;47myour \u001b[m\u001b[1;31;47meconomy \u001b[m\u001b[1;31;47mto \u001b[m\u001b[1;31;47mincrease \u001b[m\u001b[1;31;47mthe \u001b[m\u001b[1;31;47mcompetitiveness \u001b[m\u001b[1;31;47mof \u001b[m\u001b[1;31;47mGreece] \u001b[m. \n",
      "\u001b[1;31;47m[ARG0: \u001b[m\u001b[1;31;47mYou] \u001b[m, in Greece , with our support , need to \u001b[1;31;47m[V: \u001b[m\u001b[1;31;47mrebuild] \u001b[m\u001b[1;31;47m[ARG1: \u001b[m\u001b[1;31;47myour \u001b[m\u001b[1;31;47mcountry \u001b[m\u001b[1;31;47m, \u001b[m\u001b[1;31;47myour \u001b[m\u001b[1;31;47mstructures \u001b[m\u001b[1;31;47m, \u001b[m\u001b[1;31;47myour \u001b[m\u001b[1;31;47madministration \u001b[m\u001b[1;31;47m, \u001b[m\u001b[1;31;47myour \u001b[m\u001b[1;31;47meconomy] \u001b[m\u001b[1;34;47m[ARGM-PRP: \u001b[m\u001b[1;34;47mto \u001b[m\u001b[1;34;47mincrease \u001b[m\u001b[1;34;47mthe \u001b[m\u001b[1;34;47mcompetitiveness \u001b[m\u001b[1;34;47mof \u001b[m\u001b[1;34;47mGreece] \u001b[m. \n",
      "You , in Greece , with our support , need to rebuild your country , your structures , your administration , your economy to \u001b[1;30;47m[V: \u001b[m\u001b[1;30;47mincrease] \u001b[m\u001b[1;34;47m[ARG1: \u001b[m\u001b[1;34;47mthe \u001b[m\u001b[1;34;47mcompetitiveness \u001b[m\u001b[1;34;47mof \u001b[m\u001b[1;34;47mGreece] \u001b[m. \n"
     ]
    }
   ],
   "source": [
    "analyze(\"\"\"You, in Greece, with our support, need to rebuild your country, your structures, your administration, \n",
    "           your economy to increase the competitiveness of Greece.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "315abf68-be8c-4f3d-bf4c-2df02c86b2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;47m[ARG0: \u001b[m\u001b[1;31;47mThis] \u001b[m\u001b[1;30;47m[V: \u001b[m\u001b[1;30;47mopened] \u001b[m\u001b[1;34;47m[ARG1: \u001b[m\u001b[1;34;47mthe \u001b[m\u001b[1;34;47mway \u001b[m\u001b[1;34;47mto \u001b[m\u001b[1;34;47mwelfare \u001b[m\u001b[1;34;47mgains \u001b[m\u001b[1;34;47mfrom \u001b[m\u001b[1;34;47mstronger \u001b[m\u001b[1;34;47meconomic \u001b[m\u001b[1;34;47mand \u001b[m\u001b[1;34;47mfinancial \u001b[m\u001b[1;34;47mintegration] \u001b[m. \n"
     ]
    }
   ],
   "source": [
    "analyze(\"This opened the way to welfare gains from stronger economic and financial integration.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f79c931-5910-4e5e-906c-cf0038e13294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ARG1: One risk] [V: is] [ARG2: the temptation for governments to overborrow because the economic costs of excessive public debt] \n"
     ]
    }
   ],
   "source": [
    "analyze(\"One risk is the temptation for governments to overborrow because the economic costs of excessive public debt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5790cf17-2704-4467-95ac-20f071abfff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A \u001b[1;30;47m[V: \u001b[m\u001b[1;30;47mresulting] \u001b[m\u001b[1;34;47m[ARG2: \u001b[m\u001b[1;34;47mloosening] \u001b[mof fiscal discipline in individual member states can endanger the stability - oriented monetary policy . \n",
      "A resulting loosening of fiscal discipline in individual member states [V: can] endanger the stability - oriented monetary policy . \n",
      "\u001b[1;31;47m[ARG0: \u001b[m\u001b[1;31;47mA \u001b[m\u001b[1;31;47mresulting \u001b[m\u001b[1;31;47mloosening \u001b[m\u001b[1;31;47mof \u001b[m\u001b[1;31;47mfiscal \u001b[m\u001b[1;31;47mdiscipline \u001b[m\u001b[1;31;47min \u001b[m\u001b[1;31;47mindividual \u001b[m\u001b[1;31;47mmember \u001b[m\u001b[1;31;47mstates] \u001b[m[ARGM-MOD: can] \u001b[1;30;47m[V: \u001b[m\u001b[1;30;47mendanger] \u001b[m\u001b[1;34;47m[ARG1: \u001b[m\u001b[1;34;47mthe \u001b[m\u001b[1;34;47mstability \u001b[m\u001b[1;34;47m- \u001b[m\u001b[1;34;47moriented \u001b[m\u001b[1;34;47mmonetary \u001b[m\u001b[1;34;47mpolicy] \u001b[m. \n",
      "A resulting loosening of fiscal discipline in individual member states can endanger the [ARGM-MNR: stability] - [V: oriented] [ARG1: monetary policy] . \n"
     ]
    }
   ],
   "source": [
    "analyze(\"A resulting loosening of fiscal discipline in individual member states can endanger the stability-oriented monetary policy.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bee739b0-6890-44c8-9243-ba7232cfd06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Therefore , the markets [V: did] not properly perform their expected policing function . \n",
      "\u001b[1;30;47m[ARGM-DIS: \u001b[m\u001b[1;30;47mTherefore] \u001b[m, \u001b[1;34;47m[ARG0: \u001b[m\u001b[1;34;47mthe \u001b[m\u001b[1;34;47mmarkets] \u001b[mdid \u001b[1;34;47m[ARGM-NEG: \u001b[m\u001b[1;34;47mnot] \u001b[m\u001b[1;34;47m[ARGM-MNR: \u001b[m\u001b[1;34;47mproperly] \u001b[m\u001b[1;34;47m[V: \u001b[m\u001b[1;34;47mperform] \u001b[m\u001b[1;34;47m[ARG1: \u001b[m\u001b[1;34;47mtheir \u001b[m\u001b[1;34;47mexpected \u001b[m\u001b[1;34;47mpolicing \u001b[m\u001b[1;34;47mfunction] \u001b[m. \n",
      "Therefore , the markets did not properly perform their [V: expected] [ARG1: policing function] . \n"
     ]
    }
   ],
   "source": [
    "analyze(\"Therefore, the markets did not properly perform their expected policing function.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f1a41ca-b0ba-48c7-99f3-c4475ce51df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ARG0: I] [V: hope] [ARG1: that following the lessons of interdependence not only at global , but also at European level given by the crisis] \n",
      "I hope that [V: following] [ARG1: the lessons of interdependence] [ARGM-LOC: not only at global , but also at European level given by the crisis] \n",
      "I hope that following \u001b[1;34;47m[ARG1: \u001b[m\u001b[1;34;47mthe \u001b[m\u001b[1;34;47mlessons \u001b[m\u001b[1;34;47mof \u001b[m\u001b[1;34;47minterdependence] \u001b[mnot only at global , but also at European level \u001b[1;30;47m[V: \u001b[m\u001b[1;30;47mgiven] \u001b[m\u001b[1;31;47m[ARG0: \u001b[m\u001b[1;31;47mby \u001b[m\u001b[1;31;47mthe \u001b[m\u001b[1;31;47mcrisis] \u001b[m\n"
     ]
    }
   ],
   "source": [
    "analyze(\"I hope that following the lessons of interdependence not only at global, but also at European level given by the crisis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6907cf65-d7d1-4f2b-834c-c8725a789efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34;47m[ARG0: \u001b[m\u001b[1;34;47mEuropean \u001b[m\u001b[1;34;47meconomic \u001b[m\u001b[1;34;47mstrategy] \u001b[m\u001b[1;30;47m[V: \u001b[m\u001b[1;30;47mneeds] \u001b[m\u001b[1;31;47m[ARG1: \u001b[m\u001b[1;31;47mthe \u001b[m\u001b[1;31;47mfull \u001b[m\u001b[1;31;47mcommitment \u001b[m\u001b[1;31;47mof \u001b[m\u001b[1;31;47mthe \u001b[m\u001b[1;31;47mEuropean \u001b[m\u001b[1;31;47mpolitical \u001b[m\u001b[1;31;47mcommunity] \u001b[m. \n"
     ]
    }
   ],
   "source": [
    "analyze(\"European economic strategy needs the full commitment of the European political community.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "459c7201-cc64-4b74-ad11-4558a8e249fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And a European economic system \u001b[1;34;47m[ARG1: \u001b[m\u001b[1;34;47mwhose \u001b[m\u001b[1;34;47mresilience] \u001b[m\u001b[1;30;47m[V: \u001b[m\u001b[1;30;47mflows] \u001b[m[ARGM-DIR: from its single market] \n"
     ]
    }
   ],
   "source": [
    "analyze(\"And a European economic system whose resilience flows from its single market\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b72ed91-af91-4c2f-9c75-193561125851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there \u001b[1;34;47m[V: \u001b[m\u001b[1;34;47mare] \u001b[m\u001b[1;30;47m[ARGM-DIS: \u001b[m\u001b[1;30;47mof \u001b[m\u001b[1;30;47mcourse] \u001b[m\u001b[1;34;47m[ARG1: \u001b[m\u001b[1;34;47mconsiderable \u001b[m\u001b[1;34;47mbudgetary \u001b[m\u001b[1;34;47mchallenges \u001b[m\u001b[1;34;47marising \u001b[m\u001b[1;34;47mfrom \u001b[m\u001b[1;34;47mthe \u001b[m\u001b[1;34;47mrecent \u001b[m\u001b[1;34;47mexceptional \u001b[m\u001b[1;34;47mmeasures] \u001b[m\n",
      "there are of course \u001b[1;31;47m[ARG1: \u001b[m\u001b[1;31;47mconsiderable \u001b[m\u001b[1;31;47mbudgetary \u001b[m\u001b[1;31;47mchallenges] \u001b[m\u001b[1;30;47m[V: \u001b[m\u001b[1;30;47marising] \u001b[m\u001b[1;31;47m[ARG2: \u001b[m\u001b[1;31;47mfrom \u001b[m\u001b[1;31;47mthe \u001b[m\u001b[1;31;47mrecent \u001b[m\u001b[1;31;47mexceptional \u001b[m\u001b[1;31;47mmeasures] \u001b[m\n"
     ]
    }
   ],
   "source": [
    "analyze(\"there are of course considerable budgetary challenges arising from the recent exceptional measures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed79018-85a0-45fb-9d5c-2f1947602cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(\"And the best hope of a return to growth and job creation is inside the euro area.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da62399a-2a30-4bfd-a4eb-ce2215579c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(\"To conclude, let me say a few words on the euro area more generally.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d41d16d-acbf-4da7-9afe-0992057f9fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(\"\"\"We have taken important, fundamental decisions over the last couple of months to safeguard the stability \n",
    "           of the euro area, and indeed we are now in the phase of implementation.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc28fe0-2fd8-40f0-bb47-e66a0dbc7822",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(\"\"\"A number of governments have embarked on a path of reform and fiscal consolidation that was unthinkable only \n",
    "           very recently, and they have taken important decisions and I encourage them to keep this determination.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3608204a-2217-4403-896d-10b5b02f0f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(\"\"\"These reforms are now being implemented and this effort must continue with credibility, with consistency, \n",
    "           with coherence over time.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21df66a7-1c41-43a5-a953-c40ac915e150",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(\"As we said there will not be magic solutions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e08438-0804-4afb-a771-5f848fd6278e",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(\"We need sustained efforts and determination.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cd2b3d-b1ad-4a4a-b690-6d86877ef10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(\"At the same time, the existing financial backstops are being used as necessary.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bbefe2-4e57-495d-886c-d76f4b240d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(\"\"\"Most recently, the financial assistance to the recapitalisation of Spanish banks has been agreed \n",
    "           and is ready for implementation.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985bbeaa-a66b-4ee9-8bef-a512bca9cbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(\"\"\"Giving to the ECB the ultimate responsibility for supervision of banks in the euro area \n",
    "           will decisively contribute to increase confidence between the banks \n",
    "           and in this way increase the financial stability in the euro area.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74993ff-629f-4444-a3e9-95d936869c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(\"Second, Germany is acutely aware of the need to tackle the root causes and not just the symptoms of the crisis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae9f741-68e7-4ae0-b1de-5ecb8723f609",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(\"\"\"This is why it is pressing strongly for institutional reforms of the EMU framework plus structural reforms \n",
    "           and budgetary discipline in the member states.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2040f38a-a5a9-4985-bec9-5407b44785a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(\"The introduction of the euro eliminated exchange rate risks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12883bd7-edda-4218-9303-1765e061dc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(\"\"\"Another implication of the euro area's single monetary policy is that the key interest rates \n",
    "           are set for the currency bloc as a whole.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0a3592-99cf-48eb-acdd-9cfd79fff765",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(\"\"\"One risk is the temptation for governments to overborrow because the economic costs of excessive public debt, \n",
    "           for example higher interest rates, can be more easily shifted to other member states.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9960a6-24ea-4ee9-b260-6112c96cd9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(\"\"\"Even Germany ran up excessive deficits for a few years and, even worse, championed a reform of the SGP \n",
    "           which ultimately further weakened the application of the fiscal rules.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d20c14-9a56-4456-8abb-6dd8debb1b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(\"\"\"However, the EMU framework not only failed to avoid excessive deficits, it was also unable to prevent \n",
    "           the build-up of macroeconomic imbalances within the euro area.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931baf3e-958f-4ad6-a998-a4f8ea2cfcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(\"\"\"The resulting increase in domestic inflation and wages eroded the competitiveness of the countries concerned and \n",
    "           increased their dependence on capital imports.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87956f23-b8ce-48ff-8ddf-2d6ce8b5e0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(\"The task of implementing the reforms and regaining competitiveness entailed significant political and social costs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f2d27b-0dc7-48cd-9cdd-4b99aa507cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(\"\"\"However, these efforts, supported by a strong expansion in the global economy, allowed German growth to rebound \n",
    "           after 2005.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d13dc9-f815-4348-9384-b9a18d20e660",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(\"\"\"In order to achieve a turnaround and allow further assistance, it is now essential for Greece to deliver \n",
    "           on the promises that have been made.\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588908d7-0689-4902-b868-95fe6b5747ef",
   "metadata": {},
   "source": [
    "Modifiers in Propbank (source: http://clear.colorado.edu/compsem/documents/propbank_guidelines.pdf )\n",
    "* ADJ: Adjectival\n",
    "* ADV: Adverbials\n",
    "* CAU: Cause\n",
    "* COM: Comitative\n",
    "* DIR: Directional\n",
    "* DIS: Discourse\n",
    "* DSP: Direct Speech\n",
    "* EXT: Extent\n",
    "* GOL: Goal\n",
    "* LOC: Locative\n",
    "* LVB: Light Verb\n",
    "* MNR: Manner\n",
    "* MOD: Modal\n",
    "* NEG: Negation\n",
    "* PRD: Secondary Predication\n",
    "* PRP: Purpose\n",
    "* REC: Reciprocals\n",
    "* SLC: Relative Clause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1b7da2-a7d6-4031-8881-6ca37bd6ddaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "allennlp",
   "language": "python",
   "name": "allennlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
