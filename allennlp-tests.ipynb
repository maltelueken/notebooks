{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "097cf9b2-c835-4d63-93e6-fb98636763f9",
   "metadata": {},
   "source": [
    "# AllenNLP tests\n",
    "\n",
    "Use AllenNLP's semantic role labeling in combination with manually written rules for extracting causal relations from political speeches. We found two limitations: only relations within a single sentence were found and complex relations involving understanding the sentence were hard to identify.\n",
    "\n",
    "Links:\n",
    "\n",
    "* software installation: https://github.com/allenai/allennlp (do not forget to install NLTK popular models)\n",
    "* software usage: https://demo.allennlp.org/semantic-role-labeling (tab: Model Usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4d59808-a18f-4dfe-970a-35ac0d46f573",
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.predictors.predictor import Predictor\n",
    "import allennlp_models.tagging\n",
    "import re\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "207dd2bc-a758-4e4c-a813-9bf1024aac15",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_analyze = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "289eae14-db61-4df0-baec-41b07319a109",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erikt/anaconda3/envs/allennlp/lib/python3.7/site-packages/allennlp/tango/__init__.py:18: UserWarning: AllenNLP Tango is an experimental API and parts of it might change or disappear every time we release a new version.\n",
      "  \"AllenNLP Tango is an experimental API and parts of it might change or disappear \"\n",
      "2021-11-25 16:35:52,066 - INFO - allennlp.common.plugins - Plugin allennlp_models available\n",
      "2021-11-25 16:35:52,338 - INFO - cached_path - cache of https://storage.googleapis.com/allennlp-public-models/structured-prediction-srl-bert.2020.12.15.tar.gz is up-to-date\n",
      "2021-11-25 16:35:52,340 - INFO - allennlp.models.archival - loading archive file https://storage.googleapis.com/allennlp-public-models/structured-prediction-srl-bert.2020.12.15.tar.gz from cache at /home/erikt/.allennlp/cache/b5f1db011cc85691a5fa2bf29e055a712261a2e5d74a74edd7da2fffc98d4ab8.4c4ac7e06ec3d85631bd26b839f90b5a375d3ceeb43e3c74f1cf4758dcee2bb3\n",
      "2021-11-25 16:35:52,341 - INFO - allennlp.models.archival - extracting archive file /home/erikt/.allennlp/cache/b5f1db011cc85691a5fa2bf29e055a712261a2e5d74a74edd7da2fffc98d4ab8.4c4ac7e06ec3d85631bd26b839f90b5a375d3ceeb43e3c74f1cf4758dcee2bb3 to temp dir /tmp/tmp_wh_ew5u\n",
      "2021-11-25 16:35:59,219 - INFO - allennlp.common.params - dataset_reader.type = srl\n",
      "2021-11-25 16:35:59,221 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
      "2021-11-25 16:35:59,223 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
      "2021-11-25 16:35:59,224 - INFO - allennlp.common.params - dataset_reader.manual_multiprocess_sharding = False\n",
      "2021-11-25 16:35:59,236 - INFO - allennlp.common.params - dataset_reader.token_indexers = None\n",
      "2021-11-25 16:35:59,237 - INFO - allennlp.common.params - dataset_reader.domain_identifier = None\n",
      "2021-11-25 16:35:59,239 - INFO - allennlp.common.params - dataset_reader.bert_model_name = bert-base-uncased\n",
      "2021-11-25 16:35:59,240 - INFO - allennlp.common.params - type = bert-base-uncased\n",
      "2021-11-25 16:36:13,548 - INFO - allennlp.common.params - dataset_reader.type = srl\n",
      "2021-11-25 16:36:13,550 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
      "2021-11-25 16:36:13,550 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
      "2021-11-25 16:36:13,551 - INFO - allennlp.common.params - dataset_reader.manual_multiprocess_sharding = False\n",
      "2021-11-25 16:36:13,552 - INFO - allennlp.common.params - dataset_reader.token_indexers = None\n",
      "2021-11-25 16:36:13,554 - INFO - allennlp.common.params - dataset_reader.domain_identifier = None\n",
      "2021-11-25 16:36:13,557 - INFO - allennlp.common.params - dataset_reader.bert_model_name = bert-base-uncased\n",
      "2021-11-25 16:36:13,558 - INFO - allennlp.common.params - type = bert-base-uncased\n",
      "2021-11-25 16:36:17,753 - INFO - allennlp.common.params - type = from_instances\n",
      "2021-11-25 16:36:17,760 - INFO - allennlp.data.vocabulary - Loading token dictionary from /tmp/tmp_wh_ew5u/vocabulary.\n",
      "2021-11-25 16:36:17,762 - INFO - allennlp.common.params - model.type = srl_bert\n",
      "2021-11-25 16:36:17,768 - INFO - allennlp.common.params - model.regularizer = None\n",
      "2021-11-25 16:36:17,775 - INFO - allennlp.common.params - model.ddp_accelerator = None\n",
      "2021-11-25 16:36:17,778 - INFO - allennlp.common.params - model.bert_model = bert-base-uncased\n",
      "2021-11-25 16:36:17,779 - INFO - allennlp.common.params - type = bert-base-uncased\n",
      "2021-11-25 16:36:17,781 - INFO - allennlp.common.params - type = bert-base-uncased\n",
      "2021-11-25 16:36:17,783 - INFO - allennlp.common.params - model.embedding_dropout = 0.1\n",
      "2021-11-25 16:36:17,787 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7f5e43712250>\n",
      "2021-11-25 16:36:17,789 - INFO - allennlp.common.params - model.label_smoothing = None\n",
      "2021-11-25 16:36:17,790 - INFO - allennlp.common.params - model.ignore_span_metric = False\n",
      "2021-11-25 16:36:17,793 - INFO - allennlp.common.params - model.srl_eval_path = /home/erikt/anaconda3/envs/allennlp/lib/python3.7/site-packages/allennlp_models/structured_prediction/tools/srl-eval.pl\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "2021-11-25 16:36:21,154 - INFO - allennlp.nn.initializers - Initializing parameters\n",
      "2021-11-25 16:36:21,165 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
      "2021-11-25 16:36:21,172 - INFO - allennlp.nn.initializers -    bert_model.embeddings.LayerNorm.bias\n",
      "2021-11-25 16:36:21,178 - INFO - allennlp.nn.initializers -    bert_model.embeddings.LayerNorm.weight\n",
      "2021-11-25 16:36:21,181 - INFO - allennlp.nn.initializers -    bert_model.embeddings.position_embeddings.weight\n",
      "2021-11-25 16:36:21,182 - INFO - allennlp.nn.initializers -    bert_model.embeddings.token_type_embeddings.weight\n",
      "2021-11-25 16:36:21,189 - INFO - allennlp.nn.initializers -    bert_model.embeddings.word_embeddings.weight\n",
      "2021-11-25 16:36:21,193 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "2021-11-25 16:36:21,196 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "2021-11-25 16:36:21,198 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.dense.bias\n",
      "2021-11-25 16:36:21,203 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.dense.weight\n",
      "2021-11-25 16:36:21,208 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.key.bias\n",
      "2021-11-25 16:36:21,209 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.key.weight\n",
      "2021-11-25 16:36:21,211 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.query.bias\n",
      "2021-11-25 16:36:21,215 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.query.weight\n",
      "2021-11-25 16:36:21,216 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.value.bias\n",
      "2021-11-25 16:36:21,218 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.value.weight\n",
      "2021-11-25 16:36:21,219 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.intermediate.dense.bias\n",
      "2021-11-25 16:36:21,222 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.intermediate.dense.weight\n",
      "2021-11-25 16:36:21,225 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.LayerNorm.bias\n",
      "2021-11-25 16:36:21,226 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.LayerNorm.weight\n",
      "2021-11-25 16:36:21,230 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.dense.bias\n",
      "2021-11-25 16:36:21,231 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.dense.weight\n",
      "2021-11-25 16:36:21,233 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "2021-11-25 16:36:21,237 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "2021-11-25 16:36:21,238 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.dense.bias\n",
      "2021-11-25 16:36:21,239 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.dense.weight\n",
      "2021-11-25 16:36:21,243 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.key.bias\n",
      "2021-11-25 16:36:21,244 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.key.weight\n",
      "2021-11-25 16:36:21,251 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.query.bias\n",
      "2021-11-25 16:36:21,252 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.query.weight\n",
      "2021-11-25 16:36:21,253 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.value.bias\n",
      "2021-11-25 16:36:21,254 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.value.weight\n",
      "2021-11-25 16:36:21,257 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.intermediate.dense.bias\n",
      "2021-11-25 16:36:21,259 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.intermediate.dense.weight\n",
      "2021-11-25 16:36:21,264 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.LayerNorm.bias\n",
      "2021-11-25 16:36:21,268 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.LayerNorm.weight\n",
      "2021-11-25 16:36:21,269 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.dense.bias\n",
      "2021-11-25 16:36:21,271 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.dense.weight\n",
      "2021-11-25 16:36:21,274 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "2021-11-25 16:36:21,275 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "2021-11-25 16:36:21,278 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.dense.bias\n",
      "2021-11-25 16:36:21,286 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.dense.weight\n",
      "2021-11-25 16:36:21,289 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.key.bias\n",
      "2021-11-25 16:36:21,293 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.key.weight\n",
      "2021-11-25 16:36:21,294 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.query.bias\n",
      "2021-11-25 16:36:21,297 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.query.weight\n",
      "2021-11-25 16:36:21,298 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.value.bias\n",
      "2021-11-25 16:36:21,301 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.value.weight\n",
      "2021-11-25 16:36:21,302 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.intermediate.dense.bias\n",
      "2021-11-25 16:36:21,304 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.intermediate.dense.weight\n",
      "2021-11-25 16:36:21,305 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.LayerNorm.bias\n",
      "2021-11-25 16:36:21,306 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.LayerNorm.weight\n",
      "2021-11-25 16:36:21,309 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.dense.bias\n",
      "2021-11-25 16:36:21,312 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.dense.weight\n",
      "2021-11-25 16:36:21,316 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "2021-11-25 16:36:21,317 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "2021-11-25 16:36:21,321 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.dense.bias\n",
      "2021-11-25 16:36:21,322 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.dense.weight\n",
      "2021-11-25 16:36:21,328 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.key.bias\n",
      "2021-11-25 16:36:21,332 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.key.weight\n",
      "2021-11-25 16:36:21,340 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.query.bias\n",
      "2021-11-25 16:36:21,342 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.query.weight\n",
      "2021-11-25 16:36:21,347 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.value.bias\n",
      "2021-11-25 16:36:21,348 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.value.weight\n",
      "2021-11-25 16:36:21,349 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.intermediate.dense.bias\n",
      "2021-11-25 16:36:21,350 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.intermediate.dense.weight\n",
      "2021-11-25 16:36:21,352 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.LayerNorm.bias\n",
      "2021-11-25 16:36:21,355 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.LayerNorm.weight\n",
      "2021-11-25 16:36:21,370 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.dense.bias\n",
      "2021-11-25 16:36:21,374 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.dense.weight\n",
      "2021-11-25 16:36:21,376 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "2021-11-25 16:36:21,378 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "2021-11-25 16:36:21,382 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.dense.bias\n",
      "2021-11-25 16:36:21,384 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.dense.weight\n",
      "2021-11-25 16:36:21,390 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.key.bias\n",
      "2021-11-25 16:36:21,395 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.key.weight\n",
      "2021-11-25 16:36:21,397 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.query.bias\n",
      "2021-11-25 16:36:21,402 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.query.weight\n",
      "2021-11-25 16:36:21,406 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.value.bias\n",
      "2021-11-25 16:36:21,412 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.value.weight\n",
      "2021-11-25 16:36:21,414 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.intermediate.dense.bias\n",
      "2021-11-25 16:36:21,414 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.intermediate.dense.weight\n",
      "2021-11-25 16:36:21,416 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.LayerNorm.bias\n",
      "2021-11-25 16:36:21,417 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.LayerNorm.weight\n",
      "2021-11-25 16:36:21,419 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.dense.bias\n",
      "2021-11-25 16:36:21,421 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.dense.weight\n",
      "2021-11-25 16:36:21,425 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "2021-11-25 16:36:21,426 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "2021-11-25 16:36:21,427 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.dense.bias\n",
      "2021-11-25 16:36:21,429 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.dense.weight\n",
      "2021-11-25 16:36:21,433 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.key.bias\n",
      "2021-11-25 16:36:21,437 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.key.weight\n",
      "2021-11-25 16:36:21,439 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.query.bias\n",
      "2021-11-25 16:36:21,442 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.query.weight\n",
      "2021-11-25 16:36:21,448 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.value.bias\n",
      "2021-11-25 16:36:21,450 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.value.weight\n",
      "2021-11-25 16:36:21,451 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.intermediate.dense.bias\n",
      "2021-11-25 16:36:21,454 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.intermediate.dense.weight\n",
      "2021-11-25 16:36:21,455 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.LayerNorm.bias\n",
      "2021-11-25 16:36:21,459 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.LayerNorm.weight\n",
      "2021-11-25 16:36:21,460 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.dense.bias\n",
      "2021-11-25 16:36:21,463 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.dense.weight\n",
      "2021-11-25 16:36:21,466 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "2021-11-25 16:36:21,473 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "2021-11-25 16:36:21,475 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.dense.bias\n",
      "2021-11-25 16:36:21,479 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.dense.weight\n",
      "2021-11-25 16:36:21,483 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.key.bias\n",
      "2021-11-25 16:36:21,484 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.key.weight\n",
      "2021-11-25 16:36:21,484 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.query.bias\n",
      "2021-11-25 16:36:21,485 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.query.weight\n",
      "2021-11-25 16:36:21,485 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.value.bias\n",
      "2021-11-25 16:36:21,486 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.value.weight\n",
      "2021-11-25 16:36:21,487 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.intermediate.dense.bias\n",
      "2021-11-25 16:36:21,487 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.intermediate.dense.weight\n",
      "2021-11-25 16:36:21,488 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.LayerNorm.bias\n",
      "2021-11-25 16:36:21,488 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.LayerNorm.weight\n",
      "2021-11-25 16:36:21,489 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.dense.bias\n",
      "2021-11-25 16:36:21,490 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.dense.weight\n",
      "2021-11-25 16:36:21,491 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "2021-11-25 16:36:21,492 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "2021-11-25 16:36:21,492 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.dense.bias\n",
      "2021-11-25 16:36:21,493 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.dense.weight\n",
      "2021-11-25 16:36:21,496 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.key.bias\n",
      "2021-11-25 16:36:21,498 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.key.weight\n",
      "2021-11-25 16:36:21,499 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.query.bias\n",
      "2021-11-25 16:36:21,501 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.query.weight\n",
      "2021-11-25 16:36:21,502 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.value.bias\n",
      "2021-11-25 16:36:21,503 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.value.weight\n",
      "2021-11-25 16:36:21,505 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.intermediate.dense.bias\n",
      "2021-11-25 16:36:21,507 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.intermediate.dense.weight\n",
      "2021-11-25 16:36:21,508 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.LayerNorm.bias\n",
      "2021-11-25 16:36:21,509 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.LayerNorm.weight\n",
      "2021-11-25 16:36:21,510 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.dense.bias\n",
      "2021-11-25 16:36:21,510 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.dense.weight\n",
      "2021-11-25 16:36:21,512 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "2021-11-25 16:36:21,512 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "2021-11-25 16:36:21,513 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.dense.bias\n",
      "2021-11-25 16:36:21,514 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.dense.weight\n",
      "2021-11-25 16:36:21,514 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.key.bias\n",
      "2021-11-25 16:36:21,515 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.key.weight\n",
      "2021-11-25 16:36:21,516 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.query.bias\n",
      "2021-11-25 16:36:21,516 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.query.weight\n",
      "2021-11-25 16:36:21,517 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.value.bias\n",
      "2021-11-25 16:36:21,517 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.value.weight\n",
      "2021-11-25 16:36:21,518 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.intermediate.dense.bias\n",
      "2021-11-25 16:36:21,519 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.intermediate.dense.weight\n",
      "2021-11-25 16:36:21,520 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.LayerNorm.bias\n",
      "2021-11-25 16:36:21,521 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.LayerNorm.weight\n",
      "2021-11-25 16:36:21,521 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.dense.bias\n",
      "2021-11-25 16:36:21,522 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.dense.weight\n",
      "2021-11-25 16:36:21,523 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "2021-11-25 16:36:21,523 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "2021-11-25 16:36:21,524 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.dense.bias\n",
      "2021-11-25 16:36:21,525 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.dense.weight\n",
      "2021-11-25 16:36:21,526 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.key.bias\n",
      "2021-11-25 16:36:21,527 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.key.weight\n",
      "2021-11-25 16:36:21,527 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.query.bias\n",
      "2021-11-25 16:36:21,528 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.query.weight\n",
      "2021-11-25 16:36:21,529 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.value.bias\n",
      "2021-11-25 16:36:21,529 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.value.weight\n",
      "2021-11-25 16:36:21,530 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.intermediate.dense.bias\n",
      "2021-11-25 16:36:21,530 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.intermediate.dense.weight\n",
      "2021-11-25 16:36:21,531 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.LayerNorm.bias\n",
      "2021-11-25 16:36:21,532 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.LayerNorm.weight\n",
      "2021-11-25 16:36:21,532 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.dense.bias\n",
      "2021-11-25 16:36:21,533 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.dense.weight\n",
      "2021-11-25 16:36:21,534 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "2021-11-25 16:36:21,535 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "2021-11-25 16:36:21,536 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.dense.bias\n",
      "2021-11-25 16:36:21,536 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.dense.weight\n",
      "2021-11-25 16:36:21,537 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.key.bias\n",
      "2021-11-25 16:36:21,538 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.key.weight\n",
      "2021-11-25 16:36:21,538 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.query.bias\n",
      "2021-11-25 16:36:21,539 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.query.weight\n",
      "2021-11-25 16:36:21,539 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.value.bias\n",
      "2021-11-25 16:36:21,540 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.value.weight\n",
      "2021-11-25 16:36:21,541 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.intermediate.dense.bias\n",
      "2021-11-25 16:36:21,542 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.intermediate.dense.weight\n",
      "2021-11-25 16:36:21,543 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.LayerNorm.bias\n",
      "2021-11-25 16:36:21,543 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.LayerNorm.weight\n",
      "2021-11-25 16:36:21,545 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.dense.bias\n",
      "2021-11-25 16:36:21,546 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.dense.weight\n",
      "2021-11-25 16:36:21,547 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "2021-11-25 16:36:21,549 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "2021-11-25 16:36:21,549 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.dense.bias\n",
      "2021-11-25 16:36:21,550 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.dense.weight\n",
      "2021-11-25 16:36:21,551 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.key.bias\n",
      "2021-11-25 16:36:21,551 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.key.weight\n",
      "2021-11-25 16:36:21,552 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.query.bias\n",
      "2021-11-25 16:36:21,553 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.query.weight\n",
      "2021-11-25 16:36:21,553 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.value.bias\n",
      "2021-11-25 16:36:21,554 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.value.weight\n",
      "2021-11-25 16:36:21,555 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.intermediate.dense.bias\n",
      "2021-11-25 16:36:21,556 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.intermediate.dense.weight\n",
      "2021-11-25 16:36:21,557 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.LayerNorm.bias\n",
      "2021-11-25 16:36:21,558 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.LayerNorm.weight\n",
      "2021-11-25 16:36:21,558 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.dense.bias\n",
      "2021-11-25 16:36:21,559 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.dense.weight\n",
      "2021-11-25 16:36:21,559 - INFO - allennlp.nn.initializers -    bert_model.pooler.dense.bias\n",
      "2021-11-25 16:36:21,560 - INFO - allennlp.nn.initializers -    bert_model.pooler.dense.weight\n",
      "2021-11-25 16:36:21,563 - INFO - allennlp.nn.initializers -    tag_projection_layer.bias\n",
      "2021-11-25 16:36:21,564 - INFO - allennlp.nn.initializers -    tag_projection_layer.weight\n",
      "2021-11-25 16:36:23,124 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /tmp/tmp_wh_ew5u\n"
     ]
    }
   ],
   "source": [
    "srl_predictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/structured-prediction-srl-bert.2020.12.15.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "022436b0-d987-4c02-9ec8-6c8b47489dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLOR_CONCEPT_1 = 1\n",
    "COLOR_CONCEPT_2 = 4\n",
    "COLOR_CONTENT_RELATION_EXPLANATION = 0\n",
    "NO_COLOR = -1\n",
    "RELATION_VERBS = [ \"achieve\", \"allow\", \"avoid\", \"balance\", \"boost\", \"bring\", \"brought\", \"consolidate\", \"compromise\",  \"contain\", \"contribute\", \n",
    "                   \"eliminate\", \"endanger\", \"entail\", \"ensure\", \"erode\", \"fail\", \"flow\", \"gave\", \"give\", \"given\", \"increase\", \"open\", \"preserve\", \"protect\", \n",
    "                   \"reduce\", \"reinforce\", \"restore\", \"result\", \"safeguard\", \"secure\", \"strenghten\", \"support\", \"tackle\", \"trigger\", \"undermine\", \"weaken\", ]\n",
    "REVERSE_VERBS = [ \"arise\", \"need\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfb6f8c8-dcc8-4c89-93b4-78d1afab73df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_tag(token):\n",
    "    if len(token) > 1:\n",
    "        if re.search(\"^\\[\", token):\n",
    "            token = re.sub(\"^\\[\", \"\", token)\n",
    "            token = re.sub(\":$\", \"\", token)\n",
    "        token = re.sub(\"\\]$\", \"\", token)\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f33cca46-632f-4cfc-8f50-aae6f0e8fbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_with_color(string, color_code):\n",
    "    print(f\"\\x1b[1;3{color_code};47m{string}\\x1b[m\", end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ac4738ff-d132-47ea-89c9-3bc4dec25543",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_argm_prp(token, argument, first_token, last_token):\n",
    "    if argument == \"ARGM-PRP\":\n",
    "        color_code = COLOR_CONCEPT_2\n",
    "    elif argument in [\"V\", \"ARG0\", \"ARG1\", \"ARG2\" ]:\n",
    "        color_code = COLOR_CONCEPT_1\n",
    "    else:\n",
    "        color_code = NO_COLOR\n",
    "    if color_code == NO_COLOR:\n",
    "        print_token(token, argument, first_token, last_token)\n",
    "    else:\n",
    "        print_token_color(token, argument, first_token, last_token, color_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "75f9d05f-0b73-48ce-9604-ba7283d051c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_argm_dis(token, argument, first_token, last_token):\n",
    "    color_code = NO_COLOR\n",
    "    if argument == \"ARGM-DIS\":\n",
    "        color_code = COLOR_CONTENT_RELATION_EXPLANATION\n",
    "    elif arguments != \"\":\n",
    "        color_code = COLOR_CONCEPT_2\n",
    "    if color_code == NO_COLOR:\n",
    "        print_token(token, argument, first_token, last_token)\n",
    "    else:\n",
    "        print_token_color(token, argument, first_token, last_token, color_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "fe60a35d-1501-44d9-9aab-0bb7b150bcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_v(token, argument, first_token, last_token):\n",
    "    if argument == \"V\":\n",
    "        color_code = COLOR_CONTENT_RELATION_EXPLANATION\n",
    "    elif argument == \"ARG0\":\n",
    "        color_code = COLOR_CONCEPT_1\n",
    "    elif argument in [ \"ARG1\", \"ARG2\" ]:\n",
    "        color_code = COLOR_CONCEPT_2\n",
    "    else:\n",
    "        color_code = NO_COLOR\n",
    "    if color_code == NO_COLOR:\n",
    "        print_token(token, argument, first_token, last_token)\n",
    "    else:\n",
    "        print_token_color(token, argument, first_token, last_token, color_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "05549e58-5850-4ec6-a685-8470df89da05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_reverse_v(token, argument, first_token, last_token):\n",
    "    if argument == \"V\":\n",
    "        color_code = COLOR_CONTENT_RELATION_EXPLANATION\n",
    "    elif argument == \"ARG0\":\n",
    "        color_code = COLOR_CONCEPT_2\n",
    "    elif argument in [ \"ARG1\", \"ARG2\" ]:\n",
    "        color_code = COLOR_CONCEPT_1\n",
    "    else:\n",
    "        color_code = NO_COLOR\n",
    "    if color_code == NO_COLOR:\n",
    "        print_token(token, argument, first_token, last_token)\n",
    "    else:\n",
    "        print_token_color(token, argument, first_token, last_token, color_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94001968-cb87-49f3-98bb-3ecc19973f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_verb(verb, RELATION_VERBS):\n",
    "    if verb in RELATION_VERBS:\n",
    "        return True\n",
    "    if re.sub(\"[ds]$\", \"\", verb) in RELATION_VERBS:\n",
    "        return True\n",
    "    if re.sub(\"ed$\", \"\", verb) in RELATION_VERBS:\n",
    "        return True\n",
    "    if re.sub(\"ing$\", \"\", verb) in RELATION_VERBS:\n",
    "        return True\n",
    "    if re.sub(\"ing$\", \"e\", verb) in RELATION_VERBS:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e0f3a494-5bb6-461b-bc0a-10e20773f1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_token(token, argument, first_token, last_token):\n",
    "    if first_token:\n",
    "        print(f\"[{argument} \", end=\"\")\n",
    "    print(f\"{token}\", end=\"\")\n",
    "    if last_token:\n",
    "        print(f\"]\", end=\"\")\n",
    "    print(\" \", end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f5782a6a-2908-434f-86c6-9a9b132765de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_token_color(token, argument, first_token, last_token, color_code):\n",
    "    if first_token:\n",
    "        print_with_color(f\"[{argument} \", color_code)\n",
    "    print_with_color(f\"{token}\", color_code)\n",
    "    if last_token:\n",
    "        print_with_color(f\"]\", color_code)\n",
    "        print(\" \", end=\"\")\n",
    "    else:\n",
    "        print_with_color(\" \", color_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ae3f8846-942f-45f5-8305-df86673318f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_verb(tokens, arguments):\n",
    "    verb = \"\"\n",
    "    for i in range(0, len(arguments)):\n",
    "        if arguments[i] == \"V\":\n",
    "            verb = tokens[i]\n",
    "    return verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "31a63481-9434-43ff-9146-6a5fb0b39520",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print(analyzed_sentence, lemmas):\n",
    "    tokens, arguments, first_tokens, last_tokens = convert_analysis(analyzed_sentence)\n",
    "    for i in range(0, len(tokens)):\n",
    "        if \"ARGM-PRP\" in arguments:\n",
    "            print_argm_prp(tokens[i], arguments[i], first_tokens[i], last_tokens[i])\n",
    "        elif \"ARGM-DIS\" in arguments:\n",
    "            print_argm_dis(tokens[i], arguments[i], first_tokens[i], last_tokens[i])\n",
    "        elif \"V\" in arguments and check_verb(find_verb(tokens, arguments), RELATION_VERBS):\n",
    "            print_v(tokens[i], arguments[i], first_tokens[i], last_tokens[i])\n",
    "        elif \"V\" in arguments and check_verb(find_verb(tokens, arguments), REVERSE_VERBS):\n",
    "            print_reverse_v(tokens[i], arguments[i], first_tokens[i], last_tokens[i])\n",
    "        else:\n",
    "            print_token(tokens[i], arguments[i], first_tokens[i], last_tokens[i])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "07e72660-d826-49ff-ac3a-40b69d19233f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_analysis(analyzed_sentence):\n",
    "    tokens_in = analyzed_sentence.split()\n",
    "    arguments = []\n",
    "    tokens_out = []\n",
    "    first_tokens = []\n",
    "    last_tokens = []\n",
    "    current_argument = \"\"\n",
    "    first_token = False\n",
    "    for i in range(0, len(tokens_in)):\n",
    "        if re.search(\"^\\[\", tokens_in[i]):\n",
    "            current_argument = strip_tag(tokens_in[i])\n",
    "            first_token = True\n",
    "            continue\n",
    "        arguments.append(current_argument)\n",
    "        tokens_out.append(strip_tag(tokens_in[i]))\n",
    "        first_tokens.append(first_token)\n",
    "        last_tokens.append(False)\n",
    "        if re.search(\"\\]$\", tokens_in[i]):\n",
    "            current_argument = \"\"\n",
    "            last_tokens[-1] = True\n",
    "        first_token = False\n",
    "    return [tokens_out, arguments, first_tokens, last_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3057805e-406f-48e5-82f2-b57713e6c38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(sentence):\n",
    "    srl_analysis = srl_predictor.predict(sentence=sentence)\n",
    "    lemmas = get_lemmas(re.sub(\"\\s+\", \" \", sentence))\n",
    "    for verb_data in srl_analysis['verbs']:\n",
    "        pretty_print(verb_data['description'], lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad4fe971-e31e-4f11-abf8-063397bb879d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lemmas(sentence):\n",
    "    lemmas = []\n",
    "    results = spacy_analyze(sentence)\n",
    "    for token in results:\n",
    "        lemmas.append(token.lemma_)\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5a15844e-570e-4d1f-be62-b2f953dedbc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ARG0 John] [V sees] [ARG1 the mountain with the snow] \n"
     ]
    }
   ],
   "source": [
    "analyze(\"John sees the mountain with the snow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d1011a94-4b99-445b-a402-8d8da2b2c102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34;47m[ARG0 \u001b[m\u001b[1;34;47mYou\u001b[m\u001b[1;34;47m]\u001b[m , [ARGM-LOC in Greece] , [ARGM-MNR with our support] , \u001b[1;30;47m[V \u001b[m\u001b[1;30;47mneed\u001b[m\u001b[1;30;47m]\u001b[m \u001b[1;31;47m[ARG1 \u001b[m\u001b[1;31;47mto\u001b[m\u001b[1;31;47m \u001b[m\u001b[1;31;47mrebuild\u001b[m\u001b[1;31;47m \u001b[m\u001b[1;31;47myour\u001b[m\u001b[1;31;47m \u001b[m\u001b[1;31;47mcountry\u001b[m\u001b[1;31;47m \u001b[m\u001b[1;31;47m,\u001b[m\u001b[1;31;47m \u001b[m\u001b[1;31;47myour\u001b[m\u001b[1;31;47m \u001b[m\u001b[1;31;47mstructures\u001b[m\u001b[1;31;47m \u001b[m\u001b[1;31;47m,\u001b[m\u001b[1;31;47m \u001b[m\u001b[1;31;47myour\u001b[m\u001b[1;31;47m \u001b[m\u001b[1;31;47madministration\u001b[m\u001b[1;31;47m \u001b[m\u001b[1;31;47m,\u001b[m\u001b[1;31;47m \u001b[m\u001b[1;31;47myour\u001b[m\u001b[1;31;47m \u001b[m\u001b[1;31;47meconomy\u001b[m\u001b[1;31;47m \u001b[m\u001b[1;31;47mto\u001b[m\u001b[1;31;47m \u001b[m\u001b[1;31;47mincrease\u001b[m\u001b[1;31;47m \u001b[m\u001b[1;31;47mthe\u001b[m\u001b[1;31;47m \u001b[m\u001b[1;31;47mcompetitiveness\u001b[m\u001b[1;31;47m \u001b[m\u001b[1;31;47mof\u001b[m\u001b[1;31;47m \u001b[m\u001b[1;31;47mGreece\u001b[m\u001b[1;31;47m]\u001b[m . \n",
      "\u001b[1;31;47m[ARG0 \u001b[m\u001b[1;31;47mYou\u001b[m\u001b[1;31;47m]\u001b[m , in Greece , with our support , need to \u001b[1;31;47m[V \u001b[m\u001b[1;31;47mrebuild\u001b[m\u001b[1;31;47m]\u001b[m \u001b[1;31;47m[ARG1 \u001b[m\u001b[1;31;47myour\u001b[m\u001b[1;31;47m \u001b[m\u001b[1;31;47mcountry\u001b[m\u001b[1;31;47m \u001b[m\u001b[1;31;47m,\u001b[m\u001b[1;31;47m \u001b[m\u001b[1;31;47myour\u001b[m\u001b[1;31;47m \u001b[m\u001b[1;31;47mstructures\u001b[m\u001b[1;31;47m \u001b[m\u001b[1;31;47m,\u001b[m\u001b[1;31;47m \u001b[m\u001b[1;31;47myour\u001b[m\u001b[1;31;47m \u001b[m\u001b[1;31;47madministration\u001b[m\u001b[1;31;47m \u001b[m\u001b[1;31;47m,\u001b[m\u001b[1;31;47m \u001b[m\u001b[1;31;47myour\u001b[m\u001b[1;31;47m \u001b[m\u001b[1;31;47meconomy\u001b[m\u001b[1;31;47m]\u001b[m \u001b[1;34;47m[ARGM-PRP \u001b[m\u001b[1;34;47mto\u001b[m\u001b[1;34;47m \u001b[m\u001b[1;34;47mincrease\u001b[m\u001b[1;34;47m \u001b[m\u001b[1;34;47mthe\u001b[m\u001b[1;34;47m \u001b[m\u001b[1;34;47mcompetitiveness\u001b[m\u001b[1;34;47m \u001b[m\u001b[1;34;47mof\u001b[m\u001b[1;34;47m \u001b[m\u001b[1;34;47mGreece\u001b[m\u001b[1;34;47m]\u001b[m . \n",
      "You , in Greece , with our support , need to rebuild your country , your structures , your administration , your economy to \u001b[1;30;47m[V \u001b[m\u001b[1;30;47mincrease\u001b[m\u001b[1;30;47m]\u001b[m \u001b[1;34;47m[ARG1 \u001b[m\u001b[1;34;47mthe\u001b[m\u001b[1;34;47m \u001b[m\u001b[1;34;47mcompetitiveness\u001b[m\u001b[1;34;47m \u001b[m\u001b[1;34;47mof\u001b[m\u001b[1;34;47m \u001b[m\u001b[1;34;47mGreece\u001b[m\u001b[1;34;47m]\u001b[m . \n"
     ]
    }
   ],
   "source": [
    "analyze(\"\"\"You, in Greece, with our support, need to rebuild your country, your structures, your administration, \n",
    "           your economy to increase the competitiveness of Greece.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "315abf68-be8c-4f3d-bf4c-2df02c86b2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;47m[ARG0: \u001b[m\u001b[1;31;47mThis] \u001b[m\u001b[1;30;47m[V: \u001b[m\u001b[1;30;47mopened] \u001b[m\u001b[1;34;47m[ARG1: \u001b[m\u001b[1;34;47mthe \u001b[m\u001b[1;34;47mway \u001b[m\u001b[1;34;47mto \u001b[m\u001b[1;34;47mwelfare \u001b[m\u001b[1;34;47mgains \u001b[m\u001b[1;34;47mfrom \u001b[m\u001b[1;34;47mstronger \u001b[m\u001b[1;34;47meconomic \u001b[m\u001b[1;34;47mand \u001b[m\u001b[1;34;47mfinancial \u001b[m\u001b[1;34;47mintegration] \u001b[m. \n"
     ]
    }
   ],
   "source": [
    "analyze(\"This opened the way to welfare gains from stronger economic and financial integration.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f79c931-5910-4e5e-906c-cf0038e13294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ARG1: One risk] [V: is] [ARG2: the temptation for governments to overborrow because the economic costs of excessive public debt] \n"
     ]
    }
   ],
   "source": [
    "analyze(\"One risk is the temptation for governments to overborrow because the economic costs of excessive public debt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5790cf17-2704-4467-95ac-20f071abfff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A \u001b[1;30;47m[V: \u001b[m\u001b[1;30;47mresulting] \u001b[m\u001b[1;34;47m[ARG2: \u001b[m\u001b[1;34;47mloosening] \u001b[mof fiscal discipline in individual member states can endanger the stability - oriented monetary policy . \n",
      "A resulting loosening of fiscal discipline in individual member states [V: can] endanger the stability - oriented monetary policy . \n",
      "\u001b[1;31;47m[ARG0: \u001b[m\u001b[1;31;47mA \u001b[m\u001b[1;31;47mresulting \u001b[m\u001b[1;31;47mloosening \u001b[m\u001b[1;31;47mof \u001b[m\u001b[1;31;47mfiscal \u001b[m\u001b[1;31;47mdiscipline \u001b[m\u001b[1;31;47min \u001b[m\u001b[1;31;47mindividual \u001b[m\u001b[1;31;47mmember \u001b[m\u001b[1;31;47mstates] \u001b[m[ARGM-MOD: can] \u001b[1;30;47m[V: \u001b[m\u001b[1;30;47mendanger] \u001b[m\u001b[1;34;47m[ARG1: \u001b[m\u001b[1;34;47mthe \u001b[m\u001b[1;34;47mstability \u001b[m\u001b[1;34;47m- \u001b[m\u001b[1;34;47moriented \u001b[m\u001b[1;34;47mmonetary \u001b[m\u001b[1;34;47mpolicy] \u001b[m. \n",
      "A resulting loosening of fiscal discipline in individual member states can endanger the [ARGM-MNR: stability] - [V: oriented] [ARG1: monetary policy] . \n"
     ]
    }
   ],
   "source": [
    "analyze(\"A resulting loosening of fiscal discipline in individual member states can endanger the stability-oriented monetary policy.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bee739b0-6890-44c8-9243-ba7232cfd06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Therefore , the markets [V: did] not properly perform their expected policing function . \n",
      "\u001b[1;30;47m[ARGM-DIS: \u001b[m\u001b[1;30;47mTherefore] \u001b[m, \u001b[1;34;47m[ARG0: \u001b[m\u001b[1;34;47mthe \u001b[m\u001b[1;34;47mmarkets] \u001b[mdid \u001b[1;34;47m[ARGM-NEG: \u001b[m\u001b[1;34;47mnot] \u001b[m\u001b[1;34;47m[ARGM-MNR: \u001b[m\u001b[1;34;47mproperly] \u001b[m\u001b[1;34;47m[V: \u001b[m\u001b[1;34;47mperform] \u001b[m\u001b[1;34;47m[ARG1: \u001b[m\u001b[1;34;47mtheir \u001b[m\u001b[1;34;47mexpected \u001b[m\u001b[1;34;47mpolicing \u001b[m\u001b[1;34;47mfunction] \u001b[m. \n",
      "Therefore , the markets did not properly perform their [V: expected] [ARG1: policing function] . \n"
     ]
    }
   ],
   "source": [
    "analyze(\"Therefore, the markets did not properly perform their expected policing function.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f1a41ca-b0ba-48c7-99f3-c4475ce51df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ARG0: I] [V: hope] [ARG1: that following the lessons of interdependence not only at global , but also at European level given by the crisis] \n",
      "I hope that [V: following] [ARG1: the lessons of interdependence] [ARGM-LOC: not only at global , but also at European level given by the crisis] \n",
      "I hope that following \u001b[1;34;47m[ARG1: \u001b[m\u001b[1;34;47mthe \u001b[m\u001b[1;34;47mlessons \u001b[m\u001b[1;34;47mof \u001b[m\u001b[1;34;47minterdependence] \u001b[mnot only at global , but also at European level \u001b[1;30;47m[V: \u001b[m\u001b[1;30;47mgiven] \u001b[m\u001b[1;31;47m[ARG0: \u001b[m\u001b[1;31;47mby \u001b[m\u001b[1;31;47mthe \u001b[m\u001b[1;31;47mcrisis] \u001b[m\n"
     ]
    }
   ],
   "source": [
    "analyze(\"I hope that following the lessons of interdependence not only at global, but also at European level given by the crisis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6907cf65-d7d1-4f2b-834c-c8725a789efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34;47m[ARG0: \u001b[m\u001b[1;34;47mEuropean \u001b[m\u001b[1;34;47meconomic \u001b[m\u001b[1;34;47mstrategy] \u001b[m\u001b[1;30;47m[V: \u001b[m\u001b[1;30;47mneeds] \u001b[m\u001b[1;31;47m[ARG1: \u001b[m\u001b[1;31;47mthe \u001b[m\u001b[1;31;47mfull \u001b[m\u001b[1;31;47mcommitment \u001b[m\u001b[1;31;47mof \u001b[m\u001b[1;31;47mthe \u001b[m\u001b[1;31;47mEuropean \u001b[m\u001b[1;31;47mpolitical \u001b[m\u001b[1;31;47mcommunity] \u001b[m. \n"
     ]
    }
   ],
   "source": [
    "analyze(\"European economic strategy needs the full commitment of the European political community.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "459c7201-cc64-4b74-ad11-4558a8e249fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And a European economic system \u001b[1;34;47m[ARG1: \u001b[m\u001b[1;34;47mwhose \u001b[m\u001b[1;34;47mresilience] \u001b[m\u001b[1;30;47m[V: \u001b[m\u001b[1;30;47mflows] \u001b[m[ARGM-DIR: from its single market] \n"
     ]
    }
   ],
   "source": [
    "analyze(\"And a European economic system whose resilience flows from its single market\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b72ed91-af91-4c2f-9c75-193561125851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there \u001b[1;34;47m[V: \u001b[m\u001b[1;34;47mare] \u001b[m\u001b[1;30;47m[ARGM-DIS: \u001b[m\u001b[1;30;47mof \u001b[m\u001b[1;30;47mcourse] \u001b[m\u001b[1;34;47m[ARG1: \u001b[m\u001b[1;34;47mconsiderable \u001b[m\u001b[1;34;47mbudgetary \u001b[m\u001b[1;34;47mchallenges \u001b[m\u001b[1;34;47marising \u001b[m\u001b[1;34;47mfrom \u001b[m\u001b[1;34;47mthe \u001b[m\u001b[1;34;47mrecent \u001b[m\u001b[1;34;47mexceptional \u001b[m\u001b[1;34;47mmeasures] \u001b[m\n",
      "there are of course \u001b[1;31;47m[ARG1: \u001b[m\u001b[1;31;47mconsiderable \u001b[m\u001b[1;31;47mbudgetary \u001b[m\u001b[1;31;47mchallenges] \u001b[m\u001b[1;30;47m[V: \u001b[m\u001b[1;30;47marising] \u001b[m\u001b[1;31;47m[ARG2: \u001b[m\u001b[1;31;47mfrom \u001b[m\u001b[1;31;47mthe \u001b[m\u001b[1;31;47mrecent \u001b[m\u001b[1;31;47mexceptional \u001b[m\u001b[1;31;47mmeasures] \u001b[m\n"
     ]
    }
   ],
   "source": [
    "analyze(\"there are of course considerable budgetary challenges arising from the recent exceptional measures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed79018-85a0-45fb-9d5c-2f1947602cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(\"And the best hope of a return to growth and job creation is inside the euro area.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da62399a-2a30-4bfd-a4eb-ce2215579c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(\"To conclude, let me say a few words on the euro area more generally.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d41d16d-acbf-4da7-9afe-0992057f9fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(\"\"\"We have taken important, fundamental decisions over the last couple of months to safeguard the stability \n",
    "           of the euro area, and indeed we are now in the phase of implementation.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc28fe0-2fd8-40f0-bb47-e66a0dbc7822",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(\"\"\"A number of governments have embarked on a path of reform and fiscal consolidation that was unthinkable only \n",
    "           very recently, and they have taken important decisions and I encourage them to keep this determination.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3608204a-2217-4403-896d-10b5b02f0f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(\"\"\"These reforms are now being implemented and this effort must continue with credibility, with consistency, \n",
    "           with coherence over time.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21df66a7-1c41-43a5-a953-c40ac915e150",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(\"As we said there will not be magic solutions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e08438-0804-4afb-a771-5f848fd6278e",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(\"We need sustained efforts and determination.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cd2b3d-b1ad-4a4a-b690-6d86877ef10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(\"At the same time, the existing financial backstops are being used as necessary.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bbefe2-4e57-495d-886c-d76f4b240d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(\"\"\"Most recently, the financial assistance to the recapitalisation of Spanish banks has been agreed \n",
    "           and is ready for implementation.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985bbeaa-a66b-4ee9-8bef-a512bca9cbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(\"\"\"Giving to the ECB the ultimate responsibility for supervision of banks in the euro area \n",
    "           will decisively contribute to increase confidence between the banks \n",
    "           and in this way increase the financial stability in the euro area.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74993ff-629f-4444-a3e9-95d936869c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(\"Second, Germany is acutely aware of the need to tackle the root causes and not just the symptoms of the crisis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae9f741-68e7-4ae0-b1de-5ecb8723f609",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(\"\"\"This is why it is pressing strongly for institutional reforms of the EMU framework plus structural reforms \n",
    "           and budgetary discipline in the member states.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2040f38a-a5a9-4985-bec9-5407b44785a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(\"The introduction of the euro eliminated exchange rate risks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12883bd7-edda-4218-9303-1765e061dc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(\"\"\"Another implication of the euro area's single monetary policy is that the key interest rates \n",
    "           are set for the currency bloc as a whole.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0a3592-99cf-48eb-acdd-9cfd79fff765",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(\"\"\"One risk is the temptation for governments to overborrow because the economic costs of excessive public debt, \n",
    "           for example higher interest rates, can be more easily shifted to other member states.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9960a6-24ea-4ee9-b260-6112c96cd9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(\"\"\"Even Germany ran up excessive deficits for a few years and, even worse, championed a reform of the SGP \n",
    "           which ultimately further weakened the application of the fiscal rules.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d20c14-9a56-4456-8abb-6dd8debb1b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(\"\"\"However, the EMU framework not only failed to avoid excessive deficits, it was also unable to prevent \n",
    "           the build-up of macroeconomic imbalances within the euro area.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931baf3e-958f-4ad6-a998-a4f8ea2cfcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(\"\"\"The resulting increase in domestic inflation and wages eroded the competitiveness of the countries concerned and \n",
    "           increased their dependence on capital imports.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87956f23-b8ce-48ff-8ddf-2d6ce8b5e0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(\"The task of implementing the reforms and regaining competitiveness entailed significant political and social costs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f2d27b-0dc7-48cd-9cdd-4b99aa507cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(\"\"\"However, these efforts, supported by a strong expansion in the global economy, allowed German growth to rebound \n",
    "           after 2005.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d13dc9-f815-4348-9384-b9a18d20e660",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(\"\"\"In order to achieve a turnaround and allow further assistance, it is now essential for Greece to deliver \n",
    "           on the promises that have been made.\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588908d7-0689-4902-b868-95fe6b5747ef",
   "metadata": {},
   "source": [
    "Modifiers in Propbank (source: http://clear.colorado.edu/compsem/documents/propbank_guidelines.pdf )\n",
    "* ADJ: Adjectival\n",
    "* ADV: Adverbials\n",
    "* CAU: Cause\n",
    "* COM: Comitative\n",
    "* DIR: Directional\n",
    "* DIS: Discourse\n",
    "* DSP: Direct Speech\n",
    "* EXT: Extent\n",
    "* GOL: Goal\n",
    "* LOC: Locative\n",
    "* LVB: Light Verb\n",
    "* MNR: Manner\n",
    "* MOD: Modal\n",
    "* NEG: Negation\n",
    "* PRD: Secondary Predication\n",
    "* PRP: Purpose\n",
    "* REC: Reciprocals\n",
    "* SLC: Relative Clause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1b7da2-a7d6-4031-8881-6ca37bd6ddaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "allennlp",
   "language": "python",
   "name": "allennlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
