{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "097cf9b2-c835-4d63-93e6-fb98636763f9",
   "metadata": {},
   "source": [
    "# AllenNLP tests\n",
    "\n",
    "Use AllenNLP's semantic role labeling in combination with manually written rules for extracting causal relations from political speeches. We found two limitations: only relations within a single sentence were found and complex relations involving understanding the sentence were hard to identify.\n",
    "\n",
    "Links:\n",
    "\n",
    "* software installation: https://github.com/allenai/allennlp (do not forget to install NLTK popular models)\n",
    "* software usage: https://demo.allennlp.org/semantic-role-labeling (tab: Model Usage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc310b0-1c94-4561-b41d-b76cfd4a48a5",
   "metadata": {},
   "source": [
    "## 1. Language processing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4d59808-a18f-4dfe-970a-35ac0d46f573",
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.predictors.predictor import Predictor\n",
    "import allennlp_models.tagging\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684ed53c-b3e5-4cf0-bd00-023d00367908",
   "metadata": {},
   "source": [
    "We use AllenNLP for semantic role labeling and Spacy for lemmatization (of verbs) and tokenizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "403ac43b-17a2-41ca-8826-7651f5f3105c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_analyze = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "289eae14-db61-4df0-baec-41b07319a109",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erikt/anaconda3/envs/allennlp/lib/python3.7/site-packages/allennlp/tango/__init__.py:18: UserWarning: AllenNLP Tango is an experimental API and parts of it might change or disappear every time we release a new version.\n",
      "  \"AllenNLP Tango is an experimental API and parts of it might change or disappear \"\n",
      "2021-12-10 14:55:13,500 - INFO - allennlp.common.plugins - Plugin allennlp_models available\n",
      "2021-12-10 14:55:13,774 - INFO - cached_path - cache of https://storage.googleapis.com/allennlp-public-models/structured-prediction-srl-bert.2020.12.15.tar.gz is up-to-date\n",
      "2021-12-10 14:55:13,777 - INFO - allennlp.models.archival - loading archive file https://storage.googleapis.com/allennlp-public-models/structured-prediction-srl-bert.2020.12.15.tar.gz from cache at /home/erikt/.allennlp/cache/b5f1db011cc85691a5fa2bf29e055a712261a2e5d74a74edd7da2fffc98d4ab8.4c4ac7e06ec3d85631bd26b839f90b5a375d3ceeb43e3c74f1cf4758dcee2bb3\n",
      "2021-12-10 14:55:13,783 - INFO - allennlp.models.archival - extracting archive file /home/erikt/.allennlp/cache/b5f1db011cc85691a5fa2bf29e055a712261a2e5d74a74edd7da2fffc98d4ab8.4c4ac7e06ec3d85631bd26b839f90b5a375d3ceeb43e3c74f1cf4758dcee2bb3 to temp dir /tmp/tmpdo4zhma6\n",
      "2021-12-10 14:55:17,413 - INFO - allennlp.common.params - dataset_reader.type = srl\n",
      "2021-12-10 14:55:17,414 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
      "2021-12-10 14:55:17,414 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
      "2021-12-10 14:55:17,415 - INFO - allennlp.common.params - dataset_reader.manual_multiprocess_sharding = False\n",
      "2021-12-10 14:55:17,415 - INFO - allennlp.common.params - dataset_reader.token_indexers = None\n",
      "2021-12-10 14:55:17,416 - INFO - allennlp.common.params - dataset_reader.domain_identifier = None\n",
      "2021-12-10 14:55:17,416 - INFO - allennlp.common.params - dataset_reader.bert_model_name = bert-base-uncased\n",
      "2021-12-10 14:55:17,417 - INFO - allennlp.common.params - type = bert-base-uncased\n",
      "2021-12-10 14:55:30,231 - INFO - allennlp.common.params - dataset_reader.type = srl\n",
      "2021-12-10 14:55:30,232 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
      "2021-12-10 14:55:30,233 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
      "2021-12-10 14:55:30,233 - INFO - allennlp.common.params - dataset_reader.manual_multiprocess_sharding = False\n",
      "2021-12-10 14:55:30,234 - INFO - allennlp.common.params - dataset_reader.token_indexers = None\n",
      "2021-12-10 14:55:30,236 - INFO - allennlp.common.params - dataset_reader.domain_identifier = None\n",
      "2021-12-10 14:55:30,237 - INFO - allennlp.common.params - dataset_reader.bert_model_name = bert-base-uncased\n",
      "2021-12-10 14:55:30,238 - INFO - allennlp.common.params - type = bert-base-uncased\n",
      "2021-12-10 14:55:33,693 - INFO - allennlp.common.params - type = from_instances\n",
      "2021-12-10 14:55:33,694 - INFO - allennlp.data.vocabulary - Loading token dictionary from /tmp/tmpdo4zhma6/vocabulary.\n",
      "2021-12-10 14:55:33,697 - INFO - allennlp.common.params - model.type = srl_bert\n",
      "2021-12-10 14:55:33,697 - INFO - allennlp.common.params - model.regularizer = None\n",
      "2021-12-10 14:55:33,698 - INFO - allennlp.common.params - model.ddp_accelerator = None\n",
      "2021-12-10 14:55:33,699 - INFO - allennlp.common.params - model.bert_model = bert-base-uncased\n",
      "2021-12-10 14:55:33,699 - INFO - allennlp.common.params - type = bert-base-uncased\n",
      "2021-12-10 14:55:33,700 - INFO - allennlp.common.params - type = bert-base-uncased\n",
      "2021-12-10 14:55:33,701 - INFO - allennlp.common.params - model.embedding_dropout = 0.1\n",
      "2021-12-10 14:55:33,701 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7f96694515d0>\n",
      "2021-12-10 14:55:33,702 - INFO - allennlp.common.params - model.label_smoothing = None\n",
      "2021-12-10 14:55:33,702 - INFO - allennlp.common.params - model.ignore_span_metric = False\n",
      "2021-12-10 14:55:33,703 - INFO - allennlp.common.params - model.srl_eval_path = /home/erikt/anaconda3/envs/allennlp/lib/python3.7/site-packages/allennlp_models/structured_prediction/tools/srl-eval.pl\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "2021-12-10 14:55:36,215 - INFO - allennlp.nn.initializers - Initializing parameters\n",
      "2021-12-10 14:55:36,217 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
      "2021-12-10 14:55:36,218 - INFO - allennlp.nn.initializers -    bert_model.embeddings.LayerNorm.bias\n",
      "2021-12-10 14:55:36,220 - INFO - allennlp.nn.initializers -    bert_model.embeddings.LayerNorm.weight\n",
      "2021-12-10 14:55:36,221 - INFO - allennlp.nn.initializers -    bert_model.embeddings.position_embeddings.weight\n",
      "2021-12-10 14:55:36,222 - INFO - allennlp.nn.initializers -    bert_model.embeddings.token_type_embeddings.weight\n",
      "2021-12-10 14:55:36,224 - INFO - allennlp.nn.initializers -    bert_model.embeddings.word_embeddings.weight\n",
      "2021-12-10 14:55:36,227 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "2021-12-10 14:55:36,228 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "2021-12-10 14:55:36,229 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.dense.bias\n",
      "2021-12-10 14:55:36,231 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.dense.weight\n",
      "2021-12-10 14:55:36,232 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.key.bias\n",
      "2021-12-10 14:55:36,233 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.key.weight\n",
      "2021-12-10 14:55:36,235 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.query.bias\n",
      "2021-12-10 14:55:36,237 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.query.weight\n",
      "2021-12-10 14:55:36,239 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.value.bias\n",
      "2021-12-10 14:55:36,240 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.value.weight\n",
      "2021-12-10 14:55:36,242 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.intermediate.dense.bias\n",
      "2021-12-10 14:55:36,244 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.intermediate.dense.weight\n",
      "2021-12-10 14:55:36,250 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.LayerNorm.bias\n",
      "2021-12-10 14:55:36,251 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.LayerNorm.weight\n",
      "2021-12-10 14:55:36,255 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.dense.bias\n",
      "2021-12-10 14:55:36,256 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.dense.weight\n",
      "2021-12-10 14:55:36,257 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "2021-12-10 14:55:36,258 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "2021-12-10 14:55:36,259 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.dense.bias\n",
      "2021-12-10 14:55:36,260 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.dense.weight\n",
      "2021-12-10 14:55:36,261 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.key.bias\n",
      "2021-12-10 14:55:36,263 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.key.weight\n",
      "2021-12-10 14:55:36,265 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.query.bias\n",
      "2021-12-10 14:55:36,266 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.query.weight\n",
      "2021-12-10 14:55:36,267 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.value.bias\n",
      "2021-12-10 14:55:36,268 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.value.weight\n",
      "2021-12-10 14:55:36,269 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.intermediate.dense.bias\n",
      "2021-12-10 14:55:36,270 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.intermediate.dense.weight\n",
      "2021-12-10 14:55:36,271 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.LayerNorm.bias\n",
      "2021-12-10 14:55:36,272 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.LayerNorm.weight\n",
      "2021-12-10 14:55:36,273 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.dense.bias\n",
      "2021-12-10 14:55:36,274 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.dense.weight\n",
      "2021-12-10 14:55:36,274 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "2021-12-10 14:55:36,275 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "2021-12-10 14:55:36,277 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.dense.bias\n",
      "2021-12-10 14:55:36,278 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.dense.weight\n",
      "2021-12-10 14:55:36,279 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.key.bias\n",
      "2021-12-10 14:55:36,280 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.key.weight\n",
      "2021-12-10 14:55:36,282 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.query.bias\n",
      "2021-12-10 14:55:36,283 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.query.weight\n",
      "2021-12-10 14:55:36,283 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.value.bias\n",
      "2021-12-10 14:55:36,284 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.value.weight\n",
      "2021-12-10 14:55:36,285 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.intermediate.dense.bias\n",
      "2021-12-10 14:55:36,286 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.intermediate.dense.weight\n",
      "2021-12-10 14:55:36,288 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.LayerNorm.bias\n",
      "2021-12-10 14:55:36,289 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.LayerNorm.weight\n",
      "2021-12-10 14:55:36,290 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.dense.bias\n",
      "2021-12-10 14:55:36,291 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.dense.weight\n",
      "2021-12-10 14:55:36,292 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "2021-12-10 14:55:36,293 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "2021-12-10 14:55:36,294 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.dense.bias\n",
      "2021-12-10 14:55:36,295 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.dense.weight\n",
      "2021-12-10 14:55:36,298 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.key.bias\n",
      "2021-12-10 14:55:36,299 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.key.weight\n",
      "2021-12-10 14:55:36,300 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.query.bias\n",
      "2021-12-10 14:55:36,301 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.query.weight\n",
      "2021-12-10 14:55:36,302 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.value.bias\n",
      "2021-12-10 14:55:36,303 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.value.weight\n",
      "2021-12-10 14:55:36,304 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.intermediate.dense.bias\n",
      "2021-12-10 14:55:36,305 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.intermediate.dense.weight\n",
      "2021-12-10 14:55:36,306 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.LayerNorm.bias\n",
      "2021-12-10 14:55:36,307 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.LayerNorm.weight\n",
      "2021-12-10 14:55:36,308 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.dense.bias\n",
      "2021-12-10 14:55:36,309 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.dense.weight\n",
      "2021-12-10 14:55:36,310 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "2021-12-10 14:55:36,311 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "2021-12-10 14:55:36,313 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.dense.bias\n",
      "2021-12-10 14:55:36,314 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.dense.weight\n",
      "2021-12-10 14:55:36,315 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.key.bias\n",
      "2021-12-10 14:55:36,316 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.key.weight\n",
      "2021-12-10 14:55:36,317 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.query.bias\n",
      "2021-12-10 14:55:36,318 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.query.weight\n",
      "2021-12-10 14:55:36,319 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.value.bias\n",
      "2021-12-10 14:55:36,320 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.value.weight\n",
      "2021-12-10 14:55:36,321 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.intermediate.dense.bias\n",
      "2021-12-10 14:55:36,322 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.intermediate.dense.weight\n",
      "2021-12-10 14:55:36,323 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.LayerNorm.bias\n",
      "2021-12-10 14:55:36,324 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.LayerNorm.weight\n",
      "2021-12-10 14:55:36,325 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.dense.bias\n",
      "2021-12-10 14:55:36,333 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.dense.weight\n",
      "2021-12-10 14:55:36,349 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "2021-12-10 14:55:36,351 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "2021-12-10 14:55:36,352 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.dense.bias\n",
      "2021-12-10 14:55:36,353 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.dense.weight\n",
      "2021-12-10 14:55:36,354 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.key.bias\n",
      "2021-12-10 14:55:36,355 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.key.weight\n",
      "2021-12-10 14:55:36,356 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.query.bias\n",
      "2021-12-10 14:55:36,357 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.query.weight\n",
      "2021-12-10 14:55:36,360 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.value.bias\n",
      "2021-12-10 14:55:36,361 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.value.weight\n",
      "2021-12-10 14:55:36,363 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.intermediate.dense.bias\n",
      "2021-12-10 14:55:36,367 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.intermediate.dense.weight\n",
      "2021-12-10 14:55:36,371 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.LayerNorm.bias\n",
      "2021-12-10 14:55:36,372 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.LayerNorm.weight\n",
      "2021-12-10 14:55:36,373 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.dense.bias\n",
      "2021-12-10 14:55:36,374 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.dense.weight\n",
      "2021-12-10 14:55:36,374 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "2021-12-10 14:55:36,381 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "2021-12-10 14:55:36,382 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.dense.bias\n",
      "2021-12-10 14:55:36,384 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.dense.weight\n",
      "2021-12-10 14:55:36,385 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.key.bias\n",
      "2021-12-10 14:55:36,386 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.key.weight\n",
      "2021-12-10 14:55:36,387 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.query.bias\n",
      "2021-12-10 14:55:36,389 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.query.weight\n",
      "2021-12-10 14:55:36,390 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.value.bias\n",
      "2021-12-10 14:55:36,395 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.value.weight\n",
      "2021-12-10 14:55:36,397 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.intermediate.dense.bias\n",
      "2021-12-10 14:55:36,400 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.intermediate.dense.weight\n",
      "2021-12-10 14:55:36,401 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.LayerNorm.bias\n",
      "2021-12-10 14:55:36,401 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.LayerNorm.weight\n",
      "2021-12-10 14:55:36,402 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.dense.bias\n",
      "2021-12-10 14:55:36,403 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.dense.weight\n",
      "2021-12-10 14:55:36,403 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "2021-12-10 14:55:36,408 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "2021-12-10 14:55:36,409 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.dense.bias\n",
      "2021-12-10 14:55:36,409 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.dense.weight\n",
      "2021-12-10 14:55:36,410 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.key.bias\n",
      "2021-12-10 14:55:36,411 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.key.weight\n",
      "2021-12-10 14:55:36,413 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.query.bias\n",
      "2021-12-10 14:55:36,414 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.query.weight\n",
      "2021-12-10 14:55:36,415 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.value.bias\n",
      "2021-12-10 14:55:36,416 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.value.weight\n",
      "2021-12-10 14:55:36,417 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.intermediate.dense.bias\n",
      "2021-12-10 14:55:36,418 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.intermediate.dense.weight\n",
      "2021-12-10 14:55:36,419 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.LayerNorm.bias\n",
      "2021-12-10 14:55:36,420 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.LayerNorm.weight\n",
      "2021-12-10 14:55:36,421 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.dense.bias\n",
      "2021-12-10 14:55:36,422 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.dense.weight\n",
      "2021-12-10 14:55:36,423 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "2021-12-10 14:55:36,424 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "2021-12-10 14:55:36,425 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.dense.bias\n",
      "2021-12-10 14:55:36,427 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.dense.weight\n",
      "2021-12-10 14:55:36,428 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.key.bias\n",
      "2021-12-10 14:55:36,429 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.key.weight\n",
      "2021-12-10 14:55:36,431 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.query.bias\n",
      "2021-12-10 14:55:36,432 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.query.weight\n",
      "2021-12-10 14:55:36,435 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.value.bias\n",
      "2021-12-10 14:55:36,437 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.value.weight\n",
      "2021-12-10 14:55:36,438 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.intermediate.dense.bias\n",
      "2021-12-10 14:55:36,439 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.intermediate.dense.weight\n",
      "2021-12-10 14:55:36,440 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.LayerNorm.bias\n",
      "2021-12-10 14:55:36,441 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.LayerNorm.weight\n",
      "2021-12-10 14:55:36,451 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.dense.bias\n",
      "2021-12-10 14:55:36,454 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.dense.weight\n",
      "2021-12-10 14:55:36,455 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "2021-12-10 14:55:36,456 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "2021-12-10 14:55:36,459 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.dense.bias\n",
      "2021-12-10 14:55:36,462 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.dense.weight\n",
      "2021-12-10 14:55:36,463 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.key.bias\n",
      "2021-12-10 14:55:36,464 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.key.weight\n",
      "2021-12-10 14:55:36,466 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.query.bias\n",
      "2021-12-10 14:55:36,467 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.query.weight\n",
      "2021-12-10 14:55:36,467 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.value.bias\n",
      "2021-12-10 14:55:36,468 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.value.weight\n",
      "2021-12-10 14:55:36,469 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.intermediate.dense.bias\n",
      "2021-12-10 14:55:36,469 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.intermediate.dense.weight\n",
      "2021-12-10 14:55:36,470 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.LayerNorm.bias\n",
      "2021-12-10 14:55:36,471 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.LayerNorm.weight\n",
      "2021-12-10 14:55:36,473 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.dense.bias\n",
      "2021-12-10 14:55:36,474 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.dense.weight\n",
      "2021-12-10 14:55:36,475 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "2021-12-10 14:55:36,485 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "2021-12-10 14:55:36,487 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.dense.bias\n",
      "2021-12-10 14:55:36,488 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.dense.weight\n",
      "2021-12-10 14:55:36,488 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.key.bias\n",
      "2021-12-10 14:55:36,494 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.key.weight\n",
      "2021-12-10 14:55:36,495 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.query.bias\n",
      "2021-12-10 14:55:36,496 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.query.weight\n",
      "2021-12-10 14:55:36,498 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.value.bias\n",
      "2021-12-10 14:55:36,499 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.value.weight\n",
      "2021-12-10 14:55:36,500 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.intermediate.dense.bias\n",
      "2021-12-10 14:55:36,501 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.intermediate.dense.weight\n",
      "2021-12-10 14:55:36,504 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.LayerNorm.bias\n",
      "2021-12-10 14:55:36,505 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.LayerNorm.weight\n",
      "2021-12-10 14:55:36,506 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.dense.bias\n",
      "2021-12-10 14:55:36,508 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.dense.weight\n",
      "2021-12-10 14:55:36,509 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "2021-12-10 14:55:36,513 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "2021-12-10 14:55:36,514 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.dense.bias\n",
      "2021-12-10 14:55:36,515 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.dense.weight\n",
      "2021-12-10 14:55:36,518 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.key.bias\n",
      "2021-12-10 14:55:36,521 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.key.weight\n",
      "2021-12-10 14:55:36,522 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.query.bias\n",
      "2021-12-10 14:55:36,523 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.query.weight\n",
      "2021-12-10 14:55:36,525 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.value.bias\n",
      "2021-12-10 14:55:36,526 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.value.weight\n",
      "2021-12-10 14:55:36,527 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.intermediate.dense.bias\n",
      "2021-12-10 14:55:36,527 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.intermediate.dense.weight\n",
      "2021-12-10 14:55:36,530 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.LayerNorm.bias\n",
      "2021-12-10 14:55:36,532 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.LayerNorm.weight\n",
      "2021-12-10 14:55:36,532 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.dense.bias\n",
      "2021-12-10 14:55:36,533 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.dense.weight\n",
      "2021-12-10 14:55:36,534 - INFO - allennlp.nn.initializers -    bert_model.pooler.dense.bias\n",
      "2021-12-10 14:55:36,535 - INFO - allennlp.nn.initializers -    bert_model.pooler.dense.weight\n",
      "2021-12-10 14:55:36,535 - INFO - allennlp.nn.initializers -    tag_projection_layer.bias\n",
      "2021-12-10 14:55:36,536 - INFO - allennlp.nn.initializers -    tag_projection_layer.weight\n",
      "2021-12-10 14:55:37,010 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /tmp/tmpdo4zhma6\n"
     ]
    }
   ],
   "source": [
    "srl_predictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/structured-prediction-srl-bert.2020.12.15.tar.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47c920c-a5c4-4058-bb63-72c1230d0587",
   "metadata": {},
   "source": [
    "## 2. Causal relation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d1a104f-cf39-456f-9434-31aed745e40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "022436b0-d987-4c02-9ec8-6c8b47489dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "RED = 1\n",
    "BLUE = 4\n",
    "BLACK = 0\n",
    "NO_COLOR = -1\n",
    "COLOR_CONCEPT_1 = RED\n",
    "COLOR_CONCEPT_2 = BLUE\n",
    "COLOR_CONTENT_RELATION_EXPLANATION = BLACK\n",
    "CONCEPT_1 = \"Content_Concept_1\"\n",
    "CONCEPT_2 = \"Content_Concept_2\"\n",
    "CONTENT_RELATION_EXPLANATION = \"Content_Relation_Explanation\"\n",
    "NO_CONCEPT = \"\"\n",
    "COLOR_CODES = { CONCEPT_1: COLOR_CONCEPT_1, CONCEPT_2: COLOR_CONCEPT_2, CONTENT_RELATION_EXPLANATION: COLOR_CONTENT_RELATION_EXPLANATION, NO_CONCEPT: NO_COLOR }\n",
    "# 20211206 begore expansion: 34 verbs; after 78 verbs\n",
    "RELATION_VERBS = [ \"activate\", \"achieve\", \"affect\", \"aggravate\", \"allow\", \"attribute\", \"avoid\", \"base\", \"balance\", \"boost\", \n",
    "                   \"bring\", \"brought\", \"cause\", \"change\", \"compell\", \"comply\", \"compromise\", \"consolidate\", \"contain\", \"contribute\", \n",
    "                   \"control\", \"create\", \"deceive\", \"deduce\", \"depend\", \"elicit\", \"eliminate\", \"enable\", \"enact\", \"endanger\", \n",
    "                   \"enforce\", \"entail\", \"ensure\", \"erode\", \"fail\", \"flow\", \"force\", \"found\", \"increase\", \"generate\", \n",
    "                   \"ignite\", \"implicate\", \"imply\", \"induce\", \"infer\", \"influence\", \"initiate\", \"intend\", \"justify\", \"launch\", \n",
    "                   \"lead\", \"make\", \"manipulate\", \"mislead\", \"motivate\", \"obey\", \"open\", \"originate\", \"permit\", \"pick\", \n",
    "                   \"preserve\", \"produce\", \"protect\", \"provoke\", \"reduce\", \"reinforce\", \"restore\", \"result\", \"safeguard\", \"secure\", \n",
    "                   \"solve\", \"stimulate\", \"strenghten\", \"support\", \"tackle\", \"trigger\", \"undermine\", \"weaken\", ]\n",
    "REVERSE_VERBS = [ \"arise\", \"need\" ]\n",
    "ARGM_DIS_ROLES = [ \"furthermore\", \"instead\", \"moreover\", \"nevertheless\", \"otherwise\", \"therefore\", \"thus\" ]\n",
    "NO_ARG0_ROLES = [ \"he\", \"i\", \"she\", \"they\", \"we\", \"you\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfb6f8c8-dcc8-4c89-93b4-78d1afab73df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_tag(token):\n",
    "    if len(token) > 1:\n",
    "        if re.search(\"^\\[\", token):\n",
    "            token = re.sub(\"^\\[\", \"\", token)\n",
    "            token = re.sub(\":$\", \"\", token)\n",
    "        token = re.sub(\"\\]$\", \"\", token)\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f33cca46-632f-4cfc-8f50-aae6f0e8fbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_with_color(string, color_code):\n",
    "    print(f\"\\x1b[1;3{color_code};47m{string}\\x1b[m\", end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac4738ff-d132-47ea-89c9-3bc4dec25543",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_concept_tag_argm_prp(argument):\n",
    "    if argument == \"ARGM-PRP\":\n",
    "        return CONCEPT_2\n",
    "    elif argument in [\"V\", \"ARG0\", \"ARG1\", \"ARG2\" ]:\n",
    "        return CONCEPT_1\n",
    "    return NO_CONCEPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75f9d05f-0b73-48ce-9604-ba7283d051c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_concept_tag_argm_dis(argument):\n",
    "    color_code = NO_COLOR\n",
    "    if argument == \"ARGM-DIS\":\n",
    "        return CONTENT_RELATION_EXPLANATION\n",
    "    elif argument != \"\":\n",
    "        return CONCEPT_2\n",
    "    return NO_CONCEPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe60a35d-1501-44d9-9aab-0bb7b150bcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_concept_tag_v(argument, roles):\n",
    "    if argument == \"V\":\n",
    "        return CONTENT_RELATION_EXPLANATION\n",
    "    elif argument in [ \"ARG0\", \"ARGM-PRD\", \"ARGM-MNR\" ] and (argument != \"ARG0\" or roles[\"ARG0\"].lower() not in NO_ARG0_ROLES):\n",
    "        return CONCEPT_1\n",
    "    elif argument in [ \"ARG1\", \"ARG2\", ]:\n",
    "        return CONCEPT_2\n",
    "    return NO_CONCEPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05549e58-5850-4ec6-a685-8470df89da05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_concept_tag_reverse_v(argument, roles):\n",
    "    if argument == \"V\":\n",
    "        return CONTENT_RELATION_EXPLANATION\n",
    "    elif argument in [ \"ARG0\", \"ARGM-PRD\", \"ARGM-MNR\" ] and (argument != \"ARG0\" or roles[\"ARG0\"].lower() not in NO_ARG0_ROLES):\n",
    "        return CONCEPT_2\n",
    "    elif argument in [ \"ARG1\", \"ARG2\", ]:\n",
    "        return CONCEPT_1\n",
    "    return NO_CONCEPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94001968-cb87-49f3-98bb-3ecc19973f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_verb(verb, RELATION_VERBS):\n",
    "    if verb in RELATION_VERBS:\n",
    "        return True\n",
    "    if re.sub(\"[ds]$\", \"\", verb) in RELATION_VERBS:\n",
    "        return True\n",
    "    if re.sub(\"ed$\", \"\", verb) in RELATION_VERBS:\n",
    "        return True\n",
    "    if re.sub(\"ing$\", \"\", verb) in RELATION_VERBS:\n",
    "        return True\n",
    "    if re.sub(\"ing$\", \"e\", verb) in RELATION_VERBS:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "355f9209-2d8f-4b6b-bd2e-ccaf448e8367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_token(token, argument, first_token, last_token, color_code):\n",
    "    if color_code == NO_COLOR:\n",
    "        print_token_no_color(token, argument, first_token, last_token)\n",
    "    else:\n",
    "        print_token_color(token, argument, first_token, last_token, color_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0f3a494-5bb6-461b-bc0a-10e20773f1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_token_no_color(token, argument, first_token, last_token):\n",
    "    if first_token:\n",
    "        print(f\"[{argument} \", end=\"\")\n",
    "    print(f\"{token}\", end=\"\")\n",
    "    if last_token:\n",
    "        print(f\"]\", end=\"\")\n",
    "    print(\" \", end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5782a6a-2908-434f-86c6-9a9b132765de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_token_color(token, argument, first_token, last_token, color_code):\n",
    "    if first_token:\n",
    "        print_with_color(f\"[{argument} \", color_code)\n",
    "    print_with_color(f\"{token}\", color_code)\n",
    "    if last_token:\n",
    "        print_with_color(f\"]\", color_code)\n",
    "        print(\" \", end=\"\")\n",
    "    else:\n",
    "        print_with_color(\" \", color_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae3f8846-942f-45f5-8305-df86673318f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_verb(tokens, arguments, lemmas):\n",
    "    verb = \"\"\n",
    "    if len(lemmas) != len(tokens):\n",
    "        print_with_color(f\"find_verb: error: different lengths for tokens ({len(tokens)}) and lemmas ({len(lemmas)})\", 1)\n",
    "    for i in range(0, len(arguments)):\n",
    "        if arguments[i] == \"V\":\n",
    "            verb = lemmas[i]\n",
    "    return verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07e72660-d826-49ff-ac3a-40b69d19233f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_analysis(analyzed_sentence):\n",
    "    tokens_in = analyzed_sentence.split()\n",
    "    arguments = []\n",
    "    tokens_out = []\n",
    "    first_tokens = []\n",
    "    last_tokens = []\n",
    "    current_argument = \"\"\n",
    "    roles = {}\n",
    "    first_token = False\n",
    "    for i in range(0, len(tokens_in)):\n",
    "        if re.search(\"^\\[\", tokens_in[i]) and re.search(\":$\", tokens_in[i]):        \n",
    "            current_argument = strip_tag(tokens_in[i])\n",
    "            first_token = True\n",
    "            continue\n",
    "        arguments.append(current_argument)\n",
    "        tokens_out.append(strip_tag(tokens_in[i]))\n",
    "        first_tokens.append(first_token)\n",
    "        last_tokens.append(False)\n",
    "        if current_argument != \"\":\n",
    "            if current_argument not in roles:\n",
    "                roles[current_argument] = strip_tag(tokens_in[i])\n",
    "            else:\n",
    "                roles[current_argument] += \" \" + strip_tag(tokens_in[i])\n",
    "        if re.search(\"\\]$\", tokens_in[i]):\n",
    "            current_argument = \"\"\n",
    "            last_tokens[-1] = True\n",
    "        first_token = False\n",
    "    return [tokens_out, arguments, first_tokens, last_tokens, roles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad4fe971-e31e-4f11-abf8-063397bb879d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lemmas(sentence):\n",
    "    lemmas = []\n",
    "    results = spacy_analyze(sentence)\n",
    "    for token in results:\n",
    "        lemmas.append(token.lemma_)\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31a63481-9434-43ff-9146-6a5fb0b39520",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_causal_relations(analyzed_sentence, lemmas):\n",
    "    tokens, arguments, first_tokens, last_tokens, roles = convert_analysis(analyzed_sentence)\n",
    "    concepts = []\n",
    "    for i in range(0, len(tokens)):\n",
    "        if \"ARGM-PRP\" in arguments:\n",
    "            concepts.append(get_concept_tag_argm_prp(arguments[i]))\n",
    "        elif \"ARGM-DIS\" in arguments and roles[\"ARGM-DIS\"].lower() in ARGM_DIS_ROLES:\n",
    "            concepts.append(get_concept_tag_argm_dis(arguments[i]))\n",
    "        elif \"V\" in arguments and check_verb(find_verb(tokens, arguments, lemmas), RELATION_VERBS):\n",
    "            concepts.append(get_concept_tag_v(arguments[i], roles))\n",
    "        elif \"V\" in arguments and check_verb(find_verb(tokens, arguments, lemmas), REVERSE_VERBS):\n",
    "            concepts.append(get_concept_tag_reverse_v(arguments[i], roles))\n",
    "        else:\n",
    "            concepts.append(NO_CONCEPT)\n",
    "    return { \"tokens\": tokens, \"arguments\": arguments, \"first_tokens\": first_tokens, \"last_tokens\": last_tokens, \"roles\": roles, \"concepts\": concepts }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "695b907f-e7d9-42ea-b21e-e75dafa66bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print(causal_relation_data):\n",
    "    for i in range(0, len(causal_relation_data[\"tokens\"])):\n",
    "        color_code = COLOR_CODES[causal_relation_data[\"concepts\"][i]]\n",
    "        print_token(causal_relation_data[\"tokens\"][i], causal_relation_data[\"arguments\"][i], causal_relation_data[\"first_tokens\"][i], causal_relation_data[\"last_tokens\"][i], color_code)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3057805e-406f-48e5-82f2-b57713e6c38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def srl_analyze(sentence, filter=\"\", print_flag=True):\n",
    "    srl_analysis = srl_predictor.predict(sentence=sentence)\n",
    "    causal_relations = []\n",
    "    lemmas = get_lemmas(re.sub(\"\\s+\", \" \", sentence))\n",
    "    for verb_data in srl_analysis['verbs']:\n",
    "        causal_relations.append(find_causal_relations(verb_data['description'], lemmas))\n",
    "    if print_flag:\n",
    "        for causal_relation_data in causal_relations:\n",
    "            if filter == \"\" or re.search(filter, \" \".join(causal_relation_data[\"tokens\"] + causal_relation_data[\"arguments\"])):\n",
    "                pretty_print(causal_relation_data)\n",
    "    return causal_relations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878c83ec-5f49-4857-bbe3-c26e1970a4e9",
   "metadata": {},
   "source": [
    "## 3. Test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a15844e-570e-4d1f-be62-b2f953dedbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "srl_analyze(\"John sees the mountain with the snow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1011a94-4b99-445b-a402-8d8da2b2c102",
   "metadata": {},
   "outputs": [],
   "source": [
    "srl_analyze(\"\"\"You, in Greece, with our support, need to rebuild your country, your structures, your administration, \n",
    "               your economy to increase the competitiveness of Greece.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315abf68-be8c-4f3d-bf4c-2df02c86b2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "srl_analyze(\"This opened the way to welfare gains from stronger economic and financial integration.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f79c931-5910-4e5e-906c-cf0038e13294",
   "metadata": {},
   "outputs": [],
   "source": [
    "srl_analyze(\"One risk is the temptation for governments to overborrow because the economic costs of excessive public debt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5790cf17-2704-4467-95ac-20f071abfff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "srl_analyze(\"A resulting loosening of fiscal discipline in individual member states can endanger the stability-oriented monetary policy.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee739b0-6890-44c8-9243-ba7232cfd06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "srl_analyze(\"Therefore, the markets did not properly perform their expected policing function.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1a41ca-b0ba-48c7-99f3-c4475ce51df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "srl_analyze(\"I hope that following the lessons of interdependence not only at global, but also at European level given by the crisis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6907cf65-d7d1-4f2b-834c-c8725a789efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "srl_analyze(\"European economic strategy needs the full commitment of the European political community.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459c7201-cc64-4b74-ad11-4558a8e249fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "srl_analyze(\"And a European economic system whose resilience flows from its single market\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b72ed91-af91-4c2f-9c75-193561125851",
   "metadata": {},
   "outputs": [],
   "source": [
    "srl_analyze(\"there are of course considerable budgetary challenges arising from the recent exceptional measures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed79018-85a0-45fb-9d5c-2f1947602cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "srl_analyze(\"And the best hope of a return to growth and job creation is inside the euro area.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da62399a-2a30-4bfd-a4eb-ce2215579c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "srl_analyze(\"To conclude, let me say a few words on the euro area more generally.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d41d16d-acbf-4da7-9afe-0992057f9fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "srl_analyze(\"\"\"We have taken important, fundamental decisions over the last couple of months to safeguard the stability \n",
    "               of the euro area, and indeed we are now in the phase of implementation.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc28fe0-2fd8-40f0-bb47-e66a0dbc7822",
   "metadata": {},
   "outputs": [],
   "source": [
    "srl_analyze(\"\"\"A number of governments have embarked on a path of reform and fiscal consolidation that was unthinkable only \n",
    "               very recently, and they have taken important decisions and I encourage them to keep this determination.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3608204a-2217-4403-896d-10b5b02f0f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "srl_analyze(\"\"\"These reforms are now being implemented and this effort must continue with credibility, with consistency, \n",
    "               with coherence over time.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21df66a7-1c41-43a5-a953-c40ac915e150",
   "metadata": {},
   "outputs": [],
   "source": [
    "srl_analyze(\"As we said there will not be magic solutions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e08438-0804-4afb-a771-5f848fd6278e",
   "metadata": {},
   "outputs": [],
   "source": [
    "srl_analyze(\"We need sustained efforts and determination.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cd2b3d-b1ad-4a4a-b690-6d86877ef10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "srl_analyze(\"At the same time, the existing financial backstops are being used as necessary.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bbefe2-4e57-495d-886c-d76f4b240d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "srl_analyze(\"\"\"Most recently, the financial assistance to the recapitalisation of Spanish banks has been agreed \n",
    "               and is ready for implementation.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985bbeaa-a66b-4ee9-8bef-a512bca9cbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "srl_analyze(\"\"\"Giving to the ECB the ultimate responsibility for supervision of banks in the euro area \n",
    "               will decisively contribute to increase confidence between the banks \n",
    "               and in this way increase the financial stability in the euro area.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74993ff-629f-4444-a3e9-95d936869c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "srl_analyze(\"Second, Germany is acutely aware of the need to tackle the root causes and not just the symptoms of the crisis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae9f741-68e7-4ae0-b1de-5ecb8723f609",
   "metadata": {},
   "outputs": [],
   "source": [
    "srl_analyze(\"\"\"This is why it is pressing strongly for institutional reforms of the EMU framework plus structural reforms \n",
    "               and budgetary discipline in the member states.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2040f38a-a5a9-4985-bec9-5407b44785a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "srl_analyze(\"The introduction of the euro eliminated exchange rate risks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12883bd7-edda-4218-9303-1765e061dc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "srl_analyze(\"\"\"Another implication of the euro area's single monetary policy is that the key interest rates \n",
    "               are set for the currency bloc as a whole.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0a3592-99cf-48eb-acdd-9cfd79fff765",
   "metadata": {},
   "outputs": [],
   "source": [
    "srl_analyze(\"\"\"One risk is the temptation for governments to overborrow because the economic costs of excessive public debt, \n",
    "               for example higher interest rates, can be more easily shifted to other member states.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9960a6-24ea-4ee9-b260-6112c96cd9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "srl_analyze(\"\"\"Even Germany ran up excessive deficits for a few years and, even worse, championed a reform of the SGP \n",
    "               which ultimately further weakened the application of the fiscal rules.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d20c14-9a56-4456-8abb-6dd8debb1b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "srl_analyze(\"\"\"However, the EMU framework not only failed to avoid excessive deficits, it was also unable to prevent \n",
    "               the build-up of macroeconomic imbalances within the euro area.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931baf3e-958f-4ad6-a998-a4f8ea2cfcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "srl_analyze(\"\"\"The resulting increase in domestic inflation and wages eroded the competitiveness of the countries concerned and \n",
    "               increased their dependence on capital imports.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87956f23-b8ce-48ff-8ddf-2d6ce8b5e0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "srl_analyze(\"The task of implementing the reforms and regaining competitiveness entailed significant political and social costs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f2d27b-0dc7-48cd-9cdd-4b99aa507cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "srl_analyze(\"\"\"However, these efforts, supported by a strong expansion in the global economy, allowed German growth to rebound \n",
    "               after 2005.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d13dc9-f815-4348-9384-b9a18d20e660",
   "metadata": {},
   "outputs": [],
   "source": [
    "srl_analyze(\"\"\"In order to achieve a turnaround and allow further assistance, it is now essential for Greece to deliver \n",
    "               on the promises that have been made.\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972560a3-840f-4f4c-964f-6e7bfd49b320",
   "metadata": {},
   "source": [
    "## 4. Propbank role explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588908d7-0689-4902-b868-95fe6b5747ef",
   "metadata": {},
   "source": [
    "Modifiers in Propbank (source: http://clear.colorado.edu/compsem/documents/propbank_guidelines.pdf )\n",
    "* ADJ: Adjectival\n",
    "* ADV: Adverbials\n",
    "* CAU: Cause\n",
    "* COM: Comitative\n",
    "* DIR: Directional\n",
    "* DIS: Discourse\n",
    "* DSP: Direct Speech\n",
    "* EXT: Extent\n",
    "* GOL: Goal\n",
    "* LOC: Locative\n",
    "* LVB: Light Verb\n",
    "* MNR: Manner\n",
    "* MOD: Modal\n",
    "* NEG: Negation\n",
    "* PRD: Secondary Predication\n",
    "* PRP: Purpose\n",
    "* REC: Reciprocals\n",
    "* SLC: Relative Clause"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674fae69-32c1-4949-989f-06bc5e5534c7",
   "metadata": {},
   "source": [
    "## 5. Process texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9179a87-35dc-42fc-b421-d4c890d5107f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ffdbfbeb-21d8-44be-b927-5f6c5088c864",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_name):\n",
    "    json_data = []\n",
    "    infile = open(file_name, \"r\")\n",
    "    for line in infile:\n",
    "        json_data.append(json.loads(line))\n",
    "    infile.close()\n",
    "    return json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e89b4b4a-fcce-43da-9be3-6c2c44de0668",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_concepts_json(json_data_element):\n",
    "    concepts = {}\n",
    "    for label_element in json_data_element[\"label\"]:\n",
    "        label = label_element[2]\n",
    "        phrase = json_data_element[\"data\"][label_element[0]: label_element[1]]\n",
    "        if label not in concepts:\n",
    "            concepts[label] = phrase\n",
    "        else:\n",
    "            concepts[label] += \" \" + phrase\n",
    "    return list(concepts.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc7c44e1-d2ff-46bc-9163-10d7072419e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_concepts_srl(srl_data):\n",
    "    concepts = {}\n",
    "    for i in range(0, len(srl_data[\"concepts\"])):\n",
    "        if srl_data[\"concepts\"][i] != NO_CONCEPT:\n",
    "            label = srl_data[\"concepts\"][i]\n",
    "            phrase = srl_data[\"tokens\"][i]\n",
    "            if label not in concepts:\n",
    "                concepts[label] = phrase\n",
    "            elif len(phrase) > 1 or re.search(\"\\w\", phrase):\n",
    "                concepts[label] += \" \" + phrase\n",
    "            else:\n",
    "                concepts[label] += phrase\n",
    "    return list(concepts.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "34f73384-d028-4fc3-ae63-c48fc1b4ff23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_precision_recall(present, found, correct, correct_phrases):\n",
    "    print(f\"found: {found}; present: {present}; correct: {correct}; \", end=\"\")\n",
    "    if found > 0:\n",
    "        print(f\"precision: {correct/found:.3f}; \", end=\"\")\n",
    "    print(f\"recall: {correct/present:.3f}\", end=\"\")\n",
    "    if len(correct_phrases) > 0:\n",
    "        print(f\"; correct phrases: {correct_phrases}\", end=\"\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c96d456-defd-4fbd-81cf-72dd8eef4396",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_concepts(concepts_json, concepts_srl):\n",
    "    correct = 0\n",
    "    concepts_srl_used = len(concepts_srl) * [False]\n",
    "    correct_phrases = []\n",
    "    for i in range(0, len(concepts_json)):\n",
    "        for j in range(0, len(concepts_srl)):\n",
    "            if not concepts_srl_used[j] and concepts_srl[j][0] == concepts_json[i][0] and concepts_srl[j][1] == concepts_json[i][1]:\n",
    "                correct += 1\n",
    "                concepts_srl_used[j] = False # change to True to avoid accepting concepts more than once \n",
    "                correct_phrases.append(concepts_srl[j][1])\n",
    "                break\n",
    "    present = len(concepts_json)\n",
    "    found = len(concepts_srl)\n",
    "    return present, found, correct, correct_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3a12203b-e389-4326-b574-0324d44f4f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def escape_characters(json_data):\n",
    "    for data in json_data:\n",
    "        data[\"data\"] = re.sub(\"-\", \"_\", data[\"data\"])\n",
    "        data[\"data\"] = re.sub(\"\\[\", \"_\", data[\"data\"])\n",
    "        data[\"data\"] = re.sub(\"\\]\", \"_\", data[\"data\"])\n",
    "        # data[\"data\"] = re.sub('\"\\.2$', '\". 2', data[\"data\"])\n",
    "    return json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "13f071e9-468f-4ed0-80c8-926f6cf44691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_list(data):\n",
    "    if type(data) != list:\n",
    "        return [data]\n",
    "    else:\n",
    "        if len(data) == 0:\n",
    "            return []\n",
    "        else:\n",
    "            first_element_list = flatten_list(data[0])\n",
    "            rest_list = flatten_list(data[1:])\n",
    "            first_element_list.extend(rest_list)\n",
    "            return first_element_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0d678ba5-9d90-4166-a631-44d385973e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_paragraph_data(paragraph_data, out_file_name=\"data.jsonl\"):\n",
    "    counter = 1\n",
    "    out_data = []\n",
    "    for paragraph in paragraph_data:\n",
    "        while True:\n",
    "            paragraph_labels = []\n",
    "            for labels in paragraph[\"labels\"]:\n",
    "                if len(labels) > 0:\n",
    "                    paragraph_labels.extend(labels[0])\n",
    "                    labels.pop(0)\n",
    "                    break\n",
    "            if len(paragraph_labels) == 0:\n",
    "                break\n",
    "            out_data_item = { \"id\": counter, \"text\": paragraph[\"text\"], \"label\": paragraph_labels}\n",
    "            for key in paragraph:\n",
    "                if key not in [ \"text\", \"labels\" ]:\n",
    "                    out_data_item[key] = paragraph[key]\n",
    "            out_data.append(out_data_item)\n",
    "            counter += 1\n",
    "    out_file = open(out_file_name, \"w\")\n",
    "    for data in out_data:\n",
    "        print(json.dumps(data), file=out_file)\n",
    "    out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6bd0ef6b-ea31-4e55-aa5c-f72d177fdd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(string):\n",
    "    return \" \".join([str(token) for token in spacy_analyze(string)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9aff96e7-09a8-4678-b8a1-aa394c96a9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_meta_data_paragraph(paragraph, json_data, start_index):\n",
    "    text_seen_count = 0\n",
    "    for i in range(start_index, len(json_data)):\n",
    "        if json_data[i][\"data\"] == json_data[start_index][\"data\"]:\n",
    "            text_seen_count += 1\n",
    "            for key in [\"paragraph_id\", \"source_id\", \"speech_id\" ]:\n",
    "                paragraph[key] = json_data[i][key]\n",
    "            for label_data in json_data[i][\"label\"]:\n",
    "                label = f\"[{text_seen_count}] \" + label_data[2]\n",
    "                phrase = json_data[i][\"data\"][label_data[0]: label_data[1]]\n",
    "                if label in paragraph:\n",
    "                    paragraph[label].append(phrase)\n",
    "                else:\n",
    "                    paragraph[label] = [phrase]\n",
    "\n",
    "\n",
    "def add_meta_data(paragraph_data, json_data):\n",
    "    counter = 0\n",
    "    text_seen_dict = {}\n",
    "    i_last_match = -1\n",
    "    for paragraph in paragraph_data:\n",
    "        tokenized_paragraph = tokenize(paragraph[\"text\"])\n",
    "        text_seen_count = 0\n",
    "        for i in range(0, len(json_data)):\n",
    "            if json_data[i][\"data\"] not in text_seen_dict and tokenize(json_data[i][\"data\"]) == tokenized_paragraph:\n",
    "                i_last_match = i\n",
    "                text_seen_count += 1\n",
    "                add_meta_data_paragraph(paragraph, json_data, i)\n",
    "            if text_seen_count > 0 and tokenize(json_data[i][\"data\"]) != tokenized_paragraph:\n",
    "                break\n",
    "            text_seen_dict[json_data[i][\"data\"]] = True\n",
    "        if json_data[-1][\"data\"] in text_seen_dict:\n",
    "            text_seen_dict = {}\n",
    "            for k in range(i_last_match+1, len(json_data)):\n",
    "                if i_last_match < 0 or json_data[k][\"data\"] != json_data[i_last_match][\"data\"]:\n",
    "                    add_meta_data_paragraph(paragraph, json_data, k)\n",
    "                    i_last_match = k\n",
    "                    break\n",
    "        counter += 1\n",
    "        print(f\"{counter} ({len(text_seen_dict)}) \", end=\"\")\n",
    "    print(\"\")\n",
    "    return paragraph_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "abf60d6a-f977-4240-a677-de1c37dd339b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_doccano_format(srl_analysis_paragraphs, json_data):\n",
    "    paragraph_data = []\n",
    "    for srl_analysis_paragraph in srl_analysis_paragraphs:\n",
    "        text_paragraph = \"\"\n",
    "        labels_paragraph = []\n",
    "        for srl_analysis_sentence in srl_analysis_paragraph:\n",
    "            labels_sentence = []\n",
    "            text_sentence = \"\"\n",
    "            for srl_analysis in srl_analysis_sentence:\n",
    "                text = \"\"\n",
    "                labels = []\n",
    "                \n",
    "                for i in range(0, len(srl_analysis[\"tokens\"])):\n",
    "                    token = srl_analysis[\"tokens\"][i]\n",
    "                    label = srl_analysis[\"concepts\"][i]\n",
    "                    if label != \"\":\n",
    "                        if len(labels) > 0 and labels[-1][2] == label and labels[-1][1] == len(text_paragraph) + len(text):\n",
    "                            labels[-1] = (labels[-1][0], len(text_paragraph) + len(text) + len(token) + 1, label)\n",
    "                        else:\n",
    "                            labels.append((len(text_paragraph) + len(text), len(text_paragraph) + len(text) + len(token) + 1, label))\n",
    "                    text += token + \" \"\n",
    "                if len(labels) > 0:\n",
    "                    labels_sentence.append(labels)\n",
    "                text_sentence = text\n",
    "            text_paragraph += text_sentence\n",
    "            labels_paragraph.append(labels_sentence)\n",
    "        paragraph_data.append({ \"text\": text_paragraph, \"labels\": labels_paragraph })\n",
    "    paragraph_data = add_meta_data(paragraph_data, json_data)\n",
    "    save_paragraph_data(paragraph_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d7a51e81-23e5-42ae-a196-57dcae0ef632",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_concepts(concepts_json, paragraph_text, paragraph_id, print_flag=True):\n",
    "    if print_flag:\n",
    "        print(\"####################\")\n",
    "    concepts_srl = []\n",
    "    spacy_analysis = spacy_analyze(paragraph_text)\n",
    "    srl_analysis_paragraph = []\n",
    "    for sentence in spacy_analysis.sents:\n",
    "        srl_analysis_sentence = srl_analyze(str(sentence), filter=\"\", print_flag=print_flag)\n",
    "        for srl_analysis_data in srl_analysis_sentence:\n",
    "            concepts_srl.extend(get_concepts_srl(srl_analysis_data))\n",
    "        if print_flag:\n",
    "            print(\"\")\n",
    "        srl_analysis_paragraph.append(srl_analysis_sentence)\n",
    "    present, found, correct, correct_phrases = evaluate_concepts(concepts_json, concepts_srl)\n",
    "    print(f\"id {paragraph_id}: \", end=\"\")\n",
    "    show_precision_recall(present, found, correct, correct_phrases)\n",
    "    return present, found, correct,srl_analysis_paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "58112822-ba04-44d6-88ef-b79b7cf58aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_paragraph(json_data, start_paragraph_id=0, last_paragraph_id = 100, show_only_one = True, print_flag=True):\n",
    "    seen = {}\n",
    "    present_total = 0\n",
    "    found_total = 0\n",
    "    correct_total = 0\n",
    "    previous_paragraph_text = \"\"\n",
    "    previous_concepts_json = []\n",
    "    nbr_of_paragraphs = 0\n",
    "    srl_analysis_paragraphs = []\n",
    "    for paragraph_id in range(start_paragraph_id, last_paragraph_id):\n",
    "        new_paragraph_text = json_data[paragraph_id][\"data\"]\n",
    "        new_concepts_json = get_concepts_json(json_data[paragraph_id])\n",
    "        if new_paragraph_text in seen:\n",
    "            previous_concepts_json.extend(new_concepts_json)\n",
    "            nbr_of_paragraphs += 1\n",
    "        elif show_only_one and previous_paragraph_text != \"\":\n",
    "            break\n",
    "        else:\n",
    "            if len(previous_paragraph_text) > 0:\n",
    "                present, found, correct, srl_analysis_paragraph = process_concepts(previous_concepts_json, previous_paragraph_text, paragraph_id, print_flag=print_flag)\n",
    "                present_total += present\n",
    "                found_total += found\n",
    "                correct_total += correct\n",
    "                srl_analysis_paragraphs.append(srl_analysis_paragraph)\n",
    "            previous_paragraph_text = new_paragraph_text\n",
    "            previous_concepts_json = new_concepts_json\n",
    "            seen[previous_paragraph_text] = True\n",
    "            nbr_of_paragraphs = 1\n",
    "\n",
    "    present, found, correct, srl_analysis_paragraph = process_concepts(previous_concepts_json, previous_paragraph_text, paragraph_id + 1, print_flag=print_flag)\n",
    "    srl_analysis_paragraphs.append(srl_analysis_paragraph)\n",
    "    present_total += present\n",
    "    found_total += found\n",
    "    correct_total += correct\n",
    "    print(f\"ALL({nbr_of_paragraphs}): \", end=\"\")\n",
    "    show_precision_recall(present_total, found_total, correct_total, [])\n",
    "    save_doccano_format(srl_analysis_paragraphs, json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3451aeb-8942-4abb-8325-8f516ae12a3a",
   "metadata": {},
   "source": [
    "New paragraphs can be found on the ids: 0, 12, 14, 15, 20, 24, 25, 29, 32, 41, 47, 48, 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "eaa0c392-5238-4ba5-ac23-61620ef7a825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id 797: found: 2; present: 6; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 799: found: 4; present: 6; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 803: found: 21; present: 12; correct: 1; precision: 0.048; recall: 0.083; correct phrases: ['restore']\n",
      "id 805: found: 11; present: 6; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 807: found: 7; present: 6; correct: 2; precision: 0.286; recall: 0.333; correct phrases: ['the premium on loans to the Greek government', 'confidence']\n",
      "id 809: found: 7; present: 6; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 812: found: 3; present: 9; correct: 2; precision: 0.667; recall: 0.222; correct phrases: ['stronger economic growth', 'interest rates to rise']\n",
      "id 826: found: 14; present: 42; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 830: found: 7; present: 12; correct: 4; precision: 0.571; recall: 0.333; correct phrases: ['my government', 'my government', 'my government', 'my government']\n",
      "id 836: found: 4; present: 18; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 839: found: 6; present: 9; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 840: found: 0; present: 3; correct: 0; recall: 0.000\n",
      "id 845: found: 5; present: 15; correct: 1; precision: 0.200; recall: 0.067; correct phrases: ['support']\n",
      "id 846: found: 0; present: 3; correct: 0; recall: 0.000\n",
      "id 848: found: 4; present: 6; correct: 1; precision: 0.250; recall: 0.167; correct phrases: ['ensuring']\n",
      "id 850: found: 2; present: 6; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 851: found: 9; present: 3; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 853: found: 5; present: 6; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 855: found: 5; present: 6; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 859: found: 5; present: 12; correct: 2; precision: 0.400; recall: 0.167; correct phrases: ['weaken', 'public confidence in the sustainability of public finances']\n",
      "id 860: found: 11; present: 3; correct: 1; precision: 0.091; recall: 0.333; correct phrases: ['concrete and quantifiable adjustment measures']\n",
      "id 866: found: 16; present: 18; correct: 1; precision: 0.062; recall: 0.056; correct phrases: ['The Irish economy']\n",
      "id 873: found: 11; present: 21; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 877: found: 3; present: 12; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 879: found: 2; present: 6; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 882: found: 0; present: 9; correct: 0; recall: 0.000\n",
      "id 910: found: 3; present: 84; correct: 14; precision: 4.667; recall: 0.167; correct phrases: ['the crisis', 'the crisis', 'the crisis', 'the crisis', 'the crisis', 'the crisis', 'the crisis', 'the crisis', 'the crisis', 'the crisis', 'the crisis', 'the crisis', 'the crisis', 'the crisis']\n",
      "id 914: found: 3; present: 12; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 920: found: 5; present: 18; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 923: found: 3; present: 9; correct: 1; precision: 0.333; recall: 0.111; correct phrases: ['stronger monitoring of budgetary plans drafted by members of the Eurozone']\n",
      "id 925: found: 8; present: 6; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 926: found: 4; present: 3; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 932: found: 2; present: 18; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 935: found: 8; present: 9; correct: 3; precision: 0.375; recall: 0.333; correct phrases: ['caused', 'caused', 'caused']\n",
      "id 938: found: 8; present: 9; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 939: found: 4; present: 3; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 944: found: 7; present: 15; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 947: found: 5; present: 8; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 949: found: 9; present: 6; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 961: found: 15; present: 36; correct: 6; precision: 0.400; recall: 0.167; correct phrases: ['cheaper and easier access to funding', 'led', 'cheaper and easier access to funding', 'causing', 'reducing', 'reducing']\n",
      "id 968: found: 13; present: 21; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 969: found: 2; present: 3; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 972: found: 5; present: 9; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 976: found: 0; present: 12; correct: 0; recall: 0.000\n",
      "id 977: found: 3; present: 3; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 979: found: 0; present: 6; correct: 0; recall: 0.000\n",
      "id 986: found: 2; present: 21; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 987: found: 2; present: 3; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 992: found: 6; present: 15; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 997: found: 4; present: 15; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 998: found: 3; present: 3; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 1012: found: 7; present: 42; correct: 2; precision: 0.286; recall: 0.048; correct phrases: ['the worst in us', 'Idleness']\n",
      "id 1026: found: 13; present: 42; correct: 5; precision: 0.385; recall: 0.119; correct phrases: ['The financial crisis', 'The financial crisis', 'The financial crisis', 'The financial crisis', 'The financial crisis']\n",
      "id 1027: found: 5; present: 3; correct: 1; precision: 0.200; recall: 0.333; correct phrases: ['reduce']\n",
      "id 1030: found: 7; present: 9; correct: 2; precision: 0.286; recall: 0.222; correct phrases: ['generate', 'only sound public finances']\n",
      "id 1036: found: 6; present: 18; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 1037: found: 5; present: 3; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 1038: found: 6; present: 3; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 1041: found: 0; present: 9; correct: 0; recall: 0.000\n",
      "id 1043: found: 2; present: 6; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 1047: found: 0; present: 12; correct: 0; recall: 0.000\n",
      "id 1058: found: 9; present: 33; correct: 1; precision: 0.111; recall: 0.030; correct phrases: ['economic recovery']\n",
      "id 1067: found: 11; present: 27; correct: 2; precision: 0.182; recall: 0.074; correct phrases: ['confidence in public finances', 'economic activity in all advanced economies']\n",
      "id 1069: found: 0; present: 6; correct: 0; recall: 0.000\n",
      "id 1070: found: 2; present: 3; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 1072: found: 2; present: 6; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 1073: found: 5; present: 3; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 1076: found: 7; present: 9; correct: 1; precision: 0.143; recall: 0.111; correct phrases: ['the progress made']\n",
      "id 1080: found: 15; present: 12; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 1081: found: 3; present: 3; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 1083: found: 0; present: 6; correct: 0; recall: 0.000\n",
      "id 1084: found: 3; present: 3; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 1085: found: 0; present: 3; correct: 0; recall: 0.000\n",
      "id 1087: found: 0; present: 6; correct: 0; recall: 0.000\n",
      "id 1092: found: 22; present: 15; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 1093: found: 2; present: 3; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 1097: found: 12; present: 12; correct: 2; precision: 0.167; recall: 0.167; correct phrases: ['The economic problems in Europe', 'new jobs in the private sector']\n",
      "id 1101: found: 0; present: 12; correct: 0; recall: 0.000\n",
      "id 1102: found: 4; present: 3; correct: 1; precision: 0.250; recall: 0.333; correct phrases: ['therefore']\n",
      "id 1111: found: 4; present: 27; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 1114: found: 10; present: 9; correct: 1; precision: 0.100; recall: 0.111; correct phrases: ['A modern holistic solution']\n",
      "id 1116: found: 2; present: 6; correct: 2; precision: 1.000; recall: 0.333; correct phrases: ['preserved', 'the functioning of monetary policy']\n",
      "id 1117: found: 5; present: 3; correct: 1; precision: 0.200; recall: 0.333; correct phrases: ['to the European harmonisation of objectives and tools']\n",
      "id 1119: found: 5; present: 6; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 1120: found: 2; present: 3; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 1121: found: 0; present: 3; correct: 0; recall: 0.000\n",
      "id 1123: found: 6; present: 6; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 1124: found: 3; present: 3; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 1125: found: 10; present: 3; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 1126: found: 8; present: 3; correct: 1; precision: 0.125; recall: 0.333; correct phrases: ['risk']\n",
      "id 1127: found: 7; present: 3; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 1128: found: 6; present: 3; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 1132: found: 6; present: 12; correct: 2; precision: 0.333; recall: 0.167; correct phrases: ['the purchasing power of private households', 'the purchasing power of private households']\n",
      "id 1136: found: 4; present: 12; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 1137: found: 9; present: 3; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 1143: found: 5; present: 18; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 1147: found: 2; present: 12; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 1150: found: 2; present: 9; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 1155: found: 3; present: 15; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 1159: found: 0; present: 12; correct: 0; recall: 0.000\n",
      "id 1160: found: 0; present: 3; correct: 0; recall: 0.000\n",
      "id 1166: found: 3; present: 18; correct: 6; precision: 2.000; recall: 0.333; correct phrases: ['entail', 'adjustment costs', 'entail', 'adjustment costs', 'entail', 'adjustment costs']\n",
      "id 1174: found: 3; present: 24; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 1178: found: 6; present: 12; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 1185: found: 6; present: 21; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 1189: found: 3; present: 12; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 1200: found: 17; present: 33; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 1208: found: 8; present: 24; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 1209: found: 10; present: 3; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 1212: found: 0; present: 9; correct: 0; recall: 0.000\n",
      "id 1215: found: 5; present: 9; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 1217: found: 0; present: 6; correct: 0; recall: 0.000\n",
      "id 1219: found: 7; present: 6; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 1222: found: 6; present: 9; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 1225: found: 8; present: 9; correct: 1; precision: 0.125; recall: 0.111; correct phrases: ['growth']\n",
      "id 1226: found: 3; present: 3; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 1230: found: 7; present: 12; correct: 1; precision: 0.143; recall: 0.083; correct phrases: ['supporting private enterprise']\n",
      "id 1233: found: 8; present: 9; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 1238: found: 2; present: 15; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 1242: found: 2; present: 12; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 1245: found: 7; present: 9; correct: 1; precision: 0.143; recall: 0.111; correct phrases: ['high wage inflation']\n",
      "id 1246: found: 5; present: 3; correct: 2; precision: 0.400; recall: 0.667; correct phrases: ['eliminated', 'the normal market reactions towards euro area Member States with high government debt']\n",
      "id 1248: found: 0; present: 6; correct: 0; recall: 0.000\n",
      "id 1250: found: 6; present: 6; correct: 1; precision: 0.167; recall: 0.167; correct phrases: ['consumer, business and investor confidence']\n",
      "id 1258: found: 4; present: 24; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 1260: found: 7; present: 6; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 1263: found: 4; present: 9; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 1265: found: 3; present: 6; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 1269: found: 8; present: 12; correct: 1; precision: 0.125; recall: 0.083; correct phrases: ['the credibility of the fixed_exchange_rate policy']\n",
      "id 1275: found: 8; present: 18; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 1279: found: 5; present: 12; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 1281: found: 2; present: 6; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 1283: found: 4; present: 6; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 1285: found: 5; present: 6; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 1287: found: 0; present: 6; correct: 0; recall: 0.000\n",
      "id 1289: found: 4; present: 6; correct: 1; precision: 0.250; recall: 0.167; correct phrases: ['price stability']\n",
      "id 1292: found: 10; present: 9; correct: 1; precision: 0.100; recall: 0.111; correct phrases: ['the stability of our currency']\n",
      "id 1296: found: 3; present: 12; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 1298: found: 8; present: 6; correct: 0; precision: 0.000; recall: 0.000\n",
      "id 1299: found: 9; present: 3; correct: 2; precision: 0.222; recall: 0.667; correct phrases: ['reduce', 'actions by the ECB']\n",
      "id 1300: found: 6; present: 3; correct: 0; precision: 0.000; recall: 0.000\n",
      "ALL(1): found: 747; present: 1514; correct: 80; precision: 0.107; recall: 0.053\n",
      "1 (226) 2 (227) 3 (228) 4 (229) 5 (230) 6 (231) 7 (232) 8 (0) 9 (0) 10 (0) 11 (236) 12 (237) 13 (238) 14 (239) 15 (240) 16 (241) 17 (242) 18 (243) 19 (244) 20 (245) 21 (246) 22 (247) 23 (248) 24 (249) 25 (250) 26 (251) 27 (252) 28 (253) 29 (254) 30 (255) 31 (256) 32 (257) 33 (258) 34 (259) 35 (260) 36 (0) 37 (262) 38 (263) 39 (264) 40 (265) 41 (266) 42 (267) 43 (268) 44 (269) 45 (270) 46 (271) 47 (272) 48 (273) 49 (274) 50 (275) 51 (276) 52 (277) 53 (278) 54 (279) 55 (280) 56 (281) 57 (282) 58 (283) 59 (284) 60 (285) 61 (286) 62 (287) 63 (288) 64 (289) 65 (290) 66 (291) 67 (292) 68 (293) 69 (294) 70 (295) 71 (296) 72 (297) 73 (298) 74 (299) 75 (300) 76 (301) 77 (302) 78 (303) 79 (304) 80 (305) 81 (306) 82 (307) 83 (308) 84 (309) 85 (310) 86 (311) 87 (312) 88 (313) 89 (314) 90 (315) 91 (316) 92 (317) 93 (318) 94 (319) 95 (320) 96 (321) 97 (322) 98 (323) 99 (324) 100 (325) 101 (326) 102 (327) 103 (328) 104 (329) 105 (330) 106 (331) 107 (332) 108 (333) 109 (334) 110 (335) 111 (336) 112 (337) 113 (338) 114 (339) 115 (340) 116 (341) 117 (342) 118 (343) 119 (344) 120 (345) 121 (346) 122 (347) 123 (348) 124 (349) 125 (350) 126 (0) 127 (352) 128 (353) 129 (354) 130 (355) 131 (356) 132 (357) 133 (0) 134 (359) 135 (360) 136 (361) 137 (362) 138 (363) 139 (364) 140 (365) 141 (366) \n"
     ]
    }
   ],
   "source": [
    "analyze_paragraph(json_data, start_paragraph_id=795, last_paragraph_id=1300, show_only_one=False, print_flag=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abec2a55-cc92-4fc0-ad55-dcd7928a5e83",
   "metadata": {},
   "source": [
    "## 6. Normalize id values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1664fb7b-58a3-42fa-a5a5-8ff1f9825448",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_file = open(\"data-all.jsonl\", \"r\")\n",
    "out_file = open(\"data.jsonl\", \"w\")\n",
    "counter = 0\n",
    "for line in in_file:\n",
    "    json_line = json.loads(line)\n",
    "    counter += 1\n",
    "    json_line[\"id\"] = counter\n",
    "    print(json.dumps(json_line), file=out_file)\n",
    "out_file.close()\n",
    "in_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff502de-7348-4e64-be5d-ea00fe3e9f80",
   "metadata": {},
   "source": [
    "## 7. Visualize data\n",
    "\n",
    "Copied from: https://github.com/eriktks/cognitive_mapping/blob/main/phrases.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c5f62b-9b98-4f09-afcd-c596fe74587f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ids(labels, text):\n",
    "    ids = {}\n",
    "    for label_data in labels:\n",
    "        while text[label_data[0]] in \" .,?!:;\":\n",
    "            label_data[0] += 1\n",
    "        while text[label_data[1]-1] in \" .,?!:;\":\n",
    "            label_data[1] -= 1\n",
    "        if label_data[0] in ids or label_data[1] in ids:\n",
    "            print(f\"overlapping relation parts! {data_item['label']}\")\n",
    "        ids[label_data[0]] = { \"type\": \"start\", \"label\": label_data[2] }\n",
    "        ids[label_data[1]] = { \"type\":\"end\", \"label\": label_data[2] }\n",
    "    return ids "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3f5848-7758-4690-85cb-f9a4acdcd100",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_colors_to_text(text, ids):\n",
    "    for key in sorted(ids.keys(), reverse=True):\n",
    "        if ids[key][\"type\"] == \"end\":\n",
    "            text = text[:key+1] + \"\\x1b[m\" + text[key+1:]\n",
    "        else:\n",
    "            if ids[key][\"label\"] == \"Content_Concept_1\":\n",
    "                color_code = 1\n",
    "            elif ids[key][\"label\"] == \"Content_Concept_2\":\n",
    "                color_code = 4\n",
    "            elif ids[key][\"label\"] == \"Content_Relation_Explanation\":\n",
    "                color_code = 0\n",
    "            else:\n",
    "                color_code = 7\n",
    "                print(f\"unknown relation part label! ({ids[key]['label']})\")\n",
    "            text = text[:key] + f\"\\x1b[1;3{color_code};47m\" + text[key:]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2720552-29c9-4e03-a77b-27fa8d793a69",
   "metadata": {},
   "source": [
    "Note that the id parameter of the function `visualize` starts at the value 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba86f26f-ae4e-4859-a738-42d5cfdef597",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(json_data, i):\n",
    "    text = json_data[i-1][\"data\"]\n",
    "    ids = make_ids(json_data[i-1]['label'], text)\n",
    "    text = add_colors_to_text(text, ids)\n",
    "    print(text + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a4cdb2-c9e1-49c1-8782-6ede2efd9f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 2):\n",
    "    visualize(json_data, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f493d02a-cc4a-41a3-bfeb-7c3c1599d455",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "allennlp",
   "language": "python",
   "name": "allennlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
