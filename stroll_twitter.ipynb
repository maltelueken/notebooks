{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a46ba36-2904-4222-89c4-4d2e6d584948",
   "metadata": {},
   "source": [
    "# Stroll Twitter\n",
    "\n",
    "Use Stroll semantic role labeling for information extraction from tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c881825-49a1-4203-9985-73813a8d8d7f",
   "metadata": {},
   "source": [
    "## 1. Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfb8655-639a-46d8-86dd-b957a7536665",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d215a8f4-60e9-4040-8d9c-a218c87b43d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = \"../../puregome/data/text/\"\n",
    "TEXT = \"text\"\n",
    "USER = \"user\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fdbbc5-61a9-4d39-95a6-96c09c24b3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def squeal(text=None):\n",
    "    clear_output(wait=True)\n",
    "    if not text is None: print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cea2fa-f15a-4e69-b57f-b94a90c8ceed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_urls(tweet_text):\n",
    "    return(re.sub(r\"\\bhttps?://\\S*\",\"\",tweet_text,flags=re.IGNORECASE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3d01be-9b98-4093-8efd-3ec41cfcccaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_newlines(tweet_text):\n",
    "    return re.sub(r'\\\\n', '\\n', tweet_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7da21e7-eb5e-483f-bce6-ecefa0a50e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tweets(file_pattern):\n",
    "    file_names = sorted(os.listdir(DATADIR))\n",
    "    texts = []\n",
    "    for file_name in file_names:\n",
    "        if re.search(file_pattern, file_name):\n",
    "            df = pd.read_csv(DATADIR + file_name)\n",
    "            texts.extend(list(df[TEXT]))\n",
    "            squeal(file_name)\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca1c0e9-1e09-4a3a-b18c-bff8bdb99f8f",
   "metadata": {},
   "source": [
    "## 2. Stroll\n",
    "\n",
    "Functions copied from stroll_srl_test.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1b637a-c5d8-4f11-9769-f94a56ff0047",
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza\n",
    "import stroll.stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67f0bab-ba37-438c-88ee-570a49876aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp_analysis_to_table(nlp_analysis):\n",
    "    nbr_of_words = 0\n",
    "    for s in nlp_analysis.sentences:\n",
    "        for w in s.words:\n",
    "            if nbr_of_words == 0:\n",
    "                nlp_table_df = pd.DataFrame({\"id\": [w.id], \n",
    "                                             \"text\": [w.text], \n",
    "                                             \"lemma\": [w.lemma],\n",
    "                                             \"upos\": [w.upos],\n",
    "                                             \"xpos\": [w.xpos],\n",
    "                                             \"feats\": [w.feats],\n",
    "                                             \"head\": [w.head],\n",
    "                                             \"deprel\": [w.deprel],\n",
    "                                             \"deps\": [w.deps],\n",
    "                                             \"misc\": [w.misc],\n",
    "                                             \"start_char\": [w.start_char],\n",
    "                                             \"end_char\": [w.end_char],\n",
    "                                             \"parent\": [w.parent],\n",
    "                                             \"sent\": [w.sent],\n",
    "                                             \"srl\": [w.srl],\n",
    "                                             \"frame\": [w.frame],\n",
    "                                            })\n",
    "            else:\n",
    "                nlp_table_df.loc[len(nlp_table_df.index)] = [ w.id, w.text, w.lemma, w.upos, w.xpos, w.feats, w.head, w.deprel, w.deps, w.misc, \n",
    "                                                              w.start_char, w.end_char, w.parent, w.sent, w.srl, w.frame ]\n",
    "            nbr_of_words += 1\n",
    "    return nlp_table_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d05b2c-9a92-497e-bf49-51f7b7996c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "SRL_FIELDS = [ \"sent_id\", \"head_id\", \"head\", \"nsubj\", \"rel\", \"Arg0\", \"Arg1\", \"Arg2\", \n",
    "               \"ArgM-ADV\", \"ArgM-CAU\", \"ArgM-DIS\", \"ArgM-LOC\", \"ArgM-MNR\", \"ArgM-MOD\", \"ArgM-NEG\", \"ArgM-REC\", \"ArgM-TMP\" ]\n",
    "\n",
    "\n",
    "def srl_dict_to_srl_list(srl_dict):\n",
    "    srl_list = len(SRL_FIELDS) * [ \"\" ]\n",
    "    for i in range(0, len(SRL_FIELDS)):\n",
    "        if SRL_FIELDS[i] in srl_dict:\n",
    "            srl_list[i] = srl_dict[SRL_FIELDS[i]]\n",
    "    return srl_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879cb088-43ce-41ce-ae07-f3079e689ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_srl_data_to_srl_table(srl_table_df, srl_data, sentence):\n",
    "    for phrase_key in srl_data:\n",
    "        if 'head' in srl_data[phrase_key]:\n",
    "            srl_data[phrase_key][\"head\"] += \" \" + sentence[phrase_key]\n",
    "        elif phrase_key > 0:\n",
    "            srl_data[phrase_key][\"head\"] = sentence[phrase_key]\n",
    "        else:\n",
    "            srl_data[phrase_key][\"head\"] = \"FILLER\"\n",
    "        srl_table_df.loc[len(srl_table_df)] = srl_dict_to_srl_list(srl_data[phrase_key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cbcefd-57b6-45d5-808a-b24fd7fbb3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp_table_to_srl_table(nlp_table_df):\n",
    "    srl_table_df = pd.DataFrame({ field: [] for field in SRL_FIELDS })\n",
    "    srl_data = {}\n",
    "    sentence = {}\n",
    "    last_id = 0\n",
    "    sent_id = 1\n",
    "    for i, row in nlp_table_df.iterrows():\n",
    "        if row['id'] <= last_id:\n",
    "            if len(srl_data) > 0:\n",
    "                add_srl_data_to_srl_table(srl_table_df, srl_data, sentence)\n",
    "            sent_id += 1\n",
    "            srl_data = {}\n",
    "            sentence = {}\n",
    "        if row['srl'] != \"_\":\n",
    "            if row['head'] not in srl_data:\n",
    "                srl_data[row['head']] = { \"sent_id\": sent_id, \"head_id\": row[\"head\"] }\n",
    "            if row['srl'] in srl_data[row['head']]:\n",
    "                print(f\"duplicate role for {row['srl']} [{i}]: {srl_data[row['head']][row['srl']]} and {row['lemma']}\")\n",
    "            srl_data[row['head']][row['srl']] = row['lemma']\n",
    "        if row['frame'] == \"rel\":\n",
    "            if row['id'] not in srl_data:\n",
    "                srl_data[row['id']] = { \"sent_id\": sent_id, \"head_id\": row[\"id\"] }\n",
    "            srl_data[row['id']][row['frame']] = row['lemma']\n",
    "        if row['deprel'] == \"nsubj\":\n",
    "            if row['head'] not in srl_data:\n",
    "                srl_data[row['head']] = { \"sent_id\": sent_id, \"head_id\": row[\"head\"] }\n",
    "            if 'nsubj' in srl_data[row['head']]:\n",
    "                srl_data[row['head']][\"nsubj\"] += \" \" + row['lemma']\n",
    "            else:\n",
    "                srl_data[row['head']][\"nsubj\"] = row['lemma']\n",
    "        if row['deprel'] == \"compound:prt\":\n",
    "            if row['head'] not in srl_data:\n",
    "                srl_data[row['head']] = { \"sent_id\": sent_id, \"head_id\": row[\"head\"] }\n",
    "            if 'head' in srl_data[row['head']]:\n",
    "                srl_data[row['head']][\"head\"] += \" \" + row['lemma']\n",
    "            else:\n",
    "                srl_data[row['head']][\"head\"] = row['lemma']\n",
    "        last_id = row['id']\n",
    "        sentence[row['id']] = row['lemma'] \n",
    "    if len(srl_data) > 0:\n",
    "        add_srl_data_to_srl_table(srl_table_df, srl_data, sentence)\n",
    "    return srl_table_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40d81de-65de-4d2b-a66b-bb633522d7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_text(text):\n",
    "    nlp_analysis = run_nlp(text)\n",
    "    nlp_table_df = nlp_analysis_to_table(nlp_analysis)\n",
    "    srl_table_df = nlp_table_to_srl_table(nlp_table_df)\n",
    "    return nlp_table_df, srl_table_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35defdf2-1fa9-46b6-a749-555684dc409a",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_nlp = stanza.Pipeline(lang='nl', processors='tokenize,lemma,pos,depparse,srl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce56471-3bd7-4f0d-96c8-d906f775e8d0",
   "metadata": {},
   "source": [
    "## 3. Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc8849a-04e3-4ea3-a8c0-c79cf9c8e910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(results_dict):\n",
    "    results_df = pd.DataFrame([{ \"key\": key, \"count\": results_dict[key], \"best value\": \"\"} \n",
    "                               for key in sorted(results_dict, key=lambda k: results_dict[k], reverse=True)])\n",
    "    best_keys = get_best_keys(results_df)\n",
    "    for i, row in results_df.iterrows():\n",
    "        if row[\"key\"] in best_keys:\n",
    "            results_df.at[i, \"best value\"] = \"yes\"\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a102c913-4f28-4e62-ab41-4681dd31160f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_keys(results_df):\n",
    "    best_count = -1\n",
    "    best_keys = []\n",
    "    for i, row in results_df.iterrows():\n",
    "        if row[\"count\"] > best_count:\n",
    "            best_count = row[\"count\"]\n",
    "            best_keys = [row[\"key\"]]\n",
    "        elif row[\"count\"] == best_count:\n",
    "            best_keys.append(row[\"key\"])\n",
    "    case_is_upper = []\n",
    "    for key in best_keys:\n",
    "        case_is_upper.append(re.search(r\"^[A-Z]\", key) != None)\n",
    "    if True in case_is_upper:\n",
    "        best_keys = [ best_keys[i] for i in range(0, len(best_keys)) if case_is_upper[i] ] \n",
    "    return best_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9be53b-ccfe-41ed-9b70-f7ba6513fe95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actions(srl_table_df):\n",
    "    actions = {}\n",
    "    for i, row in srl_table_df.iterrows():\n",
    "        if row[\"rel\"] != \"\":\n",
    "            action = row[\"rel\"]\n",
    "        elif row[\"head\"] != \"\":\n",
    "            action = row[\"head\"]\n",
    "        else:\n",
    "            action = \"\"\n",
    "        if action != \"\":\n",
    "            if action in actions:\n",
    "                actions[action] += 1\n",
    "            else:\n",
    "                actions[action] = 1\n",
    "    return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef16e5f1-e0bf-4fb8-a987-cf4e09f16a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actors(srl_table_df):\n",
    "    actors = {}\n",
    "    for i, row in srl_table_df.iterrows():\n",
    "        if row[\"Arg0\"] != \"\":\n",
    "            actor = row[\"Arg0\"]\n",
    "        elif row[\"head\"] != \"\":\n",
    "            actor = row[\"head\"]\n",
    "        else:\n",
    "            actor = \"\"\n",
    "        if actor != \"\":\n",
    "            if actor in actors:\n",
    "                actors[actor] += 1\n",
    "            else:\n",
    "                actors[actor] = 1\n",
    "    return actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9566d6-95e0-4f62-8cd0-546ac8c69b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_arguments(srl_table_df, number=1):\n",
    "    argument_name = \"Arg\" + str(number)\n",
    "    arguments = {}\n",
    "    for i, row in srl_table_df.iterrows():\n",
    "        if row[argument_name] != \"\":\n",
    "            argument = row[argument_name]\n",
    "        else:\n",
    "            argument = \"\"\n",
    "        if argument != \"\":\n",
    "            if argument in arguments:\n",
    "                arguments[argument] += 1\n",
    "            else:\n",
    "                arguments[argument] = 1\n",
    "    return arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c9fc47-711c-41a3-95c8-900a756206af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(data):\n",
    "    for word_data in data:\n",
    "        if word_data[\"pos\"] == \"ADJ\":\n",
    "            print(word_data[\"lemma\"], data[word_data[\"head\"]-1][\"lemma\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f7353e-a910-4c6a-8c0f-ce0c4ff3a40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for hour in [ \"20211231-06\", \"20211231-07\" ]:\n",
    "    tweet_texts = read_tweets(hour)\n",
    "    nlp_table_df_all = pd.DataFrame([])\n",
    "    srl_table_df_all = pd.DataFrame([])\n",
    "    counter = 0\n",
    "    for tweet_text in tweet_texts:\n",
    "        try:\n",
    "            counter += 1\n",
    "            squeal(f\"{hour} {counter}/{len(tweet_texts)} \" + tweet_text)\n",
    "            new_nlp_table_df, new_srl_table_df = analyze_text(restore_newlines(remove_urls(tweet_text)))\n",
    "            nlp_table_df_all = pd.concat([nlp_table_df_all, new_nlp_table_df])\n",
    "            srl_table_df_all = pd.concat([srl_table_df_all, new_srl_table_df])\n",
    "        except: \n",
    "            pass\n",
    "    srl_table_df_all.to_csv(hour + \"_srl_table_df_all.csv.gz\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f660d9-cf76-4176-9a4b-74dd14976a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nlp_table_df_all), len(srl_table_df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e7735c-48d0-470f-a2c9-49f08190a3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_table_df_all.to_csv(\"2022123105_nlp_table_df_all.csv.gz\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd953d3-8be0-43b1-979a-71f091be329e",
   "metadata": {},
   "outputs": [],
   "source": [
    "srl_table_df_all.to_csv(\"2022123105_srl_table_df_all.csv.gz\"), compression=\"gzip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9acde7-4749-4eaf-87b3-e3dec31c7d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results(get_actions(srl_table_df))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b14811-530e-4112-8bd1-dafcaa9a5770",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results(get_arguments(srl_table_df, number=1))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc341816-1ef9-4fbb-adcc-427839517e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i, row in nlp_table_df.iterrows():\n",
    "    if len(data) > 0 and row[\"id\"] < data[-1][\"id\"]:\n",
    "        check(data)\n",
    "        data = []\n",
    "    data.append({\"id\": row[\"id\"], \"pos\": row[\"upos\"], \"lemma\": row[\"lemma\"], \"head\": row[\"head\"]})\n",
    "if len(data) > 0:\n",
    "    check(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a90e09-79bc-41f0-be12-a6a9aec91822",
   "metadata": {},
   "source": [
    "## 4. Read and process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4ebedc-d4f3-4f70-ad70-65be2a7fa45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "srl_table_df_all = pd.DataFrame([])\n",
    "for hour in [ \"05\", \"06\", \"07\" ]:\n",
    "    srl_table_df = pd.read_csv(f\"20211231-{hour}_srl_table_df_all.csv.gz\", compression=\"gzip\", index_col=0).fillna(\"\")\n",
    "    srl_table_df_all = pd.concat([srl_table_df_all, srl_table_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a77cf5-7b3d-42d8-8f3a-7356ad116b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "srl_table_df_all[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9253429e-f408-4505-b18f-08c262b1795e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(srl_table_df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1881e11b-5948-4c6c-9c09-f4af9931c002",
   "metadata": {},
   "outputs": [],
   "source": [
    "srl_table_df_all[srl_table_df_all[\"Arg0\"]==\"Rutte\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9768446-aa0e-4b00-b0a4-0d6883c0a24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = show_results(get_actors(srl_table_df_all))\n",
    "[ (row[\"key\"], row[\"count\"]) for i, row in analysis.iterrows() if re.search(\"^[A-Z]\", row[\"key\"]) ][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644f6459-c47c-4e77-898b-edfd2258d668",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stroll",
   "language": "python",
   "name": "stroll"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
